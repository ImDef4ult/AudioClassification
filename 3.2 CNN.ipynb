{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "max_pad_len = 174\n",
    "\n",
    "def extract_features(file_name):\n",
    "\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None\n",
    "\n",
    "    return mfccs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3554it [02:41, 22.17it/s]C:\\Users\\masterdoc\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1323\n",
      "  warnings.warn(\n",
      "8326it [06:13, 30.91it/s]C:\\Users\\masterdoc\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1103\n",
      "  warnings.warn(\n",
      "C:\\Users\\masterdoc\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1523\n",
      "  warnings.warn(\n",
      "8732it [06:30, 22.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  8732  files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the full UrbanSound dataset\n",
    "full_dataset_path = 'Data/UrbanSound8K/audio'\n",
    "metadata = pd.read_csv('Data/UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "features = []\n",
    "\n",
    "# Iterate through each sound file and extract the features\n",
    "for index, row in tqdm(metadata.iterrows()):\n",
    "\n",
    "    file_name = os.path.join(os.path.abspath(full_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "\n",
    "    class_label = row[\"class\"]\n",
    "    data = extract_features(file_name)\n",
    "\n",
    "    features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe\n",
    "features_df = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(features_df), ' files')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                feature       class_label\n0     [[-306.77255, -177.59209, -99.13616, -65.97198...          dog_bark\n1     [[-457.6953, -451.0248, -450.68613, -444.99997...  children_playing\n2     [[-468.0367, -467.42264, -481.04654, -486.5948...  children_playing\n3     [[-422.42215, -411.9085, -409.46243, -409.0892...  children_playing\n4     [[-438.10162, -434.47787, -443.3284, -442.6644...  children_playing\n...                                                 ...               ...\n8727  [[-397.82446, -400.45578, -407.5035, -408.9529...          car_horn\n8728  [[-451.81265, -451.41983, -450.67892, -445.635...          car_horn\n8729  [[-301.06348, -298.25397, -305.0326, -303.8614...          car_horn\n8730  [[-373.6307, -369.44986, -366.48, -364.9094, -...          car_horn\n8731  [[-309.34647, -305.3132, -308.23593, -308.1856...          car_horn\n\n[8732 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n      <th>class_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[-306.77255, -177.59209, -99.13616, -65.97198...</td>\n      <td>dog_bark</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[-457.6953, -451.0248, -450.68613, -444.99997...</td>\n      <td>children_playing</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[-468.0367, -467.42264, -481.04654, -486.5948...</td>\n      <td>children_playing</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[-422.42215, -411.9085, -409.46243, -409.0892...</td>\n      <td>children_playing</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[-438.10162, -434.47787, -443.3284, -442.6644...</td>\n      <td>children_playing</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8727</th>\n      <td>[[-397.82446, -400.45578, -407.5035, -408.9529...</td>\n      <td>car_horn</td>\n    </tr>\n    <tr>\n      <th>8728</th>\n      <td>[[-451.81265, -451.41983, -450.67892, -445.635...</td>\n      <td>car_horn</td>\n    </tr>\n    <tr>\n      <th>8729</th>\n      <td>[[-301.06348, -298.25397, -305.0326, -303.8614...</td>\n      <td>car_horn</td>\n    </tr>\n    <tr>\n      <th>8730</th>\n      <td>[[-373.6307, -369.44986, -366.48, -364.9094, -...</td>\n      <td>car_horn</td>\n    </tr>\n    <tr>\n      <th>8731</th>\n      <td>[[-309.34647, -305.3132, -308.23593, -308.1856...</td>\n      <td>car_horn</td>\n    </tr>\n  </tbody>\n</table>\n<p>8732 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "features_df.to_csv('features_df_index.csv', index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(features_df.feature.tolist())\n",
    "y = np.array(features_df.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y))\n",
    "\n",
    "# split the dataset\n",
    "\n",
    "x_train_full, x_test, y_train_full, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size=0.2, random_state = 42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, GlobalAveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "num_rows = 40\n",
    "num_columns = 174\n",
    "num_channels = 1\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_val = x_val.reshape(x_val.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compile the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 39, 173, 16)       80        \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 19, 86, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 19, 86, 16)        0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 18, 85, 32)        2080      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 9, 42, 32)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 9, 42, 32)         0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 8, 41, 64)         8256      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 4, 20, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 4, 20, 64)         0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 3, 19, 128)        32896     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 1, 9, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 1, 9, 128)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 128)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,602\n",
      "Trainable params: 44,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "44/44 [==============================] - 1s 10ms/step - loss: 5.6856 - accuracy: 0.0594\n",
      "Pre-training accuracy: 5.9413%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary\n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy\n",
    "score = model.evaluate(x_val, y_val, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "num_epochs = 72\n",
    "num_batch_size = 256\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='saved_models_CNN/weights.best.basic_cnn.hdf5',\n",
    "    verbose=1,\n",
    "    save_best_only=True\n",
    ")\n",
    "start = datetime.now()\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_val, y_val), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(f'Trained the model in: {duration}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 4.0353 - accuracy: 0.1945\n",
      "Epoch 00001: val_loss improved from inf to 2.12391, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 4.0353 - accuracy: 0.1945 - val_loss: 2.1239 - val_accuracy: 0.2527\n",
      "Epoch 2/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.9923 - accuracy: 0.3160\n",
      "Epoch 00002: val_loss improved from 2.12391 to 2.03971, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 1.9923 - accuracy: 0.3160 - val_loss: 2.0397 - val_accuracy: 0.3286\n",
      "Epoch 3/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.6578 - accuracy: 0.4188\n",
      "Epoch 00003: val_loss improved from 2.03971 to 1.78514, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 1.6578 - accuracy: 0.4188 - val_loss: 1.7851 - val_accuracy: 0.4152\n",
      "Epoch 4/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.4910 - accuracy: 0.4769\n",
      "Epoch 00004: val_loss improved from 1.78514 to 1.66470, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 1.4910 - accuracy: 0.4769 - val_loss: 1.6647 - val_accuracy: 0.4381\n",
      "Epoch 5/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.4135 - accuracy: 0.5079\n",
      "Epoch 00005: val_loss improved from 1.66470 to 1.62297, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 1.4135 - accuracy: 0.5079 - val_loss: 1.6230 - val_accuracy: 0.4388\n",
      "Epoch 6/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.3540 - accuracy: 0.5272\n",
      "Epoch 00006: val_loss improved from 1.62297 to 1.52758, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 1.3540 - accuracy: 0.5272 - val_loss: 1.5276 - val_accuracy: 0.4961\n",
      "Epoch 7/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.2875 - accuracy: 0.5523\n",
      "Epoch 00007: val_loss improved from 1.52758 to 1.47918, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 1.2875 - accuracy: 0.5523 - val_loss: 1.4792 - val_accuracy: 0.5011\n",
      "Epoch 8/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.2423 - accuracy: 0.5687\n",
      "Epoch 00008: val_loss improved from 1.47918 to 1.42172, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 1.2423 - accuracy: 0.5687 - val_loss: 1.4217 - val_accuracy: 0.5240\n",
      "Epoch 9/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.1870 - accuracy: 0.5872\n",
      "Epoch 00009: val_loss improved from 1.42172 to 1.36178, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 1.1870 - accuracy: 0.5872 - val_loss: 1.3618 - val_accuracy: 0.5333\n",
      "Epoch 10/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.1391 - accuracy: 0.5948\n",
      "Epoch 00010: val_loss improved from 1.36178 to 1.30153, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 1.1391 - accuracy: 0.5948 - val_loss: 1.3015 - val_accuracy: 0.5476\n",
      "Epoch 11/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.1031 - accuracy: 0.6115\n",
      "Epoch 00011: val_loss improved from 1.30153 to 1.27155, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 1.1031 - accuracy: 0.6115 - val_loss: 1.2715 - val_accuracy: 0.5662\n",
      "Epoch 12/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.0634 - accuracy: 0.6240\n",
      "Epoch 00012: val_loss improved from 1.27155 to 1.24568, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 1.0634 - accuracy: 0.6240 - val_loss: 1.2457 - val_accuracy: 0.5583\n",
      "Epoch 13/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.0294 - accuracy: 0.6433\n",
      "Epoch 00013: val_loss improved from 1.24568 to 1.17906, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 1.0294 - accuracy: 0.6433 - val_loss: 1.1791 - val_accuracy: 0.6027\n",
      "Epoch 14/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9947 - accuracy: 0.6537\n",
      "Epoch 00014: val_loss improved from 1.17906 to 1.16794, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.9947 - accuracy: 0.6537 - val_loss: 1.1679 - val_accuracy: 0.6099\n",
      "Epoch 15/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9693 - accuracy: 0.6620\n",
      "Epoch 00015: val_loss improved from 1.16794 to 1.12045, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.9693 - accuracy: 0.6620 - val_loss: 1.1205 - val_accuracy: 0.6170\n",
      "Epoch 16/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9429 - accuracy: 0.6686\n",
      "Epoch 00016: val_loss improved from 1.12045 to 1.07770, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.9429 - accuracy: 0.6686 - val_loss: 1.0777 - val_accuracy: 0.6543\n",
      "Epoch 17/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9156 - accuracy: 0.6850\n",
      "Epoch 00017: val_loss improved from 1.07770 to 1.07719, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.9156 - accuracy: 0.6850 - val_loss: 1.0772 - val_accuracy: 0.6464\n",
      "Epoch 18/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9032 - accuracy: 0.6935\n",
      "Epoch 00018: val_loss improved from 1.07719 to 1.01640, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.9032 - accuracy: 0.6935 - val_loss: 1.0164 - val_accuracy: 0.6815\n",
      "Epoch 19/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8700 - accuracy: 0.6994\n",
      "Epoch 00019: val_loss did not improve from 1.01640\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.8700 - accuracy: 0.6994 - val_loss: 1.0598 - val_accuracy: 0.6471\n",
      "Epoch 20/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8619 - accuracy: 0.6970\n",
      "Epoch 00020: val_loss improved from 1.01640 to 1.01069, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.8619 - accuracy: 0.6970 - val_loss: 1.0107 - val_accuracy: 0.6593\n",
      "Epoch 21/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8477 - accuracy: 0.7146\n",
      "Epoch 00021: val_loss improved from 1.01069 to 0.97987, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.8477 - accuracy: 0.7146 - val_loss: 0.9799 - val_accuracy: 0.6772\n",
      "Epoch 22/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8022 - accuracy: 0.7183\n",
      "Epoch 00022: val_loss improved from 0.97987 to 0.96897, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.8022 - accuracy: 0.7183 - val_loss: 0.9690 - val_accuracy: 0.6822\n",
      "Epoch 23/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7718 - accuracy: 0.7337\n",
      "Epoch 00023: val_loss improved from 0.96897 to 0.94279, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.7718 - accuracy: 0.7337 - val_loss: 0.9428 - val_accuracy: 0.6865\n",
      "Epoch 24/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7724 - accuracy: 0.7307\n",
      "Epoch 00024: val_loss improved from 0.94279 to 0.88946, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.7724 - accuracy: 0.7307 - val_loss: 0.8895 - val_accuracy: 0.7015\n",
      "Epoch 25/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7270 - accuracy: 0.7475\n",
      "Epoch 00025: val_loss did not improve from 0.88946\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.7270 - accuracy: 0.7475 - val_loss: 0.9184 - val_accuracy: 0.6922\n",
      "Epoch 26/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7231 - accuracy: 0.7500\n",
      "Epoch 00026: val_loss did not improve from 0.88946\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.7231 - accuracy: 0.7500 - val_loss: 0.9107 - val_accuracy: 0.6994\n",
      "Epoch 27/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7233 - accuracy: 0.7459\n",
      "Epoch 00027: val_loss improved from 0.88946 to 0.86479, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.7233 - accuracy: 0.7459 - val_loss: 0.8648 - val_accuracy: 0.7158\n",
      "Epoch 28/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6995 - accuracy: 0.7593\n",
      "Epoch 00028: val_loss improved from 0.86479 to 0.84398, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.6995 - accuracy: 0.7593 - val_loss: 0.8440 - val_accuracy: 0.7201\n",
      "Epoch 29/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6859 - accuracy: 0.7636\n",
      "Epoch 00029: val_loss improved from 0.84398 to 0.82905, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.6859 - accuracy: 0.7636 - val_loss: 0.8290 - val_accuracy: 0.7430\n",
      "Epoch 30/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6597 - accuracy: 0.7742\n",
      "Epoch 00030: val_loss did not improve from 0.82905\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.6597 - accuracy: 0.7742 - val_loss: 0.8389 - val_accuracy: 0.7230\n",
      "Epoch 31/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6668 - accuracy: 0.7727\n",
      "Epoch 00031: val_loss improved from 0.82905 to 0.76409, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 0.6668 - accuracy: 0.7727 - val_loss: 0.7641 - val_accuracy: 0.7545\n",
      "Epoch 32/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6391 - accuracy: 0.7768\n",
      "Epoch 00032: val_loss did not improve from 0.76409\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.6391 - accuracy: 0.7768 - val_loss: 0.7887 - val_accuracy: 0.7394\n",
      "Epoch 33/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6204 - accuracy: 0.7892\n",
      "Epoch 00033: val_loss improved from 0.76409 to 0.73731, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.6204 - accuracy: 0.7892 - val_loss: 0.7373 - val_accuracy: 0.7595\n",
      "Epoch 34/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6015 - accuracy: 0.7913\n",
      "Epoch 00034: val_loss improved from 0.73731 to 0.73444, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.6015 - accuracy: 0.7913 - val_loss: 0.7344 - val_accuracy: 0.7688\n",
      "Epoch 35/72\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 0.5821 - accuracy: 0.8015\n",
      "Epoch 00035: val_loss improved from 0.73444 to 0.71440, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 0.5794 - accuracy: 0.8028 - val_loss: 0.7144 - val_accuracy: 0.7802\n",
      "Epoch 36/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5688 - accuracy: 0.8083\n",
      "Epoch 00036: val_loss improved from 0.71440 to 0.70322, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.5688 - accuracy: 0.8083 - val_loss: 0.7032 - val_accuracy: 0.7845\n",
      "Epoch 37/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5632 - accuracy: 0.8098\n",
      "Epoch 00037: val_loss improved from 0.70322 to 0.68066, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 0.5632 - accuracy: 0.8098 - val_loss: 0.6807 - val_accuracy: 0.7838\n",
      "Epoch 38/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5470 - accuracy: 0.8148\n",
      "Epoch 00038: val_loss improved from 0.68066 to 0.67293, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.5470 - accuracy: 0.8148 - val_loss: 0.6729 - val_accuracy: 0.7838\n",
      "Epoch 39/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5309 - accuracy: 0.8194\n",
      "Epoch 00039: val_loss improved from 0.67293 to 0.65195, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.5309 - accuracy: 0.8194 - val_loss: 0.6520 - val_accuracy: 0.7981\n",
      "Epoch 40/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5306 - accuracy: 0.8223\n",
      "Epoch 00040: val_loss improved from 0.65195 to 0.64000, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 0.5306 - accuracy: 0.8223 - val_loss: 0.6400 - val_accuracy: 0.8046\n",
      "Epoch 41/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5277 - accuracy: 0.8212\n",
      "Epoch 00041: val_loss improved from 0.64000 to 0.61060, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 0.5277 - accuracy: 0.8212 - val_loss: 0.6106 - val_accuracy: 0.8210\n",
      "Epoch 42/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5046 - accuracy: 0.8253\n",
      "Epoch 00042: val_loss improved from 0.61060 to 0.60605, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.5046 - accuracy: 0.8253 - val_loss: 0.6061 - val_accuracy: 0.8139\n",
      "Epoch 43/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4881 - accuracy: 0.8325\n",
      "Epoch 00043: val_loss did not improve from 0.60605\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.4881 - accuracy: 0.8325 - val_loss: 0.6286 - val_accuracy: 0.8046\n",
      "Epoch 44/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4886 - accuracy: 0.8275\n",
      "Epoch 00044: val_loss did not improve from 0.60605\n",
      "22/22 [==============================] - 0s 23ms/step - loss: 0.4886 - accuracy: 0.8275 - val_loss: 0.6316 - val_accuracy: 0.8039\n",
      "Epoch 45/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4774 - accuracy: 0.8388\n",
      "Epoch 00045: val_loss did not improve from 0.60605\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.4774 - accuracy: 0.8388 - val_loss: 0.6410 - val_accuracy: 0.7996\n",
      "Epoch 46/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4734 - accuracy: 0.8379\n",
      "Epoch 00046: val_loss did not improve from 0.60605\n",
      "22/22 [==============================] - 0s 23ms/step - loss: 0.4734 - accuracy: 0.8379 - val_loss: 0.6354 - val_accuracy: 0.7931\n",
      "Epoch 47/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4661 - accuracy: 0.8418\n",
      "Epoch 00047: val_loss improved from 0.60605 to 0.59501, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.4661 - accuracy: 0.8418 - val_loss: 0.5950 - val_accuracy: 0.8160\n",
      "Epoch 48/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4582 - accuracy: 0.8472\n",
      "Epoch 00048: val_loss improved from 0.59501 to 0.58637, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.4582 - accuracy: 0.8472 - val_loss: 0.5864 - val_accuracy: 0.8196\n",
      "Epoch 49/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4455 - accuracy: 0.8468\n",
      "Epoch 00049: val_loss did not improve from 0.58637\n",
      "22/22 [==============================] - 0s 23ms/step - loss: 0.4455 - accuracy: 0.8468 - val_loss: 0.6117 - val_accuracy: 0.8117\n",
      "Epoch 50/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4340 - accuracy: 0.8547\n",
      "Epoch 00050: val_loss improved from 0.58637 to 0.56817, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.4340 - accuracy: 0.8547 - val_loss: 0.5682 - val_accuracy: 0.8304\n",
      "Epoch 51/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4386 - accuracy: 0.8495\n",
      "Epoch 00051: val_loss did not improve from 0.56817\n",
      "22/22 [==============================] - 0s 23ms/step - loss: 0.4386 - accuracy: 0.8495 - val_loss: 0.5866 - val_accuracy: 0.8203\n",
      "Epoch 52/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4214 - accuracy: 0.8556\n",
      "Epoch 00052: val_loss did not improve from 0.56817\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.4214 - accuracy: 0.8556 - val_loss: 0.5697 - val_accuracy: 0.8203\n",
      "Epoch 53/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4153 - accuracy: 0.8570\n",
      "Epoch 00053: val_loss improved from 0.56817 to 0.55770, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.4153 - accuracy: 0.8570 - val_loss: 0.5577 - val_accuracy: 0.8296\n",
      "Epoch 54/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4078 - accuracy: 0.8590\n",
      "Epoch 00054: val_loss did not improve from 0.55770\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.4078 - accuracy: 0.8590 - val_loss: 0.5757 - val_accuracy: 0.8239\n",
      "Epoch 55/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4130 - accuracy: 0.8545\n",
      "Epoch 00055: val_loss improved from 0.55770 to 0.53116, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.4130 - accuracy: 0.8545 - val_loss: 0.5312 - val_accuracy: 0.8389\n",
      "Epoch 56/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4026 - accuracy: 0.8647\n",
      "Epoch 00056: val_loss improved from 0.53116 to 0.51579, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.4026 - accuracy: 0.8647 - val_loss: 0.5158 - val_accuracy: 0.8418\n",
      "Epoch 57/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.8701\n",
      "Epoch 00057: val_loss did not improve from 0.51579\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.3816 - accuracy: 0.8701 - val_loss: 0.5274 - val_accuracy: 0.8368\n",
      "Epoch 58/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3851 - accuracy: 0.8686\n",
      "Epoch 00058: val_loss did not improve from 0.51579\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.3851 - accuracy: 0.8686 - val_loss: 0.6477 - val_accuracy: 0.7946\n",
      "Epoch 59/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3707 - accuracy: 0.8720\n",
      "Epoch 00059: val_loss did not improve from 0.51579\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.3707 - accuracy: 0.8720 - val_loss: 0.5606 - val_accuracy: 0.8232\n",
      "Epoch 60/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3384 - accuracy: 0.8824\n",
      "Epoch 00060: val_loss improved from 0.51579 to 0.50746, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.3384 - accuracy: 0.8824 - val_loss: 0.5075 - val_accuracy: 0.8440\n",
      "Epoch 61/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3551 - accuracy: 0.8749\n",
      "Epoch 00061: val_loss did not improve from 0.50746\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.3551 - accuracy: 0.8749 - val_loss: 0.5136 - val_accuracy: 0.8382\n",
      "Epoch 62/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3523 - accuracy: 0.8780\n",
      "Epoch 00062: val_loss improved from 0.50746 to 0.50071, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.3523 - accuracy: 0.8780 - val_loss: 0.5007 - val_accuracy: 0.8382\n",
      "Epoch 63/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3527 - accuracy: 0.8760\n",
      "Epoch 00063: val_loss did not improve from 0.50071\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.3527 - accuracy: 0.8760 - val_loss: 0.5163 - val_accuracy: 0.8397\n",
      "Epoch 64/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3467 - accuracy: 0.8865\n",
      "Epoch 00064: val_loss did not improve from 0.50071\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.3467 - accuracy: 0.8865 - val_loss: 0.5044 - val_accuracy: 0.8468\n",
      "Epoch 65/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3349 - accuracy: 0.8862\n",
      "Epoch 00065: val_loss improved from 0.50071 to 0.47325, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.3349 - accuracy: 0.8862 - val_loss: 0.4733 - val_accuracy: 0.8604\n",
      "Epoch 66/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3387 - accuracy: 0.8851\n",
      "Epoch 00066: val_loss improved from 0.47325 to 0.45247, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.3387 - accuracy: 0.8851 - val_loss: 0.4525 - val_accuracy: 0.8669\n",
      "Epoch 67/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3294 - accuracy: 0.8860\n",
      "Epoch 00067: val_loss did not improve from 0.45247\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.3294 - accuracy: 0.8860 - val_loss: 0.4683 - val_accuracy: 0.8583\n",
      "Epoch 68/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3076 - accuracy: 0.8973\n",
      "Epoch 00068: val_loss did not improve from 0.45247\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.3076 - accuracy: 0.8973 - val_loss: 0.4778 - val_accuracy: 0.8525\n",
      "Epoch 69/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3173 - accuracy: 0.8894\n",
      "Epoch 00069: val_loss did not improve from 0.45247\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.3173 - accuracy: 0.8894 - val_loss: 0.5193 - val_accuracy: 0.8490\n",
      "Epoch 70/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2997 - accuracy: 0.8919\n",
      "Epoch 00070: val_loss did not improve from 0.45247\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.2997 - accuracy: 0.8919 - val_loss: 0.4716 - val_accuracy: 0.8611\n",
      "Epoch 71/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3152 - accuracy: 0.8932\n",
      "Epoch 00071: val_loss did not improve from 0.45247\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.3152 - accuracy: 0.8932 - val_loss: 0.4637 - val_accuracy: 0.8525\n",
      "Epoch 72/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3140 - accuracy: 0.8896\n",
      "Epoch 00072: val_loss did not improve from 0.45247\n",
      "22/22 [==============================] - 0s 23ms/step - loss: 0.3140 - accuracy: 0.8896 - val_loss: 0.4966 - val_accuracy: 0.8504\n",
      "Trained the model in: 0:00:38.939273\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9090909361839294\n",
      "Testing Accuracy:  0.8503937125205994\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_val, y_val, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def print_prediction(file_name):\n",
    "    prediction_feature = extract_features(file_name)\n",
    "    prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n",
    "\n",
    "    predicted_vector = model.predict(prediction_feature)\n",
    "    classes_x = np.argmax(predicted_vector, axis=1)\n",
    "    predicted_class = le.inverse_transform(classes_x)\n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n')\n",
    "\n",
    "    predicted_proba_vector = model.predict(prediction_feature)\n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)):\n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: air_conditioner \n",
      "\n",
      "air_conditioner \t\t :  0.99485683441162109375000000000000\n",
      "car_horn \t\t :  0.00001890494240797124803066253662\n",
      "children_playing \t\t :  0.00018242474470753222703933715820\n",
      "dog_bark \t\t :  0.00032498687505722045898437500000\n",
      "drilling \t\t :  0.00160049670375883579254150390625\n",
      "engine_idling \t\t :  0.00028481020126491785049438476562\n",
      "gun_shot \t\t :  0.00181328039616346359252929687500\n",
      "jackhammer \t\t :  0.00033878750400617718696594238281\n",
      "siren \t\t :  0.00029152922797948122024536132812\n",
      "street_music \t\t :  0.00028802047017961740493774414062\n"
     ]
    }
   ],
   "source": [
    "# Air conditioner\n",
    "file_name = 'samples/100852-0-0-0.wav'\n",
    "print_prediction(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: drilling \n",
      "\n",
      "air_conditioner \t\t :  0.00021437001123558729887008666992\n",
      "car_horn \t\t :  0.00006648711860179901123046875000\n",
      "children_playing \t\t :  0.00000793537128629395738244056702\n",
      "dog_bark \t\t :  0.00000333618322656548116356134415\n",
      "drilling \t\t :  0.99124407768249511718750000000000\n",
      "engine_idling \t\t :  0.00002026891888817772269248962402\n",
      "gun_shot \t\t :  0.00000398321662942180410027503967\n",
      "jackhammer \t\t :  0.00010648378520272672176361083984\n",
      "siren \t\t :  0.00003567542444216087460517883301\n",
      "street_music \t\t :  0.00829732511192560195922851562500\n"
     ]
    }
   ],
   "source": [
    "# Drilling\n",
    "file_name = 'samples/103199-4-0-0.wav'\n",
    "print_prediction(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: street_music \n",
      "\n",
      "air_conditioner \t\t :  0.00077994761522859334945678710938\n",
      "car_horn \t\t :  0.00009125717770075425505638122559\n",
      "children_playing \t\t :  0.04169697687029838562011718750000\n",
      "dog_bark \t\t :  0.00100257922895252704620361328125\n",
      "drilling \t\t :  0.00000510017935084761120378971100\n",
      "engine_idling \t\t :  0.00006124380888650193810462951660\n",
      "gun_shot \t\t :  0.00000000003515476798554573178990\n",
      "jackhammer \t\t :  0.00000009573000170348677784204483\n",
      "siren \t\t :  0.00136090023443102836608886718750\n",
      "street_music \t\t :  0.95500195026397705078125000000000\n"
     ]
    }
   ],
   "source": [
    "# Street music\n",
    "file_name = 'samples/101848-9-0-0.wav'\n",
    "print_prediction(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: gun_shot \n",
      "\n",
      "air_conditioner \t\t :  0.00108351698145270347595214843750\n",
      "car_horn \t\t :  0.15269839763641357421875000000000\n",
      "children_playing \t\t :  0.00603420706465840339660644531250\n",
      "dog_bark \t\t :  0.18530437350273132324218750000000\n",
      "drilling \t\t :  0.22294433414936065673828125000000\n",
      "engine_idling \t\t :  0.01421661861240863800048828125000\n",
      "gun_shot \t\t :  0.26423656940460205078125000000000\n",
      "jackhammer \t\t :  0.13804303109645843505859375000000\n",
      "siren \t\t :  0.01404852233827114105224609375000\n",
      "street_music \t\t :  0.00139042572118341922760009765625\n"
     ]
    }
   ],
   "source": [
    "# Car horn\n",
    "file_name = 'samples/100648-1-0-0.wav'\n",
    "print_prediction(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "# Serialize model to Json\n",
    "model_json = model.to_json()\n",
    "with open('models/cnn.json', 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# Serialize weights to HDF5\n",
    "model.save_weights('models/cnn.h5')\n",
    "print('Model saved')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the model and test it"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "json_file2 = open('models/cnn.json')\n",
    "loaded_model_json = json_file2.read()\n",
    "json_file2.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# Load weights into new model\n",
    "loaded_model.load_weights('models/cnn.h5')\n",
    "print('Model loaded')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test the loaded model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: street_music \n",
      "\n",
      "air_conditioner \t\t :  0.00077994761522859334945678710938\n",
      "car_horn \t\t :  0.00009125717770075425505638122559\n",
      "children_playing \t\t :  0.04169697687029838562011718750000\n",
      "dog_bark \t\t :  0.00100257922895252704620361328125\n",
      "drilling \t\t :  0.00000510017935084761120378971100\n",
      "engine_idling \t\t :  0.00006124380888650193810462951660\n",
      "gun_shot \t\t :  0.00000000003515476798554573178990\n",
      "jackhammer \t\t :  0.00000009573000170348677784204483\n",
      "siren \t\t :  0.00136090023443102836608886718750\n",
      "street_music \t\t :  0.95500195026397705078125000000000\n"
     ]
    }
   ],
   "source": [
    "file_name = 'samples/101848-9-0-0.wav'\n",
    "prediction_feature = extract_features(file_name)\n",
    "prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n",
    "\n",
    "predicted_vector = loaded_model.predict(prediction_feature)\n",
    "classes_x = np.argmax(predicted_vector, axis=1)\n",
    "predicted_class = le.inverse_transform(classes_x)\n",
    "print(\"The predicted class is:\", predicted_class[0], '\\n')\n",
    "\n",
    "predicted_proba_vector = loaded_model.predict(prediction_feature)\n",
    "predicted_proba = predicted_proba_vector[0]\n",
    "for i in range(len(predicted_proba)):\n",
    "    category = le.inverse_transform(np.array([i]))\n",
    "    print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tunning the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def cnn_tunning():\n",
    "    results = pd.DataFrame(columns=['epochs', 'kernel_size', 'train', 'val', 'time'])\n",
    "    kernel_list = [8, 16, 32]\n",
    "    epochs_list = [50, 100, 150]\n",
    "    for kernel in kernel_list:\n",
    "        for epoch in epochs_list:\n",
    "            print(f'Training model: Kernel -> {kernel} - Epochs -> {epoch}')\n",
    "            # Construct model\n",
    "            model = Sequential()\n",
    "            model.add(Conv2D(filters=kernel, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "            model.add(MaxPooling2D(pool_size=2))\n",
    "            model.add(Dropout(0.2))\n",
    "\n",
    "            model.add(Conv2D(filters=kernel*2, kernel_size=2, activation='relu'))\n",
    "            model.add(MaxPooling2D(pool_size=2))\n",
    "            model.add(Dropout(0.2))\n",
    "\n",
    "            model.add(Conv2D(filters=kernel*3, kernel_size=2, activation='relu'))\n",
    "            model.add(MaxPooling2D(pool_size=2))\n",
    "            model.add(Dropout(0.2))\n",
    "\n",
    "            model.add(Conv2D(filters=kernel*4, kernel_size=2, activation='relu'))\n",
    "            model.add(MaxPooling2D(pool_size=2))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(GlobalAveragePooling2D())\n",
    "\n",
    "            model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "            # Compile the model\n",
    "            model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "            checkpointer = ModelCheckpoint(\n",
    "                filepath='saved_models_CNN/weights.best.basic_cnn.hdf5',\n",
    "                verbose=1,\n",
    "                save_best_only=True\n",
    "            )\n",
    "            start = datetime.now()\n",
    "            model.fit(x_train, y_train, batch_size=num_batch_size, epochs=epoch, validation_data=(x_val, y_val), verbose=0)\n",
    "\n",
    "            duration = datetime.now() - start\n",
    "\n",
    "            score_train = model.evaluate(x_train, y_train, verbose=0)\n",
    "\n",
    "            score_val = model.evaluate(x_val, y_val, verbose=0)\n",
    "            results.loc[len(results)] = [epoch, kernel, score_train[1], score_val[1], duration]\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: Kernel -> 8 - Epochs -> 50\n",
      "Training model: Kernel -> 8 - Epochs -> 100\n",
      "Training model: Kernel -> 8 - Epochs -> 150\n",
      "Training model: Kernel -> 16 - Epochs -> 50\n",
      "Training model: Kernel -> 16 - Epochs -> 100\n",
      "Training model: Kernel -> 16 - Epochs -> 150\n",
      "Training model: Kernel -> 32 - Epochs -> 50\n",
      "Training model: Kernel -> 32 - Epochs -> 100\n",
      "Training model: Kernel -> 32 - Epochs -> 150\n"
     ]
    }
   ],
   "source": [
    "tunning_results = cnn_tunning()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "  epochs kernel_size     train       val                   time\n0     50           8  0.667681  0.637795 0 days 00:00:18.567406\n1    100           8  0.759485  0.733715 0 days 00:00:36.033873\n2    150           8  0.757695  0.719399 0 days 00:00:53.713254\n3     50          16  0.819435  0.777380 0 days 00:00:23.524534\n4    100          16  0.919291  0.863278 0 days 00:00:52.429907\n5    150          16  0.959914  0.896922 0 days 00:01:22.659197\n6     50          32  0.944345  0.883321 0 days 00:00:50.371103\n7    100          32  0.988726  0.910523 0 days 00:01:39.029825\n8    150          32  0.995526  0.925555 0 days 00:02:32.502665",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epochs</th>\n      <th>kernel_size</th>\n      <th>train</th>\n      <th>val</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50</td>\n      <td>8</td>\n      <td>0.667681</td>\n      <td>0.637795</td>\n      <td>0 days 00:00:18.567406</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100</td>\n      <td>8</td>\n      <td>0.759485</td>\n      <td>0.733715</td>\n      <td>0 days 00:00:36.033873</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>150</td>\n      <td>8</td>\n      <td>0.757695</td>\n      <td>0.719399</td>\n      <td>0 days 00:00:53.713254</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50</td>\n      <td>16</td>\n      <td>0.819435</td>\n      <td>0.777380</td>\n      <td>0 days 00:00:23.524534</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100</td>\n      <td>16</td>\n      <td>0.919291</td>\n      <td>0.863278</td>\n      <td>0 days 00:00:52.429907</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>150</td>\n      <td>16</td>\n      <td>0.959914</td>\n      <td>0.896922</td>\n      <td>0 days 00:01:22.659197</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>50</td>\n      <td>32</td>\n      <td>0.944345</td>\n      <td>0.883321</td>\n      <td>0 days 00:00:50.371103</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>100</td>\n      <td>32</td>\n      <td>0.988726</td>\n      <td>0.910523</td>\n      <td>0 days 00:01:39.029825</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>150</td>\n      <td>32</td>\n      <td>0.995526</td>\n      <td>0.925555</td>\n      <td>0 days 00:02:32.502665</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tunning_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing the tunned model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# Construct model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=96, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "22/22 [==============================] - 2s 44ms/step - loss: 0.0705 - accuracy: 0.9775 - val_loss: 0.3700 - val_accuracy: 0.9241\n",
      "Epoch 2/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0470 - accuracy: 0.9834 - val_loss: 0.3119 - val_accuracy: 0.9291\n",
      "Epoch 3/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0498 - accuracy: 0.9819 - val_loss: 0.3369 - val_accuracy: 0.9248\n",
      "Epoch 4/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0497 - accuracy: 0.9855 - val_loss: 0.3634 - val_accuracy: 0.9284\n",
      "Epoch 5/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0480 - accuracy: 0.9844 - val_loss: 0.3938 - val_accuracy: 0.9198\n",
      "Epoch 6/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0353 - accuracy: 0.9889 - val_loss: 0.3549 - val_accuracy: 0.9241\n",
      "Epoch 7/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0376 - accuracy: 0.9866 - val_loss: 0.3739 - val_accuracy: 0.9220\n",
      "Epoch 8/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0338 - accuracy: 0.9893 - val_loss: 0.3704 - val_accuracy: 0.9248\n",
      "Epoch 9/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0383 - accuracy: 0.9866 - val_loss: 0.3195 - val_accuracy: 0.9284\n",
      "Epoch 10/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0501 - accuracy: 0.9823 - val_loss: 0.3809 - val_accuracy: 0.9177\n",
      "Epoch 11/150\n",
      "22/22 [==============================] - 1s 42ms/step - loss: 0.0446 - accuracy: 0.9844 - val_loss: 0.3530 - val_accuracy: 0.9227\n",
      "Epoch 12/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0258 - accuracy: 0.9914 - val_loss: 0.3321 - val_accuracy: 0.9263\n",
      "Epoch 13/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0366 - accuracy: 0.9868 - val_loss: 0.3437 - val_accuracy: 0.9277\n",
      "Epoch 14/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0383 - accuracy: 0.9869 - val_loss: 0.3821 - val_accuracy: 0.9234\n",
      "Epoch 15/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0391 - accuracy: 0.9860 - val_loss: 0.3883 - val_accuracy: 0.9213\n",
      "Epoch 16/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0478 - accuracy: 0.9844 - val_loss: 0.3527 - val_accuracy: 0.9284\n",
      "Epoch 17/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0452 - accuracy: 0.9841 - val_loss: 0.3691 - val_accuracy: 0.9270\n",
      "Epoch 18/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0471 - accuracy: 0.9837 - val_loss: 0.4059 - val_accuracy: 0.9148\n",
      "Epoch 19/150\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 0.0497 - accuracy: 0.9839 - val_loss: 0.4141 - val_accuracy: 0.9234\n",
      "Epoch 20/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0524 - accuracy: 0.9834 - val_loss: 0.4125 - val_accuracy: 0.9220\n",
      "Epoch 21/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0383 - accuracy: 0.9873 - val_loss: 0.3264 - val_accuracy: 0.9320\n",
      "Epoch 22/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0367 - accuracy: 0.9885 - val_loss: 0.3588 - val_accuracy: 0.9341\n",
      "Epoch 23/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0411 - accuracy: 0.9839 - val_loss: 0.3376 - val_accuracy: 0.9334\n",
      "Epoch 24/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0497 - accuracy: 0.9834 - val_loss: 0.3706 - val_accuracy: 0.9263\n",
      "Epoch 25/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0397 - accuracy: 0.9857 - val_loss: 0.3363 - val_accuracy: 0.9205\n",
      "Epoch 26/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0356 - accuracy: 0.9893 - val_loss: 0.3535 - val_accuracy: 0.9298\n",
      "Epoch 27/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0289 - accuracy: 0.9911 - val_loss: 0.3570 - val_accuracy: 0.9334\n",
      "Epoch 28/150\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 0.0396 - accuracy: 0.9873 - val_loss: 0.3358 - val_accuracy: 0.9341\n",
      "Epoch 29/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0383 - accuracy: 0.9862 - val_loss: 0.3731 - val_accuracy: 0.9306\n",
      "Epoch 30/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0455 - accuracy: 0.9851 - val_loss: 0.3735 - val_accuracy: 0.9263\n",
      "Epoch 31/150\n",
      "22/22 [==============================] - 1s 42ms/step - loss: 0.0335 - accuracy: 0.9878 - val_loss: 0.3372 - val_accuracy: 0.9384\n",
      "Epoch 32/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0243 - accuracy: 0.9909 - val_loss: 0.3648 - val_accuracy: 0.9313\n",
      "Epoch 33/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0284 - accuracy: 0.9902 - val_loss: 0.3758 - val_accuracy: 0.9284\n",
      "Epoch 34/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0271 - accuracy: 0.9912 - val_loss: 0.3893 - val_accuracy: 0.9298\n",
      "Epoch 35/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0342 - accuracy: 0.9891 - val_loss: 0.4071 - val_accuracy: 0.9277\n",
      "Epoch 36/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0351 - accuracy: 0.9882 - val_loss: 0.3958 - val_accuracy: 0.9248\n",
      "Epoch 37/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0354 - accuracy: 0.9873 - val_loss: 0.3714 - val_accuracy: 0.9284\n",
      "Epoch 38/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0425 - accuracy: 0.9864 - val_loss: 0.3909 - val_accuracy: 0.9256\n",
      "Epoch 39/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0395 - accuracy: 0.9857 - val_loss: 0.4042 - val_accuracy: 0.9213\n",
      "Epoch 40/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0398 - accuracy: 0.9882 - val_loss: 0.4081 - val_accuracy: 0.9220\n",
      "Epoch 41/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0290 - accuracy: 0.9894 - val_loss: 0.3685 - val_accuracy: 0.9248\n",
      "Epoch 42/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0301 - accuracy: 0.9893 - val_loss: 0.3834 - val_accuracy: 0.9327\n",
      "Epoch 43/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0362 - accuracy: 0.9894 - val_loss: 0.4213 - val_accuracy: 0.9241\n",
      "Epoch 44/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0376 - accuracy: 0.9884 - val_loss: 0.3929 - val_accuracy: 0.9241\n",
      "Epoch 45/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0411 - accuracy: 0.9851 - val_loss: 0.3703 - val_accuracy: 0.9313\n",
      "Epoch 46/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0408 - accuracy: 0.9866 - val_loss: 0.4259 - val_accuracy: 0.9334\n",
      "Epoch 47/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0371 - accuracy: 0.9893 - val_loss: 0.4151 - val_accuracy: 0.9198\n",
      "Epoch 48/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0510 - accuracy: 0.9828 - val_loss: 0.4159 - val_accuracy: 0.9141\n",
      "Epoch 49/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0517 - accuracy: 0.9819 - val_loss: 0.3910 - val_accuracy: 0.9248\n",
      "Epoch 50/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0454 - accuracy: 0.9839 - val_loss: 0.3368 - val_accuracy: 0.9284\n",
      "Epoch 51/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0408 - accuracy: 0.9860 - val_loss: 0.2969 - val_accuracy: 0.9349\n",
      "Epoch 52/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0305 - accuracy: 0.9889 - val_loss: 0.3255 - val_accuracy: 0.9349\n",
      "Epoch 53/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0289 - accuracy: 0.9903 - val_loss: 0.3449 - val_accuracy: 0.9349\n",
      "Epoch 54/150\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 0.0268 - accuracy: 0.9909 - val_loss: 0.3238 - val_accuracy: 0.9370\n",
      "Epoch 55/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0306 - accuracy: 0.9893 - val_loss: 0.3471 - val_accuracy: 0.9392\n",
      "Epoch 56/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0343 - accuracy: 0.9889 - val_loss: 0.3807 - val_accuracy: 0.9341\n",
      "Epoch 57/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0284 - accuracy: 0.9896 - val_loss: 0.3979 - val_accuracy: 0.9256\n",
      "Epoch 58/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0229 - accuracy: 0.9911 - val_loss: 0.3718 - val_accuracy: 0.9349\n",
      "Epoch 59/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0268 - accuracy: 0.9896 - val_loss: 0.3873 - val_accuracy: 0.9291\n",
      "Epoch 60/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0277 - accuracy: 0.9898 - val_loss: 0.3971 - val_accuracy: 0.9320\n",
      "Epoch 61/150\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 0.0340 - accuracy: 0.9907 - val_loss: 0.3350 - val_accuracy: 0.9313\n",
      "Epoch 62/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0279 - accuracy: 0.9903 - val_loss: 0.3822 - val_accuracy: 0.9399\n",
      "Epoch 63/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0253 - accuracy: 0.9912 - val_loss: 0.3520 - val_accuracy: 0.9306\n",
      "Epoch 64/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0225 - accuracy: 0.9925 - val_loss: 0.3592 - val_accuracy: 0.9370\n",
      "Epoch 65/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0335 - accuracy: 0.9884 - val_loss: 0.3887 - val_accuracy: 0.9363\n",
      "Epoch 66/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0237 - accuracy: 0.9909 - val_loss: 0.3772 - val_accuracy: 0.9320\n",
      "Epoch 67/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0221 - accuracy: 0.9934 - val_loss: 0.4262 - val_accuracy: 0.9256\n",
      "Epoch 68/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0292 - accuracy: 0.9907 - val_loss: 0.3870 - val_accuracy: 0.9256\n",
      "Epoch 69/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0341 - accuracy: 0.9882 - val_loss: 0.4118 - val_accuracy: 0.9291\n",
      "Epoch 70/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0328 - accuracy: 0.9891 - val_loss: 0.4052 - val_accuracy: 0.9320\n",
      "Epoch 71/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0275 - accuracy: 0.9902 - val_loss: 0.4265 - val_accuracy: 0.9277\n",
      "Epoch 72/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0336 - accuracy: 0.9869 - val_loss: 0.4038 - val_accuracy: 0.9248\n",
      "Epoch 73/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.3690 - val_accuracy: 0.9298\n",
      "Epoch 74/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0220 - accuracy: 0.9907 - val_loss: 0.3441 - val_accuracy: 0.9334\n",
      "Epoch 75/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.3714 - val_accuracy: 0.9327\n",
      "Epoch 76/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0310 - accuracy: 0.9884 - val_loss: 0.4222 - val_accuracy: 0.9220\n",
      "Epoch 77/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0453 - accuracy: 0.9862 - val_loss: 0.4273 - val_accuracy: 0.9277\n",
      "Epoch 78/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0357 - accuracy: 0.9871 - val_loss: 0.3791 - val_accuracy: 0.9341\n",
      "Epoch 79/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0288 - accuracy: 0.9909 - val_loss: 0.3399 - val_accuracy: 0.9341\n",
      "Epoch 80/150\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 0.0270 - accuracy: 0.9925 - val_loss: 0.3546 - val_accuracy: 0.9356\n",
      "Epoch 81/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0254 - accuracy: 0.9918 - val_loss: 0.3250 - val_accuracy: 0.9313\n",
      "Epoch 82/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0420 - accuracy: 0.9864 - val_loss: 0.4635 - val_accuracy: 0.9198\n",
      "Epoch 83/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0349 - accuracy: 0.9885 - val_loss: 0.3589 - val_accuracy: 0.9306\n",
      "Epoch 84/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0304 - accuracy: 0.9902 - val_loss: 0.3626 - val_accuracy: 0.9277\n",
      "Epoch 85/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0322 - accuracy: 0.9889 - val_loss: 0.3561 - val_accuracy: 0.9356\n",
      "Epoch 86/150\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 0.0344 - accuracy: 0.9898 - val_loss: 0.3759 - val_accuracy: 0.9270\n",
      "Epoch 87/150\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 0.0269 - accuracy: 0.9907 - val_loss: 0.3625 - val_accuracy: 0.9320\n",
      "Epoch 88/150\n",
      "22/22 [==============================] - 1s 43ms/step - loss: 0.0202 - accuracy: 0.9925 - val_loss: 0.3974 - val_accuracy: 0.9284\n",
      "Epoch 89/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0280 - accuracy: 0.9911 - val_loss: 0.4036 - val_accuracy: 0.9284\n",
      "Epoch 90/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0296 - accuracy: 0.9900 - val_loss: 0.3731 - val_accuracy: 0.9277\n",
      "Epoch 91/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 0.3816 - val_accuracy: 0.9327\n",
      "Epoch 92/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0201 - accuracy: 0.9932 - val_loss: 0.3686 - val_accuracy: 0.9306\n",
      "Epoch 93/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0211 - accuracy: 0.9918 - val_loss: 0.3288 - val_accuracy: 0.9356\n",
      "Epoch 94/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0293 - accuracy: 0.9898 - val_loss: 0.3635 - val_accuracy: 0.9306\n",
      "Epoch 95/150\n",
      "22/22 [==============================] - 1s 43ms/step - loss: 0.0361 - accuracy: 0.9898 - val_loss: 0.3870 - val_accuracy: 0.9306\n",
      "Epoch 96/150\n",
      "22/22 [==============================] - 1s 44ms/step - loss: 0.0297 - accuracy: 0.9909 - val_loss: 0.3232 - val_accuracy: 0.9349\n",
      "Epoch 97/150\n",
      "22/22 [==============================] - 1s 44ms/step - loss: 0.0235 - accuracy: 0.9918 - val_loss: 0.3337 - val_accuracy: 0.9413\n",
      "Epoch 98/150\n",
      "22/22 [==============================] - 1s 44ms/step - loss: 0.0230 - accuracy: 0.9914 - val_loss: 0.3627 - val_accuracy: 0.9392\n",
      "Epoch 99/150\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 0.0199 - accuracy: 0.9919 - val_loss: 0.3507 - val_accuracy: 0.9363\n",
      "Epoch 100/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0207 - accuracy: 0.9925 - val_loss: 0.3700 - val_accuracy: 0.9284\n",
      "Epoch 101/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0268 - accuracy: 0.9903 - val_loss: 0.3409 - val_accuracy: 0.9363\n",
      "Epoch 102/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0301 - accuracy: 0.9891 - val_loss: 0.3970 - val_accuracy: 0.9291\n",
      "Epoch 103/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0344 - accuracy: 0.9898 - val_loss: 0.3789 - val_accuracy: 0.9313\n",
      "Epoch 104/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0303 - accuracy: 0.9900 - val_loss: 0.3311 - val_accuracy: 0.9327\n",
      "Epoch 105/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0234 - accuracy: 0.9925 - val_loss: 0.3787 - val_accuracy: 0.9298\n",
      "Epoch 106/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.3834 - val_accuracy: 0.9284\n",
      "Epoch 107/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 0.3564 - val_accuracy: 0.9320\n",
      "Epoch 108/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0247 - accuracy: 0.9907 - val_loss: 0.3621 - val_accuracy: 0.9349\n",
      "Epoch 109/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 0.3737 - val_accuracy: 0.9370\n",
      "Epoch 110/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0274 - accuracy: 0.9918 - val_loss: 0.4137 - val_accuracy: 0.9334\n",
      "Epoch 111/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0236 - accuracy: 0.9909 - val_loss: 0.3856 - val_accuracy: 0.9327\n",
      "Epoch 112/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0215 - accuracy: 0.9937 - val_loss: 0.3325 - val_accuracy: 0.9349\n",
      "Epoch 113/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0234 - accuracy: 0.9914 - val_loss: 0.3587 - val_accuracy: 0.9334\n",
      "Epoch 114/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0226 - accuracy: 0.9919 - val_loss: 0.3854 - val_accuracy: 0.9334\n",
      "Epoch 115/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0305 - accuracy: 0.9905 - val_loss: 0.3297 - val_accuracy: 0.9384\n",
      "Epoch 116/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0240 - accuracy: 0.9923 - val_loss: 0.3473 - val_accuracy: 0.9392\n",
      "Epoch 117/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0244 - accuracy: 0.9912 - val_loss: 0.3644 - val_accuracy: 0.9384\n",
      "Epoch 118/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0271 - accuracy: 0.9911 - val_loss: 0.3903 - val_accuracy: 0.9363\n",
      "Epoch 119/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0274 - accuracy: 0.9903 - val_loss: 0.3916 - val_accuracy: 0.9356\n",
      "Epoch 120/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0301 - accuracy: 0.9909 - val_loss: 0.3711 - val_accuracy: 0.9349\n",
      "Epoch 121/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0342 - accuracy: 0.9893 - val_loss: 0.4166 - val_accuracy: 0.9298\n",
      "Epoch 122/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0212 - accuracy: 0.9932 - val_loss: 0.3522 - val_accuracy: 0.9356\n",
      "Epoch 123/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0190 - accuracy: 0.9923 - val_loss: 0.3277 - val_accuracy: 0.9377\n",
      "Epoch 124/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0255 - accuracy: 0.9925 - val_loss: 0.3647 - val_accuracy: 0.9392\n",
      "Epoch 125/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.3662 - val_accuracy: 0.9399\n",
      "Epoch 126/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 0.4030 - val_accuracy: 0.9320\n",
      "Epoch 127/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0252 - accuracy: 0.9914 - val_loss: 0.3930 - val_accuracy: 0.9406\n",
      "Epoch 128/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0212 - accuracy: 0.9919 - val_loss: 0.3615 - val_accuracy: 0.9399\n",
      "Epoch 129/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0286 - accuracy: 0.9911 - val_loss: 0.4058 - val_accuracy: 0.9313\n",
      "Epoch 130/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0333 - accuracy: 0.9900 - val_loss: 0.4301 - val_accuracy: 0.9191\n",
      "Epoch 131/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0376 - accuracy: 0.9871 - val_loss: 0.4228 - val_accuracy: 0.9256\n",
      "Epoch 132/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0433 - accuracy: 0.9869 - val_loss: 0.5109 - val_accuracy: 0.9162\n",
      "Epoch 133/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0449 - accuracy: 0.9857 - val_loss: 0.4121 - val_accuracy: 0.9277\n",
      "Epoch 134/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.4250 - val_accuracy: 0.9334\n",
      "Epoch 135/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0274 - accuracy: 0.9923 - val_loss: 0.3600 - val_accuracy: 0.9442\n",
      "Epoch 136/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0201 - accuracy: 0.9939 - val_loss: 0.3722 - val_accuracy: 0.9370\n",
      "Epoch 137/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0181 - accuracy: 0.9943 - val_loss: 0.3763 - val_accuracy: 0.9334\n",
      "Epoch 138/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.4360 - val_accuracy: 0.9270\n",
      "Epoch 139/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0193 - accuracy: 0.9937 - val_loss: 0.4045 - val_accuracy: 0.9334\n",
      "Epoch 140/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 0.4042 - val_accuracy: 0.9313\n",
      "Epoch 141/150\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.3672 - val_accuracy: 0.9363\n",
      "Epoch 142/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0196 - accuracy: 0.9927 - val_loss: 0.3607 - val_accuracy: 0.9363\n",
      "Epoch 143/150\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 0.0186 - accuracy: 0.9927 - val_loss: 0.3710 - val_accuracy: 0.9399\n",
      "Epoch 144/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0151 - accuracy: 0.9948 - val_loss: 0.4049 - val_accuracy: 0.9298\n",
      "Epoch 145/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0222 - accuracy: 0.9918 - val_loss: 0.3661 - val_accuracy: 0.9370\n",
      "Epoch 146/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0209 - accuracy: 0.9919 - val_loss: 0.3553 - val_accuracy: 0.9327\n",
      "Epoch 147/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.4074 - val_accuracy: 0.9384\n",
      "Epoch 148/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0185 - accuracy: 0.9948 - val_loss: 0.3676 - val_accuracy: 0.9313\n",
      "Epoch 149/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0169 - accuracy: 0.9946 - val_loss: 0.3784 - val_accuracy: 0.9392\n",
      "Epoch 150/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0217 - accuracy: 0.9918 - val_loss: 0.3945 - val_accuracy: 0.9370\n",
      "Trained the model in: 0:02:11.794616\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='saved_models_CNN/weights.best.basic_cnn.hdf5',\n",
    "    verbose=1,\n",
    "    save_best_only=True\n",
    ")\n",
    "start = datetime.now()\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=150, validation_data=(x_val, y_val), verbose=1)\n",
    "duration = datetime.now() - start\n",
    "print(f'Trained the model in: {duration}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9992842078208923\n",
      "Validation accuracy: 0.9370078444480896\n"
     ]
    }
   ],
   "source": [
    "score_train = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(f'Training accuracy: {score_train[1]}')\n",
    "score_val = model.evaluate(x_val, y_val, verbose=0)\n",
    "print(f'Validation accuracy: {score_val[1]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: air_conditioner \n",
      "\n",
      "air_conditioner \t\t :  1.00000000000000000000000000000000\n",
      "car_horn \t\t :  0.00000000000000000000384969049289\n",
      "children_playing \t\t :  0.00000000001709116355386175456488\n",
      "dog_bark \t\t :  0.00000000000000107214794073401008\n",
      "drilling \t\t :  0.00000000031607427786184416618198\n",
      "engine_idling \t\t :  0.00000000001162494493028853881356\n",
      "gun_shot \t\t :  0.00000000000000000000163449495597\n",
      "jackhammer \t\t :  0.00000000359806673344564842409454\n",
      "siren \t\t :  0.00000000000374940703484760717856\n",
      "street_music \t\t :  0.00000000000001100076078136818375\n"
     ]
    }
   ],
   "source": [
    "# Air conditioner\n",
    "file_name = 'samples/100852-0-0-0.wav'\n",
    "print_prediction(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: drilling \n",
      "\n",
      "air_conditioner \t\t :  0.00000000000244068979436684596607\n",
      "car_horn \t\t :  0.00000000000021146665419181226442\n",
      "children_playing \t\t :  0.00000000000002157657190936246305\n",
      "dog_bark \t\t :  0.00000000000000008105524955305887\n",
      "drilling \t\t :  0.99995279312133789062500000000000\n",
      "engine_idling \t\t :  0.00000000000000106221722058128226\n",
      "gun_shot \t\t :  0.00000000000000000435926002612793\n",
      "jackhammer \t\t :  0.00000059221844139756285585463047\n",
      "siren \t\t :  0.00000000000000000096916016763831\n",
      "street_music \t\t :  0.00004664198058890178799629211426\n"
     ]
    }
   ],
   "source": [
    "# Drilling\n",
    "file_name = 'samples/103199-4-0-0.wav'\n",
    "print_prediction(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: street_music \n",
      "\n",
      "air_conditioner \t\t :  0.00000000000529474597846246730626\n",
      "car_horn \t\t :  0.00000000000007847479041372604214\n",
      "children_playing \t\t :  0.00000022000639887664874549955130\n",
      "dog_bark \t\t :  0.00000001188371712146363279316574\n",
      "drilling \t\t :  0.00000000000000500747201340255403\n",
      "engine_idling \t\t :  0.00000000000008149759350446067474\n",
      "gun_shot \t\t :  0.00000000000000000000028429161153\n",
      "jackhammer \t\t :  0.00000000000001598916650664451711\n",
      "siren \t\t :  0.00000004245556084470081259496510\n",
      "street_music \t\t :  0.99999976158142089843750000000000\n"
     ]
    }
   ],
   "source": [
    "# Street music\n",
    "file_name = 'samples/101848-9-0-0.wav'\n",
    "print_prediction(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: car_horn \n",
      "\n",
      "air_conditioner \t\t :  0.00001789550515240989625453948975\n",
      "car_horn \t\t :  0.98768591880798339843750000000000\n",
      "children_playing \t\t :  0.00001624612741579767316579818726\n",
      "dog_bark \t\t :  0.00256198784336447715759277343750\n",
      "drilling \t\t :  0.00631046155467629432678222656250\n",
      "engine_idling \t\t :  0.00001318976865150034427642822266\n",
      "gun_shot \t\t :  0.00032445686520077288150787353516\n",
      "jackhammer \t\t :  0.00228123273700475692749023437500\n",
      "siren \t\t :  0.00076773302862420678138732910156\n",
      "street_music \t\t :  0.00002089177723973989486694335938\n"
     ]
    }
   ],
   "source": [
    "# Car horn\n",
    "file_name = 'samples/100648-1-0-0.wav'\n",
    "print_prediction(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Saving the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open('models/cnn_tunned.json', 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# Serialize weights to HDF5\n",
    "model.save_weights('models/cnn_tunned.h5')\n",
    "print('Model saved')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}