{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Build a MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the data preprocessed in the previous notebook"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%store -r x_train\n",
    "%store -r x_test\n",
    "%store -r y_train\n",
    "%store -r y_test\n",
    "%store -r yy\n",
    "%store -r le"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Architecture"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "num_labels = yy.shape[1]\n",
    "\n",
    "# Construct the modedl\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, input_shape=(40, )))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compile the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Display architecture"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               10496     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78,858\n",
      "Trainable params: 78,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pre-training accuracy: 6.067544221878052%\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(f'Pre-training accuracy: {accuracy}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 8.8772 - accuracy: 0.1687\n",
      "Epoch 00001: val_loss improved from inf to 2.22190, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 2s 6ms/step - loss: 8.7548 - accuracy: 0.1684 - val_loss: 2.2219 - val_accuracy: 0.1597\n",
      "Epoch 2/100\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 2.3048 - accuracy: 0.1926\n",
      "Epoch 00002: val_loss improved from 2.22190 to 2.12806, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 2.3027 - accuracy: 0.1963 - val_loss: 2.1281 - val_accuracy: 0.2381\n",
      "Epoch 3/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 2.1072 - accuracy: 0.2590\n",
      "Epoch 00003: val_loss improved from 2.12806 to 1.92011, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.1065 - accuracy: 0.2596 - val_loss: 1.9201 - val_accuracy: 0.3406\n",
      "Epoch 4/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 1.9851 - accuracy: 0.3007\n",
      "Epoch 00004: val_loss improved from 1.92011 to 1.77915, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 1.9811 - accuracy: 0.2994 - val_loss: 1.7791 - val_accuracy: 0.3824\n",
      "Epoch 5/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 1.8552 - accuracy: 0.3478\n",
      "Epoch 00005: val_loss improved from 1.77915 to 1.62822, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 1.8527 - accuracy: 0.3489 - val_loss: 1.6282 - val_accuracy: 0.4264\n",
      "Epoch 6/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 1.7569 - accuracy: 0.3810\n",
      "Epoch 00006: val_loss improved from 1.62822 to 1.53800, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 1.7569 - accuracy: 0.3810 - val_loss: 1.5380 - val_accuracy: 0.5020\n",
      "Epoch 7/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 1.6464 - accuracy: 0.4312\n",
      "Epoch 00007: val_loss improved from 1.53800 to 1.40326, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 1.6457 - accuracy: 0.4302 - val_loss: 1.4033 - val_accuracy: 0.5381\n",
      "Epoch 8/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 1.5544 - accuracy: 0.4643\n",
      "Epoch 00008: val_loss improved from 1.40326 to 1.30746, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 1.5501 - accuracy: 0.4664 - val_loss: 1.3075 - val_accuracy: 0.5718\n",
      "Epoch 9/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 1.4786 - accuracy: 0.4899\n",
      "Epoch 00009: val_loss improved from 1.30746 to 1.23784, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 1.4770 - accuracy: 0.4895 - val_loss: 1.2378 - val_accuracy: 0.5919\n",
      "Epoch 10/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.3994 - accuracy: 0.5220\n",
      "Epoch 00010: val_loss improved from 1.23784 to 1.14020, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 1.3973 - accuracy: 0.5228 - val_loss: 1.1402 - val_accuracy: 0.6359\n",
      "Epoch 11/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 1.3208 - accuracy: 0.5527\n",
      "Epoch 00011: val_loss improved from 1.14020 to 1.08513, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 1.3192 - accuracy: 0.5533 - val_loss: 1.0851 - val_accuracy: 0.6520\n",
      "Epoch 12/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 1.2526 - accuracy: 0.5648\n",
      "Epoch 00012: val_loss improved from 1.08513 to 1.02287, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 1.2526 - accuracy: 0.5648 - val_loss: 1.0229 - val_accuracy: 0.6686\n",
      "Epoch 13/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 1.2243 - accuracy: 0.5895\n",
      "Epoch 00013: val_loss improved from 1.02287 to 0.97129, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 1.2239 - accuracy: 0.5887 - val_loss: 0.9713 - val_accuracy: 0.6772\n",
      "Epoch 14/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 1.1604 - accuracy: 0.6038\n",
      "Epoch 00014: val_loss improved from 0.97129 to 0.94543, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.1597 - accuracy: 0.6046 - val_loss: 0.9454 - val_accuracy: 0.7069\n",
      "Epoch 15/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 1.1189 - accuracy: 0.6205\n",
      "Epoch 00015: val_loss improved from 0.94543 to 0.87521, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 1.1139 - accuracy: 0.6223 - val_loss: 0.8752 - val_accuracy: 0.7281\n",
      "Epoch 16/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 1.0812 - accuracy: 0.6362\n",
      "Epoch 00016: val_loss improved from 0.87521 to 0.82949, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.0801 - accuracy: 0.6354 - val_loss: 0.8295 - val_accuracy: 0.7418\n",
      "Epoch 17/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.0293 - accuracy: 0.6496\n",
      "Epoch 00017: val_loss improved from 0.82949 to 0.81499, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 1.0316 - accuracy: 0.6488 - val_loss: 0.8150 - val_accuracy: 0.7476\n",
      "Epoch 18/100\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 0.9951 - accuracy: 0.6678\n",
      "Epoch 00018: val_loss improved from 0.81499 to 0.77333, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.9985 - accuracy: 0.6659 - val_loss: 0.7733 - val_accuracy: 0.7710\n",
      "Epoch 19/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.9679 - accuracy: 0.6779\n",
      "Epoch 00019: val_loss improved from 0.77333 to 0.75791, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9689 - accuracy: 0.6782 - val_loss: 0.7579 - val_accuracy: 0.7796\n",
      "Epoch 20/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9288 - accuracy: 0.6842\n",
      "Epoch 00020: val_loss improved from 0.75791 to 0.73002, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.9285 - accuracy: 0.6838 - val_loss: 0.7300 - val_accuracy: 0.7762\n",
      "Epoch 21/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.9173 - accuracy: 0.6962\n",
      "Epoch 00021: val_loss improved from 0.73002 to 0.71527, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.9173 - accuracy: 0.6962 - val_loss: 0.7153 - val_accuracy: 0.7728\n",
      "Epoch 22/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.8943 - accuracy: 0.6986\n",
      "Epoch 00022: val_loss improved from 0.71527 to 0.69131, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.8999 - accuracy: 0.6975 - val_loss: 0.6913 - val_accuracy: 0.7882\n",
      "Epoch 23/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8580 - accuracy: 0.7146\n",
      "Epoch 00023: val_loss improved from 0.69131 to 0.66136, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.8579 - accuracy: 0.7147 - val_loss: 0.6614 - val_accuracy: 0.7997\n",
      "Epoch 24/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.8579 - accuracy: 0.7090\n",
      "Epoch 00024: val_loss improved from 0.66136 to 0.65434, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.8562 - accuracy: 0.7094 - val_loss: 0.6543 - val_accuracy: 0.7934\n",
      "Epoch 25/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.8133 - accuracy: 0.7282\n",
      "Epoch 00025: val_loss improved from 0.65434 to 0.62581, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.8150 - accuracy: 0.7267 - val_loss: 0.6258 - val_accuracy: 0.8082\n",
      "Epoch 26/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.8055 - accuracy: 0.7266\n",
      "Epoch 00026: val_loss improved from 0.62581 to 0.59767, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.8037 - accuracy: 0.7273 - val_loss: 0.5977 - val_accuracy: 0.8082\n",
      "Epoch 27/100\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.7799 - accuracy: 0.7399\n",
      "Epoch 00027: val_loss improved from 0.59767 to 0.58621, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.7769 - accuracy: 0.7400 - val_loss: 0.5862 - val_accuracy: 0.8145\n",
      "Epoch 28/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.7622 - accuracy: 0.7445\n",
      "Epoch 00028: val_loss did not improve from 0.58621\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.7660 - accuracy: 0.7433 - val_loss: 0.6032 - val_accuracy: 0.8140\n",
      "Epoch 29/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.7756 - accuracy: 0.7392\n",
      "Epoch 00029: val_loss did not improve from 0.58621\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.7758 - accuracy: 0.7392 - val_loss: 0.6049 - val_accuracy: 0.8185\n",
      "Epoch 30/100\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.7427 - accuracy: 0.7485\n",
      "Epoch 00030: val_loss improved from 0.58621 to 0.58258, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.7398 - accuracy: 0.7482 - val_loss: 0.5826 - val_accuracy: 0.8271\n",
      "Epoch 31/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.7404 - accuracy: 0.7528\n",
      "Epoch 00031: val_loss improved from 0.58258 to 0.55985, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.7400 - accuracy: 0.7522 - val_loss: 0.5598 - val_accuracy: 0.8277\n",
      "Epoch 32/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.7051 - accuracy: 0.7595\n",
      "Epoch 00032: val_loss improved from 0.55985 to 0.55383, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.7054 - accuracy: 0.7595 - val_loss: 0.5538 - val_accuracy: 0.8277\n",
      "Epoch 33/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.6865 - accuracy: 0.7656\n",
      "Epoch 00033: val_loss improved from 0.55383 to 0.54075, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.6904 - accuracy: 0.7636 - val_loss: 0.5407 - val_accuracy: 0.8317\n",
      "Epoch 34/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.6839 - accuracy: 0.7673\n",
      "Epoch 00034: val_loss improved from 0.54075 to 0.52835, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.6814 - accuracy: 0.7685 - val_loss: 0.5283 - val_accuracy: 0.8346\n",
      "Epoch 35/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.6904 - accuracy: 0.7645\n",
      "Epoch 00035: val_loss did not improve from 0.52835\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.7636 - val_loss: 0.5300 - val_accuracy: 0.8386\n",
      "Epoch 36/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.6796 - accuracy: 0.7713\n",
      "Epoch 00036: val_loss did not improve from 0.52835\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.6797 - accuracy: 0.7702 - val_loss: 0.5368 - val_accuracy: 0.8277\n",
      "Epoch 37/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.6644 - accuracy: 0.7765\n",
      "Epoch 00037: val_loss improved from 0.52835 to 0.50998, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.6644 - accuracy: 0.7765 - val_loss: 0.5100 - val_accuracy: 0.8454\n",
      "Epoch 38/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.6631 - accuracy: 0.7768\n",
      "Epoch 00038: val_loss improved from 0.50998 to 0.50583, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.6631 - accuracy: 0.7768 - val_loss: 0.5058 - val_accuracy: 0.8460\n",
      "Epoch 39/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.6553 - accuracy: 0.7710\n",
      "Epoch 00039: val_loss improved from 0.50583 to 0.49702, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.6579 - accuracy: 0.7714 - val_loss: 0.4970 - val_accuracy: 0.8495\n",
      "Epoch 40/100\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 0.6497 - accuracy: 0.7793\n",
      "Epoch 00040: val_loss improved from 0.49702 to 0.49106, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.6503 - accuracy: 0.7795 - val_loss: 0.4911 - val_accuracy: 0.8477\n",
      "Epoch 41/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.6428 - accuracy: 0.7796\n",
      "Epoch 00041: val_loss did not improve from 0.49106\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6429 - accuracy: 0.7794 - val_loss: 0.5135 - val_accuracy: 0.8477\n",
      "Epoch 42/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.6220 - accuracy: 0.7898\n",
      "Epoch 00042: val_loss improved from 0.49106 to 0.48345, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.6221 - accuracy: 0.7906 - val_loss: 0.4835 - val_accuracy: 0.8489\n",
      "Epoch 43/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.6324 - accuracy: 0.7883\n",
      "Epoch 00043: val_loss did not improve from 0.48345\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.6281 - accuracy: 0.7894 - val_loss: 0.5002 - val_accuracy: 0.8432\n",
      "Epoch 44/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.6382 - accuracy: 0.7817\n",
      "Epoch 00044: val_loss did not improve from 0.48345\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6368 - accuracy: 0.7811 - val_loss: 0.4931 - val_accuracy: 0.8586\n",
      "Epoch 45/100\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.6035 - accuracy: 0.7988\n",
      "Epoch 00045: val_loss improved from 0.48345 to 0.47438, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6090 - accuracy: 0.7980 - val_loss: 0.4744 - val_accuracy: 0.8598\n",
      "Epoch 46/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.6082 - accuracy: 0.7926\n",
      "Epoch 00046: val_loss improved from 0.47438 to 0.46973, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6089 - accuracy: 0.7920 - val_loss: 0.4697 - val_accuracy: 0.8575\n",
      "Epoch 47/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.6032 - accuracy: 0.7955\n",
      "Epoch 00047: val_loss improved from 0.46973 to 0.45707, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.6036 - accuracy: 0.7958 - val_loss: 0.4571 - val_accuracy: 0.8598\n",
      "Epoch 48/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.6088 - accuracy: 0.7970\n",
      "Epoch 00048: val_loss did not improve from 0.45707\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.6097 - accuracy: 0.7967 - val_loss: 0.4714 - val_accuracy: 0.8552\n",
      "Epoch 49/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.5820 - accuracy: 0.7993\n",
      "Epoch 00049: val_loss did not improve from 0.45707\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5837 - accuracy: 0.7990 - val_loss: 0.4722 - val_accuracy: 0.8655\n",
      "Epoch 50/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.6015 - accuracy: 0.8003\n",
      "Epoch 00050: val_loss did not improve from 0.45707\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6021 - accuracy: 0.7993 - val_loss: 0.4839 - val_accuracy: 0.8563\n",
      "Epoch 51/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.5862 - accuracy: 0.8017\n",
      "Epoch 00051: val_loss did not improve from 0.45707\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5846 - accuracy: 0.8017 - val_loss: 0.4596 - val_accuracy: 0.8535\n",
      "Epoch 52/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.5894 - accuracy: 0.8026\n",
      "Epoch 00052: val_loss did not improve from 0.45707\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.5892 - accuracy: 0.8024 - val_loss: 0.4753 - val_accuracy: 0.8672\n",
      "Epoch 53/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.5743 - accuracy: 0.8064\n",
      "Epoch 00053: val_loss did not improve from 0.45707\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.5774 - accuracy: 0.8053 - val_loss: 0.4606 - val_accuracy: 0.8649\n",
      "Epoch 54/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.5720 - accuracy: 0.8006\n",
      "Epoch 00054: val_loss did not improve from 0.45707\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5731 - accuracy: 0.8004 - val_loss: 0.4779 - val_accuracy: 0.8689\n",
      "Epoch 55/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.5929 - accuracy: 0.7977\n",
      "Epoch 00055: val_loss did not improve from 0.45707\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5924 - accuracy: 0.7974 - val_loss: 0.4681 - val_accuracy: 0.8672\n",
      "Epoch 56/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.5775 - accuracy: 0.8046\n",
      "Epoch 00056: val_loss did not improve from 0.45707\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.5800 - accuracy: 0.8031 - val_loss: 0.4792 - val_accuracy: 0.8592\n",
      "Epoch 57/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.6041 - accuracy: 0.7980\n",
      "Epoch 00057: val_loss improved from 0.45707 to 0.45617, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6037 - accuracy: 0.7983 - val_loss: 0.4562 - val_accuracy: 0.8678\n",
      "Epoch 58/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.5707 - accuracy: 0.8045\n",
      "Epoch 00058: val_loss did not improve from 0.45617\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.5658 - accuracy: 0.8057 - val_loss: 0.4569 - val_accuracy: 0.8706\n",
      "Epoch 59/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.5674 - accuracy: 0.8115\n",
      "Epoch 00059: val_loss improved from 0.45617 to 0.45382, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.5680 - accuracy: 0.8112 - val_loss: 0.4538 - val_accuracy: 0.8632\n",
      "Epoch 60/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.5676 - accuracy: 0.8119\n",
      "Epoch 00060: val_loss improved from 0.45382 to 0.45250, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.5676 - accuracy: 0.8119 - val_loss: 0.4525 - val_accuracy: 0.8603\n",
      "Epoch 61/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.5556 - accuracy: 0.8135\n",
      "Epoch 00061: val_loss improved from 0.45250 to 0.43771, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5565 - accuracy: 0.8133 - val_loss: 0.4377 - val_accuracy: 0.8632\n",
      "Epoch 62/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.5534 - accuracy: 0.8109\n",
      "Epoch 00062: val_loss improved from 0.43771 to 0.43283, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5548 - accuracy: 0.8106 - val_loss: 0.4328 - val_accuracy: 0.8689\n",
      "Epoch 63/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.5768 - accuracy: 0.8073\n",
      "Epoch 00063: val_loss did not improve from 0.43283\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5754 - accuracy: 0.8080 - val_loss: 0.4518 - val_accuracy: 0.8603\n",
      "Epoch 64/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.5439 - accuracy: 0.8151\n",
      "Epoch 00064: val_loss did not improve from 0.43283\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5437 - accuracy: 0.8152 - val_loss: 0.4534 - val_accuracy: 0.8666\n",
      "Epoch 65/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.5629 - accuracy: 0.8139\n",
      "Epoch 00065: val_loss did not improve from 0.43283\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5641 - accuracy: 0.8136 - val_loss: 0.4425 - val_accuracy: 0.8724\n",
      "Epoch 66/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.5494 - accuracy: 0.8135\n",
      "Epoch 00066: val_loss did not improve from 0.43283\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5488 - accuracy: 0.8137 - val_loss: 0.4463 - val_accuracy: 0.8735\n",
      "Epoch 67/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.5456 - accuracy: 0.8146\n",
      "Epoch 00067: val_loss did not improve from 0.43283\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5521 - accuracy: 0.8140 - val_loss: 0.4573 - val_accuracy: 0.8620\n",
      "Epoch 68/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.5404 - accuracy: 0.8173\n",
      "Epoch 00068: val_loss did not improve from 0.43283\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5444 - accuracy: 0.8168 - val_loss: 0.4450 - val_accuracy: 0.8735\n",
      "Epoch 69/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.5537 - accuracy: 0.8150\n",
      "Epoch 00069: val_loss did not improve from 0.43283\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.5513 - accuracy: 0.8163 - val_loss: 0.4550 - val_accuracy: 0.8666\n",
      "Epoch 70/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.5380 - accuracy: 0.8207\n",
      "Epoch 00070: val_loss did not improve from 0.43283\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5364 - accuracy: 0.8215 - val_loss: 0.4420 - val_accuracy: 0.8655\n",
      "Epoch 71/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.5351 - accuracy: 0.8199\n",
      "Epoch 00071: val_loss did not improve from 0.43283\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5359 - accuracy: 0.8200 - val_loss: 0.4665 - val_accuracy: 0.8609\n",
      "Epoch 72/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.5192 - accuracy: 0.8219\n",
      "Epoch 00072: val_loss did not improve from 0.43283\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5175 - accuracy: 0.8230 - val_loss: 0.4652 - val_accuracy: 0.8615\n",
      "Epoch 73/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.5351 - accuracy: 0.8227\n",
      "Epoch 00073: val_loss did not improve from 0.43283\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5345 - accuracy: 0.8236 - val_loss: 0.4709 - val_accuracy: 0.8626\n",
      "Epoch 74/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.5026 - accuracy: 0.8276\n",
      "Epoch 00074: val_loss did not improve from 0.43283\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5016 - accuracy: 0.8279 - val_loss: 0.4534 - val_accuracy: 0.8689\n",
      "Epoch 75/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.5270 - accuracy: 0.8265\n",
      "Epoch 00075: val_loss did not improve from 0.43283\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.5249 - accuracy: 0.8272 - val_loss: 0.4461 - val_accuracy: 0.8724\n",
      "Epoch 76/100\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 0.5318 - accuracy: 0.8242\n",
      "Epoch 00076: val_loss did not improve from 0.43283\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.5296 - accuracy: 0.8255 - val_loss: 0.4546 - val_accuracy: 0.8701\n",
      "Epoch 77/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.5040 - accuracy: 0.8307\n",
      "Epoch 00077: val_loss did not improve from 0.43283\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5065 - accuracy: 0.8295 - val_loss: 0.4406 - val_accuracy: 0.8769\n",
      "Epoch 78/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.5151 - accuracy: 0.8228\n",
      "Epoch 00078: val_loss did not improve from 0.43283\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.5158 - accuracy: 0.8215 - val_loss: 0.4406 - val_accuracy: 0.8701\n",
      "Epoch 79/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.5275 - accuracy: 0.8249\n",
      "Epoch 00079: val_loss did not improve from 0.43283\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.5266 - accuracy: 0.8253 - val_loss: 0.4565 - val_accuracy: 0.8758\n",
      "Epoch 80/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.4884 - accuracy: 0.8374\n",
      "Epoch 00080: val_loss did not improve from 0.43283\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.4869 - accuracy: 0.8375 - val_loss: 0.4375 - val_accuracy: 0.8661\n",
      "Epoch 81/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.5088 - accuracy: 0.8347\n",
      "Epoch 00081: val_loss improved from 0.43283 to 0.41953, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5091 - accuracy: 0.8341 - val_loss: 0.4195 - val_accuracy: 0.8735\n",
      "Epoch 82/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.4768 - accuracy: 0.8395\n",
      "Epoch 00082: val_loss did not improve from 0.41953\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.4788 - accuracy: 0.8394 - val_loss: 0.4253 - val_accuracy: 0.8775\n",
      "Epoch 83/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.5310 - accuracy: 0.8246\n",
      "Epoch 00083: val_loss improved from 0.41953 to 0.41296, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5380 - accuracy: 0.8220 - val_loss: 0.4130 - val_accuracy: 0.8781\n",
      "Epoch 84/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.5076 - accuracy: 0.8310\n",
      "Epoch 00084: val_loss did not improve from 0.41296\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5070 - accuracy: 0.8311 - val_loss: 0.4277 - val_accuracy: 0.8741\n",
      "Epoch 85/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.5095 - accuracy: 0.8314\n",
      "Epoch 00085: val_loss did not improve from 0.41296\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.5092 - accuracy: 0.8315 - val_loss: 0.4178 - val_accuracy: 0.8712\n",
      "Epoch 86/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.5249 - accuracy: 0.8281\n",
      "Epoch 00086: val_loss did not improve from 0.41296\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5233 - accuracy: 0.8288 - val_loss: 0.4307 - val_accuracy: 0.8695\n",
      "Epoch 87/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.4766 - accuracy: 0.8346\n",
      "Epoch 00087: val_loss did not improve from 0.41296\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.4786 - accuracy: 0.8342 - val_loss: 0.4382 - val_accuracy: 0.8661\n",
      "Epoch 88/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.5003 - accuracy: 0.8322\n",
      "Epoch 00088: val_loss improved from 0.41296 to 0.40746, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5024 - accuracy: 0.8322 - val_loss: 0.4075 - val_accuracy: 0.8821\n",
      "Epoch 89/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.4981 - accuracy: 0.8362\n",
      "Epoch 00089: val_loss improved from 0.40746 to 0.39784, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.5039 - accuracy: 0.8346 - val_loss: 0.3978 - val_accuracy: 0.8855\n",
      "Epoch 90/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.4938 - accuracy: 0.8369\n",
      "Epoch 00090: val_loss did not improve from 0.39784\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.4951 - accuracy: 0.8365 - val_loss: 0.4116 - val_accuracy: 0.8832\n",
      "Epoch 91/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.4869 - accuracy: 0.8370\n",
      "Epoch 00091: val_loss did not improve from 0.39784\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.4864 - accuracy: 0.8369 - val_loss: 0.4080 - val_accuracy: 0.8832\n",
      "Epoch 92/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.4915 - accuracy: 0.8370\n",
      "Epoch 00092: val_loss did not improve from 0.39784\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.4901 - accuracy: 0.8374 - val_loss: 0.4048 - val_accuracy: 0.8895\n",
      "Epoch 93/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.4928 - accuracy: 0.8342\n",
      "Epoch 00093: val_loss did not improve from 0.39784\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.4925 - accuracy: 0.8341 - val_loss: 0.4131 - val_accuracy: 0.8827\n",
      "Epoch 94/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.5016 - accuracy: 0.8302\n",
      "Epoch 00094: val_loss did not improve from 0.39784\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.5032 - accuracy: 0.8295 - val_loss: 0.4177 - val_accuracy: 0.8838\n",
      "Epoch 95/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.5241 - accuracy: 0.8303\n",
      "Epoch 00095: val_loss did not improve from 0.39784\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.5257 - accuracy: 0.8295 - val_loss: 0.4124 - val_accuracy: 0.8781\n",
      "Epoch 96/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.4729 - accuracy: 0.8422\n",
      "Epoch 00096: val_loss did not improve from 0.39784\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.4777 - accuracy: 0.8407 - val_loss: 0.4341 - val_accuracy: 0.8752\n",
      "Epoch 97/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.4765 - accuracy: 0.8427\n",
      "Epoch 00097: val_loss did not improve from 0.39784\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.4793 - accuracy: 0.8419 - val_loss: 0.4250 - val_accuracy: 0.8781\n",
      "Epoch 98/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.4834 - accuracy: 0.8419\n",
      "Epoch 00098: val_loss did not improve from 0.39784\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.4834 - accuracy: 0.8419 - val_loss: 0.4378 - val_accuracy: 0.8832\n",
      "Epoch 99/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.4774 - accuracy: 0.8438\n",
      "Epoch 00099: val_loss did not improve from 0.39784\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.4766 - accuracy: 0.8441 - val_loss: 0.4190 - val_accuracy: 0.8884\n",
      "Epoch 100/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.4689 - accuracy: 0.8430\n",
      "Epoch 00100: val_loss did not improve from 0.39784\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.4687 - accuracy: 0.8438 - val_loss: 0.4191 - val_accuracy: 0.8901\n",
      "Training completed in time: 0:01:43.954661\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.hdf5',\n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=num_batch_size,\n",
    "          epochs=num_epochs,\n",
    "          validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(f'Training completed in time: {duration}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acurracy: 0.9454545378684998\n",
      "Training acurracy: 0.8900973200798035\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(f'Training acurracy: {score[1]}')\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'Training acurracy: {score[1]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def extract_feature(file_name):\n",
    "\n",
    "    try:\n",
    "        audio_data, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None, None\n",
    "\n",
    "    return np.array([mfccsscaled])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def print_prediction(file_name):\n",
    "    prediction_feature = extract_feature(file_name)\n",
    "\n",
    "    predicted_vector = np.argmax(model.predict(prediction_feature))\n",
    "    predicted_class = le.inverse_transform(predicted_vector)\n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n')\n",
    "\n",
    "    predicted_proba_vector = model.predict_proba(prediction_feature)\n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)):\n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Validation with samples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape () instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\MASTER~1\\AppData\\Local\\Temp/ipykernel_21372/1923807724.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mfile_name\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'samples/100852-0-0-0.wav'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mprint_prediction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mC:\\Users\\MASTER~1\\AppData\\Local\\Temp/ipykernel_21372/4258789425.py\u001B[0m in \u001B[0;36mprint_prediction\u001B[1;34m(file_name)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[0mpredicted_vector\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0margmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprediction_feature\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m     \u001B[0mpredicted_class\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mle\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minverse_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpredicted_vector\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"The predicted class is:\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpredicted_class\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'\\n'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001B[0m in \u001B[0;36minverse_transform\u001B[1;34m(self, y)\u001B[0m\n\u001B[0;32m    152\u001B[0m         \"\"\"\n\u001B[0;32m    153\u001B[0m         \u001B[0mcheck_is_fitted\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 154\u001B[1;33m         \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcolumn_or_1d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwarn\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    155\u001B[0m         \u001B[1;31m# inverse transform of empty array is empty array\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    156\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0m_num_samples\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcolumn_or_1d\u001B[1;34m(y, warn)\u001B[0m\n\u001B[0;32m   1022\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mravel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1023\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1024\u001B[1;33m     raise ValueError(\n\u001B[0m\u001B[0;32m   1025\u001B[0m         \u001B[1;34m\"y should be a 1d array, got an array of shape {} instead.\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1026\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: y should be a 1d array, got an array of shape () instead."
     ]
    }
   ],
   "source": [
    "file_name = 'samples/100852-0-0-0.wav'\n",
    "print_prediction(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}