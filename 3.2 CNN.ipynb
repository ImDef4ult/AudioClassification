{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "max_pad_len = 174\n",
    "\n",
    "def extract_features(file_name):\n",
    "\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None\n",
    "\n",
    "    return mfccs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3553it [02:29, 23.69it/s]C:\\Users\\masterdoc\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1323\n",
      "  warnings.warn(\n",
      "8324it [05:37, 34.34it/s]C:\\Users\\masterdoc\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1103\n",
      "  warnings.warn(\n",
      "C:\\Users\\masterdoc\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1523\n",
      "  warnings.warn(\n",
      "8732it [05:52, 24.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  8732  files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the full UrbanSound dataset\n",
    "full_dataset_path = 'Data/UrbanSound8K/audio'\n",
    "metadata = pd.read_csv('Data/UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "features = []\n",
    "\n",
    "# Iterate through each sound file and extract the features\n",
    "for index, row in tqdm(metadata.iterrows()):\n",
    "\n",
    "    file_name = os.path.join(os.path.abspath(full_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "\n",
    "    class_label = row[\"class\"]\n",
    "    data = extract_features(file_name)\n",
    "\n",
    "    features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe\n",
    "features_df = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(features_df), ' files')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(features_df.feature.tolist())\n",
    "y = np.array(features_df.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y))\n",
    "\n",
    "# split the dataset\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, GlobalAveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "num_rows = 40\n",
    "num_columns = 174\n",
    "num_channels = 1\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compile the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 39, 173, 16)       80        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 19, 86, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 19, 86, 16)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 18, 85, 32)        2080      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 9, 42, 32)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 9, 42, 32)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 41, 64)         8256      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 20, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 20, 64)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 3, 19, 128)        32896     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 9, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 9, 128)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,602\n",
      "Trainable params: 44,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "55/55 [==============================] - 5s 5ms/step - loss: 9.4592 - accuracy: 0.1546\n",
      "Pre-training accuracy: 15.4551%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary\n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "num_epochs = 72\n",
    "num_batch_size = 256\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='saved_models_CNN/weights.best.basic_cnn.hdf5',\n",
    "    verbose=1,\n",
    "    save_best_only=True\n",
    ")\n",
    "start = datetime.now()\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(f'Trained the model in: {duration}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 5.3937 - accuracy: 0.1545\n",
      "Epoch 00001: val_loss improved from inf to 2.05193, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 3s 40ms/step - loss: 5.3937 - accuracy: 0.1545 - val_loss: 2.0519 - val_accuracy: 0.2793\n",
      "Epoch 2/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.9966 - accuracy: 0.2988\n",
      "Epoch 00002: val_loss improved from 2.05193 to 1.96140, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.9966 - accuracy: 0.2988 - val_loss: 1.9614 - val_accuracy: 0.3532\n",
      "Epoch 3/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.7432 - accuracy: 0.3907\n",
      "Epoch 00003: val_loss improved from 1.96140 to 1.82247, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.7432 - accuracy: 0.3907 - val_loss: 1.8225 - val_accuracy: 0.4110\n",
      "Epoch 4/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.5884 - accuracy: 0.4520\n",
      "Epoch 00004: val_loss improved from 1.82247 to 1.71823, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.5884 - accuracy: 0.4520 - val_loss: 1.7182 - val_accuracy: 0.4213\n",
      "Epoch 5/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4866 - accuracy: 0.4810\n",
      "Epoch 00005: val_loss improved from 1.71823 to 1.64071, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.4866 - accuracy: 0.4810 - val_loss: 1.6407 - val_accuracy: 0.4533\n",
      "Epoch 6/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4127 - accuracy: 0.5089\n",
      "Epoch 00006: val_loss improved from 1.64071 to 1.56033, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.4127 - accuracy: 0.5089 - val_loss: 1.5603 - val_accuracy: 0.4837\n",
      "Epoch 7/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3390 - accuracy: 0.5286\n",
      "Epoch 00007: val_loss improved from 1.56033 to 1.47306, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.3390 - accuracy: 0.5286 - val_loss: 1.4731 - val_accuracy: 0.5232\n",
      "Epoch 8/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2902 - accuracy: 0.5546\n",
      "Epoch 00008: val_loss improved from 1.47306 to 1.40350, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.2902 - accuracy: 0.5546 - val_loss: 1.4035 - val_accuracy: 0.5718\n",
      "Epoch 9/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2337 - accuracy: 0.5709\n",
      "Epoch 00009: val_loss improved from 1.40350 to 1.37766, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.2337 - accuracy: 0.5709 - val_loss: 1.3777 - val_accuracy: 0.5318\n",
      "Epoch 10/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1521 - accuracy: 0.5967\n",
      "Epoch 00010: val_loss improved from 1.37766 to 1.32361, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1521 - accuracy: 0.5967 - val_loss: 1.3236 - val_accuracy: 0.5678\n",
      "Epoch 11/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1157 - accuracy: 0.6096\n",
      "Epoch 00011: val_loss improved from 1.32361 to 1.25016, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.1157 - accuracy: 0.6096 - val_loss: 1.2502 - val_accuracy: 0.5890\n",
      "Epoch 12/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0697 - accuracy: 0.6273\n",
      "Epoch 00012: val_loss improved from 1.25016 to 1.21003, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.0697 - accuracy: 0.6273 - val_loss: 1.2100 - val_accuracy: 0.5947\n",
      "Epoch 13/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0279 - accuracy: 0.6399\n",
      "Epoch 00013: val_loss improved from 1.21003 to 1.16631, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.0279 - accuracy: 0.6399 - val_loss: 1.1663 - val_accuracy: 0.6153\n",
      "Epoch 14/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9625 - accuracy: 0.6667\n",
      "Epoch 00014: val_loss improved from 1.16631 to 1.12911, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9625 - accuracy: 0.6667 - val_loss: 1.1291 - val_accuracy: 0.6153\n",
      "Epoch 15/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9419 - accuracy: 0.6742\n",
      "Epoch 00015: val_loss improved from 1.12911 to 1.11687, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.9419 - accuracy: 0.6742 - val_loss: 1.1169 - val_accuracy: 0.6228\n",
      "Epoch 16/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9211 - accuracy: 0.6746\n",
      "Epoch 00016: val_loss improved from 1.11687 to 1.05020, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.9211 - accuracy: 0.6746 - val_loss: 1.0502 - val_accuracy: 0.6548\n",
      "Epoch 17/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9003 - accuracy: 0.6945\n",
      "Epoch 00017: val_loss improved from 1.05020 to 1.02806, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.9003 - accuracy: 0.6945 - val_loss: 1.0281 - val_accuracy: 0.6560\n",
      "Epoch 18/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8791 - accuracy: 0.6959\n",
      "Epoch 00018: val_loss improved from 1.02806 to 0.97177, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8791 - accuracy: 0.6959 - val_loss: 0.9718 - val_accuracy: 0.6817\n",
      "Epoch 19/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8352 - accuracy: 0.7101\n",
      "Epoch 00019: val_loss did not improve from 0.97177\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.8352 - accuracy: 0.7101 - val_loss: 0.9829 - val_accuracy: 0.6777\n",
      "Epoch 20/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8203 - accuracy: 0.7200\n",
      "Epoch 00020: val_loss improved from 0.97177 to 0.93403, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.8203 - accuracy: 0.7200 - val_loss: 0.9340 - val_accuracy: 0.6812\n",
      "Epoch 21/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7864 - accuracy: 0.7268\n",
      "Epoch 00021: val_loss did not improve from 0.93403\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.7864 - accuracy: 0.7268 - val_loss: 0.9475 - val_accuracy: 0.6852\n",
      "Epoch 22/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7676 - accuracy: 0.7364\n",
      "Epoch 00022: val_loss did not improve from 0.93403\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.7676 - accuracy: 0.7364 - val_loss: 0.9430 - val_accuracy: 0.6857\n",
      "Epoch 23/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7427 - accuracy: 0.7487\n",
      "Epoch 00023: val_loss improved from 0.93403 to 0.88787, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.7427 - accuracy: 0.7487 - val_loss: 0.8879 - val_accuracy: 0.6972\n",
      "Epoch 24/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7162 - accuracy: 0.7601\n",
      "Epoch 00024: val_loss improved from 0.88787 to 0.86457, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.7162 - accuracy: 0.7601 - val_loss: 0.8646 - val_accuracy: 0.7178\n",
      "Epoch 25/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7097 - accuracy: 0.7539\n",
      "Epoch 00025: val_loss improved from 0.86457 to 0.81200, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7097 - accuracy: 0.7539 - val_loss: 0.8120 - val_accuracy: 0.7344\n",
      "Epoch 26/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.7613\n",
      "Epoch 00026: val_loss improved from 0.81200 to 0.80646, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.6935 - accuracy: 0.7613 - val_loss: 0.8065 - val_accuracy: 0.7384\n",
      "Epoch 27/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.6828 - accuracy: 0.7709\n",
      "Epoch 00027: val_loss did not improve from 0.80646\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.6828 - accuracy: 0.7709 - val_loss: 0.8102 - val_accuracy: 0.7373\n",
      "Epoch 28/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.6574 - accuracy: 0.7792\n",
      "Epoch 00028: val_loss improved from 0.80646 to 0.79604, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.6574 - accuracy: 0.7792 - val_loss: 0.7960 - val_accuracy: 0.7350\n",
      "Epoch 29/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.6374 - accuracy: 0.7832\n",
      "Epoch 00029: val_loss improved from 0.79604 to 0.73140, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.6374 - accuracy: 0.7832 - val_loss: 0.7314 - val_accuracy: 0.7642\n",
      "Epoch 30/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.6221 - accuracy: 0.7853\n",
      "Epoch 00030: val_loss did not improve from 0.73140\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.6221 - accuracy: 0.7853 - val_loss: 0.7584 - val_accuracy: 0.7567\n",
      "Epoch 31/72\n",
      "25/28 [=========================>....] - ETA: 0s - loss: 0.6057 - accuracy: 0.7937\n",
      "Epoch 00031: val_loss did not improve from 0.73140\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.6014 - accuracy: 0.7947 - val_loss: 0.7328 - val_accuracy: 0.7533\n",
      "Epoch 32/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.5820 - accuracy: 0.8014\n",
      "Epoch 00032: val_loss improved from 0.73140 to 0.70564, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.5820 - accuracy: 0.8014 - val_loss: 0.7056 - val_accuracy: 0.7733\n",
      "Epoch 33/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.5739 - accuracy: 0.8086\n",
      "Epoch 00033: val_loss improved from 0.70564 to 0.69032, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.5739 - accuracy: 0.8086 - val_loss: 0.6903 - val_accuracy: 0.7653\n",
      "Epoch 34/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.5534 - accuracy: 0.8116\n",
      "Epoch 00034: val_loss improved from 0.69032 to 0.65573, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.5534 - accuracy: 0.8116 - val_loss: 0.6557 - val_accuracy: 0.7899\n",
      "Epoch 35/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.5607 - accuracy: 0.8172\n",
      "Epoch 00035: val_loss improved from 0.65573 to 0.64220, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.5607 - accuracy: 0.8172 - val_loss: 0.6422 - val_accuracy: 0.7974\n",
      "Epoch 36/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.5355 - accuracy: 0.8189\n",
      "Epoch 00036: val_loss did not improve from 0.64220\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.5355 - accuracy: 0.8189 - val_loss: 0.6575 - val_accuracy: 0.7831\n",
      "Epoch 37/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.5166 - accuracy: 0.8256\n",
      "Epoch 00037: val_loss improved from 0.64220 to 0.60449, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.5166 - accuracy: 0.8256 - val_loss: 0.6045 - val_accuracy: 0.8042\n",
      "Epoch 38/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.5204 - accuracy: 0.8220\n",
      "Epoch 00038: val_loss did not improve from 0.60449\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.5204 - accuracy: 0.8220 - val_loss: 0.6181 - val_accuracy: 0.7985\n",
      "Epoch 39/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.5080 - accuracy: 0.8324\n",
      "Epoch 00039: val_loss improved from 0.60449 to 0.58255, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.5080 - accuracy: 0.8324 - val_loss: 0.5825 - val_accuracy: 0.8168\n",
      "Epoch 40/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4920 - accuracy: 0.8374\n",
      "Epoch 00040: val_loss improved from 0.58255 to 0.57126, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.4920 - accuracy: 0.8374 - val_loss: 0.5713 - val_accuracy: 0.8208\n",
      "Epoch 41/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4838 - accuracy: 0.8381\n",
      "Epoch 00041: val_loss improved from 0.57126 to 0.55114, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.4838 - accuracy: 0.8381 - val_loss: 0.5511 - val_accuracy: 0.8248\n",
      "Epoch 42/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4711 - accuracy: 0.8434\n",
      "Epoch 00042: val_loss improved from 0.55114 to 0.53451, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.4711 - accuracy: 0.8434 - val_loss: 0.5345 - val_accuracy: 0.8392\n",
      "Epoch 43/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4605 - accuracy: 0.8451\n",
      "Epoch 00043: val_loss did not improve from 0.53451\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.4605 - accuracy: 0.8451 - val_loss: 0.5454 - val_accuracy: 0.8248\n",
      "Epoch 44/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4532 - accuracy: 0.8470\n",
      "Epoch 00044: val_loss did not improve from 0.53451\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.4532 - accuracy: 0.8470 - val_loss: 0.5517 - val_accuracy: 0.8283\n",
      "Epoch 45/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4515 - accuracy: 0.8438\n",
      "Epoch 00045: val_loss improved from 0.53451 to 0.50673, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.4515 - accuracy: 0.8438 - val_loss: 0.5067 - val_accuracy: 0.8443\n",
      "Epoch 46/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4460 - accuracy: 0.8482\n",
      "Epoch 00046: val_loss did not improve from 0.50673\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.4460 - accuracy: 0.8482 - val_loss: 0.5499 - val_accuracy: 0.8226\n",
      "Epoch 47/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4329 - accuracy: 0.8510\n",
      "Epoch 00047: val_loss did not improve from 0.50673\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.4329 - accuracy: 0.8510 - val_loss: 0.5301 - val_accuracy: 0.8346\n",
      "Epoch 48/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4262 - accuracy: 0.8570\n",
      "Epoch 00048: val_loss did not improve from 0.50673\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.4262 - accuracy: 0.8570 - val_loss: 0.5222 - val_accuracy: 0.8271\n",
      "Epoch 49/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4147 - accuracy: 0.8601\n",
      "Epoch 00049: val_loss improved from 0.50673 to 0.49526, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.4147 - accuracy: 0.8601 - val_loss: 0.4953 - val_accuracy: 0.8432\n",
      "Epoch 50/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4086 - accuracy: 0.8597\n",
      "Epoch 00050: val_loss improved from 0.49526 to 0.47675, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.4086 - accuracy: 0.8597 - val_loss: 0.4767 - val_accuracy: 0.8540\n",
      "Epoch 51/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3957 - accuracy: 0.8660\n",
      "Epoch 00051: val_loss did not improve from 0.47675\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.3957 - accuracy: 0.8660 - val_loss: 0.5055 - val_accuracy: 0.8329\n",
      "Epoch 52/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3852 - accuracy: 0.8684\n",
      "Epoch 00052: val_loss improved from 0.47675 to 0.44152, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.3852 - accuracy: 0.8684 - val_loss: 0.4415 - val_accuracy: 0.8689\n",
      "Epoch 53/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.8710\n",
      "Epoch 00053: val_loss did not improve from 0.44152\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.3816 - accuracy: 0.8710 - val_loss: 0.4906 - val_accuracy: 0.8477\n",
      "Epoch 54/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3912 - accuracy: 0.8664\n",
      "Epoch 00054: val_loss did not improve from 0.44152\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.3912 - accuracy: 0.8664 - val_loss: 0.4938 - val_accuracy: 0.8414\n",
      "Epoch 55/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3631 - accuracy: 0.8759\n",
      "Epoch 00055: val_loss did not improve from 0.44152\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.3631 - accuracy: 0.8759 - val_loss: 0.4544 - val_accuracy: 0.8638\n",
      "Epoch 56/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3677 - accuracy: 0.8737\n",
      "Epoch 00056: val_loss improved from 0.44152 to 0.42250, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.3677 - accuracy: 0.8737 - val_loss: 0.4225 - val_accuracy: 0.8638\n",
      "Epoch 57/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3534 - accuracy: 0.8767\n",
      "Epoch 00057: val_loss did not improve from 0.42250\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.3534 - accuracy: 0.8767 - val_loss: 0.4247 - val_accuracy: 0.8558\n",
      "Epoch 58/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3524 - accuracy: 0.8787\n",
      "Epoch 00058: val_loss improved from 0.42250 to 0.40528, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.3524 - accuracy: 0.8787 - val_loss: 0.4053 - val_accuracy: 0.8672\n",
      "Epoch 59/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3464 - accuracy: 0.8789\n",
      "Epoch 00059: val_loss did not improve from 0.40528\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.3464 - accuracy: 0.8789 - val_loss: 0.4403 - val_accuracy: 0.8552\n",
      "Epoch 60/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3493 - accuracy: 0.8803\n",
      "Epoch 00060: val_loss did not improve from 0.40528\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.3493 - accuracy: 0.8803 - val_loss: 0.4143 - val_accuracy: 0.8701\n",
      "Epoch 61/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3380 - accuracy: 0.8865\n",
      "Epoch 00061: val_loss did not improve from 0.40528\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.3380 - accuracy: 0.8865 - val_loss: 0.4251 - val_accuracy: 0.8655\n",
      "Epoch 62/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3402 - accuracy: 0.8823\n",
      "Epoch 00062: val_loss did not improve from 0.40528\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.3402 - accuracy: 0.8823 - val_loss: 0.4142 - val_accuracy: 0.8666\n",
      "Epoch 63/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3206 - accuracy: 0.8942\n",
      "Epoch 00063: val_loss improved from 0.40528 to 0.40231, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.3206 - accuracy: 0.8942 - val_loss: 0.4023 - val_accuracy: 0.8718\n",
      "Epoch 64/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3137 - accuracy: 0.8929\n",
      "Epoch 00064: val_loss did not improve from 0.40231\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.3137 - accuracy: 0.8929 - val_loss: 0.4379 - val_accuracy: 0.8586\n",
      "Epoch 65/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3092 - accuracy: 0.8948\n",
      "Epoch 00065: val_loss improved from 0.40231 to 0.37732, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.3092 - accuracy: 0.8948 - val_loss: 0.3773 - val_accuracy: 0.8867\n",
      "Epoch 66/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3196 - accuracy: 0.8935\n",
      "Epoch 00066: val_loss did not improve from 0.37732\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.3196 - accuracy: 0.8935 - val_loss: 0.3791 - val_accuracy: 0.8838\n",
      "Epoch 67/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3153 - accuracy: 0.8938\n",
      "Epoch 00067: val_loss did not improve from 0.37732\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.3153 - accuracy: 0.8938 - val_loss: 0.3810 - val_accuracy: 0.8775\n",
      "Epoch 68/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.2960 - accuracy: 0.8979\n",
      "Epoch 00068: val_loss did not improve from 0.37732\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.2960 - accuracy: 0.8979 - val_loss: 0.3785 - val_accuracy: 0.8786\n",
      "Epoch 69/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3008 - accuracy: 0.8951\n",
      "Epoch 00069: val_loss improved from 0.37732 to 0.35685, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.3008 - accuracy: 0.8951 - val_loss: 0.3568 - val_accuracy: 0.8855\n",
      "Epoch 70/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.2821 - accuracy: 0.9038\n",
      "Epoch 00070: val_loss did not improve from 0.35685\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.2821 - accuracy: 0.9038 - val_loss: 0.3656 - val_accuracy: 0.8844\n",
      "Epoch 71/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.2888 - accuracy: 0.8958\n",
      "Epoch 00071: val_loss improved from 0.35685 to 0.33914, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.2888 - accuracy: 0.8958 - val_loss: 0.3391 - val_accuracy: 0.8952\n",
      "Epoch 72/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.2915 - accuracy: 0.9032\n",
      "Epoch 00072: val_loss did not improve from 0.33914\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.2915 - accuracy: 0.9032 - val_loss: 0.3855 - val_accuracy: 0.8798\n",
      "Trained the model in: 0:00:52.308492\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9292770028114319\n",
      "Testing Accuracy:  0.8797939419746399\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def print_prediction(file_name):\n",
    "    prediction_feature = extract_features(file_name)\n",
    "    prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n",
    "\n",
    "    predicted_vector = model.predict(prediction_feature)\n",
    "    classes_x = np.argmax(predicted_vector, axis=1)\n",
    "    predicted_class = le.inverse_transform(classes_x)\n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n')\n",
    "\n",
    "    predicted_proba_vector = model.predict(prediction_feature)\n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)):\n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: air_conditioner \n",
      "\n",
      "air_conditioner \t\t :  0.99540776014328002929687500000000\n",
      "car_horn \t\t :  0.00003157432729494757950305938721\n",
      "children_playing \t\t :  0.00001373798022541450336575508118\n",
      "dog_bark \t\t :  0.00000000570944358457836642628536\n",
      "drilling \t\t :  0.00366561813279986381530761718750\n",
      "engine_idling \t\t :  0.00040878166328184306621551513672\n",
      "gun_shot \t\t :  0.00000001143161831862471444765106\n",
      "jackhammer \t\t :  0.00010210958134848624467849731445\n",
      "siren \t\t :  0.00000051181905291741713881492615\n",
      "street_music \t\t :  0.00036985610495321452617645263672\n"
     ]
    }
   ],
   "source": [
    "# Air conditioner\n",
    "file_name = 'samples/100852-0-0-0.wav'\n",
    "print_prediction(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: drilling \n",
      "\n",
      "air_conditioner \t\t :  0.00000003424619166025877348147333\n",
      "car_horn \t\t :  0.00000656253678243956528604030609\n",
      "children_playing \t\t :  0.00000000518480014477518125204369\n",
      "dog_bark \t\t :  0.00000025486053800705121830105782\n",
      "drilling \t\t :  0.99974745512008666992187500000000\n",
      "engine_idling \t\t :  0.00000000213068451770936917455401\n",
      "gun_shot \t\t :  0.00000002537138499292268534190953\n",
      "jackhammer \t\t :  0.00008359959610970690846443176270\n",
      "siren \t\t :  0.00000016761700294409820344299078\n",
      "street_music \t\t :  0.00016178518126253038644790649414\n"
     ]
    }
   ],
   "source": [
    "# Drilling\n",
    "file_name = 'samples/103199-4-0-0.wav'\n",
    "print_prediction(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: street_music \n",
      "\n",
      "air_conditioner \t\t :  0.00211299513466656208038330078125\n",
      "car_horn \t\t :  0.00042010183096863329410552978516\n",
      "children_playing \t\t :  0.02874629758298397064208984375000\n",
      "dog_bark \t\t :  0.00253833271563053131103515625000\n",
      "drilling \t\t :  0.00010770319204311817884445190430\n",
      "engine_idling \t\t :  0.00007903886580606922507286071777\n",
      "gun_shot \t\t :  0.00000000460769777888003773114178\n",
      "jackhammer \t\t :  0.00000626230166744790039956569672\n",
      "siren \t\t :  0.00061379023827612400054931640625\n",
      "street_music \t\t :  0.96537536382675170898437500000000\n"
     ]
    }
   ],
   "source": [
    "# Street music\n",
    "file_name = 'samples/101848-9-0-0.wav'\n",
    "print_prediction(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: drilling \n",
      "\n",
      "air_conditioner \t\t :  0.00212934589944779872894287109375\n",
      "car_horn \t\t :  0.21844662725925445556640625000000\n",
      "children_playing \t\t :  0.01239802129566669464111328125000\n",
      "dog_bark \t\t :  0.12190297245979309082031250000000\n",
      "drilling \t\t :  0.31346091628074645996093750000000\n",
      "engine_idling \t\t :  0.01633055880665779113769531250000\n",
      "gun_shot \t\t :  0.10233467072248458862304687500000\n",
      "jackhammer \t\t :  0.18508528172969818115234375000000\n",
      "siren \t\t :  0.02293832227587699890136718750000\n",
      "street_music \t\t :  0.00497322529554367065429687500000\n"
     ]
    }
   ],
   "source": [
    "# Car horn\n",
    "file_name = 'samples/100648-1-0-0.wav'\n",
    "print_prediction(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "# Serialize model to Json\n",
    "model_json = model.to_json()\n",
    "with open('models/cnn.json', 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# Serialize weights to HDF5\n",
    "model.save_weights('models/cnn.h5')\n",
    "print('Model saved')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the model and test it"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "json_file2 = open('models/cnn.json')\n",
    "loaded_model_json = json_file2.read()\n",
    "json_file2.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# Load weights into new model\n",
    "loaded_model.load_weights('models/cnn.h5')\n",
    "print('Model loaded')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test the loaded model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: street_music \n",
      "\n",
      "air_conditioner \t\t :  0.00211299513466656208038330078125\n",
      "car_horn \t\t :  0.00042010183096863329410552978516\n",
      "children_playing \t\t :  0.02874629758298397064208984375000\n",
      "dog_bark \t\t :  0.00253833271563053131103515625000\n",
      "drilling \t\t :  0.00010770319204311817884445190430\n",
      "engine_idling \t\t :  0.00007903886580606922507286071777\n",
      "gun_shot \t\t :  0.00000000460769777888003773114178\n",
      "jackhammer \t\t :  0.00000626230166744790039956569672\n",
      "siren \t\t :  0.00061379023827612400054931640625\n",
      "street_music \t\t :  0.96537536382675170898437500000000\n"
     ]
    }
   ],
   "source": [
    "file_name = 'samples/101848-9-0-0.wav'\n",
    "prediction_feature = extract_features(file_name)\n",
    "prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n",
    "\n",
    "predicted_vector = loaded_model.predict(prediction_feature)\n",
    "classes_x = np.argmax(predicted_vector, axis=1)\n",
    "predicted_class = le.inverse_transform(classes_x)\n",
    "print(\"The predicted class is:\", predicted_class[0], '\\n')\n",
    "\n",
    "predicted_proba_vector = loaded_model.predict(prediction_feature)\n",
    "predicted_proba = predicted_proba_vector[0]\n",
    "for i in range(len(predicted_proba)):\n",
    "    category = le.inverse_transform(np.array([i]))\n",
    "    print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}