{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "max_pad_len = 174\n",
    "\n",
    "def extract_features(file_name):\n",
    "\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None\n",
    "\n",
    "    return mfccs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3553it [02:13, 26.26it/s]C:\\Users\\masterdoc\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1323\n",
      "  warnings.warn(\n",
      "8325it [05:05, 36.03it/s]C:\\Users\\masterdoc\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1103\n",
      "  warnings.warn(\n",
      "C:\\Users\\masterdoc\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1523\n",
      "  warnings.warn(\n",
      "8732it [05:19, 27.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  8732  files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the full UrbanSound dataset\n",
    "full_dataset_path = 'Data/UrbanSound8K/audio'\n",
    "metadata = pd.read_csv('Data/UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "features = []\n",
    "\n",
    "# Iterate through each sound file and extract the features\n",
    "for index, row in tqdm(metadata.iterrows()):\n",
    "\n",
    "    file_name = os.path.join(os.path.abspath(full_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "\n",
    "    class_label = row[\"class\"]\n",
    "    data = extract_features(file_name)\n",
    "\n",
    "    features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe\n",
    "features_df = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(features_df), ' files')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(features_df.feature.tolist())\n",
    "y = np.array(features_df.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y))\n",
    "\n",
    "# split the dataset\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, GlobalAveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "num_rows = 40\n",
    "num_columns = 174\n",
    "num_channels = 1\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compile the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 39, 173, 16)       80        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 19, 86, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 19, 86, 16)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 18, 85, 32)        2080      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 9, 42, 32)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 9, 42, 32)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 41, 64)         8256      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 20, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 20, 64)         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 3, 19, 128)        32896     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 9, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 9, 128)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,602\n",
      "Trainable params: 44,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "55/55 [==============================] - 5s 4ms/step - loss: 11.6830 - accuracy: 0.0412\n",
      "Pre-training accuracy: 4.1214%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary\n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "num_epochs = 72\n",
    "num_batch_size = 256\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='saved_models_CNN/weights.best.basic_cnn.hdf5',\n",
    "    verbose=1,\n",
    "    save_best_only=True\n",
    ")\n",
    "start = datetime.now()\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(f'Trained the model in: {duration}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 4.7540 - accuracy: 0.1696\n",
      "Epoch 00001: val_loss improved from inf to 2.07351, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 3s 39ms/step - loss: 4.7540 - accuracy: 0.1696 - val_loss: 2.0735 - val_accuracy: 0.2765\n",
      "Epoch 2/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 2.0217 - accuracy: 0.3241\n",
      "Epoch 00002: val_loss improved from 2.07351 to 1.85659, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 2.0217 - accuracy: 0.3241 - val_loss: 1.8566 - val_accuracy: 0.3938\n",
      "Epoch 3/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.6554 - accuracy: 0.4179\n",
      "Epoch 00003: val_loss improved from 1.85659 to 1.66192, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.6554 - accuracy: 0.4179 - val_loss: 1.6619 - val_accuracy: 0.4413\n",
      "Epoch 4/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4920 - accuracy: 0.4810\n",
      "Epoch 00004: val_loss improved from 1.66192 to 1.53851, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.4920 - accuracy: 0.4810 - val_loss: 1.5385 - val_accuracy: 0.5060\n",
      "Epoch 5/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4009 - accuracy: 0.5005\n",
      "Epoch 00005: val_loss improved from 1.53851 to 1.44652, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.4009 - accuracy: 0.5005 - val_loss: 1.4465 - val_accuracy: 0.5243\n",
      "Epoch 6/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3223 - accuracy: 0.5301\n",
      "Epoch 00006: val_loss improved from 1.44652 to 1.36708, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.3223 - accuracy: 0.5301 - val_loss: 1.3671 - val_accuracy: 0.5478\n",
      "Epoch 7/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2393 - accuracy: 0.5618\n",
      "Epoch 00007: val_loss improved from 1.36708 to 1.29684, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.2393 - accuracy: 0.5618 - val_loss: 1.2968 - val_accuracy: 0.5661\n",
      "Epoch 8/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1935 - accuracy: 0.5825\n",
      "Epoch 00008: val_loss improved from 1.29684 to 1.25314, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.1935 - accuracy: 0.5825 - val_loss: 1.2531 - val_accuracy: 0.5821\n",
      "Epoch 9/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1380 - accuracy: 0.6013\n",
      "Epoch 00009: val_loss improved from 1.25314 to 1.19342, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1380 - accuracy: 0.6013 - val_loss: 1.1934 - val_accuracy: 0.6056\n",
      "Epoch 10/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0945 - accuracy: 0.6172\n",
      "Epoch 00010: val_loss improved from 1.19342 to 1.14287, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0945 - accuracy: 0.6172 - val_loss: 1.1429 - val_accuracy: 0.6388\n",
      "Epoch 11/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0361 - accuracy: 0.6354\n",
      "Epoch 00011: val_loss improved from 1.14287 to 1.07487, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0361 - accuracy: 0.6354 - val_loss: 1.0749 - val_accuracy: 0.6709\n",
      "Epoch 12/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9884 - accuracy: 0.6604\n",
      "Epoch 00012: val_loss improved from 1.07487 to 1.05735, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9884 - accuracy: 0.6604 - val_loss: 1.0574 - val_accuracy: 0.6571\n",
      "Epoch 13/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9530 - accuracy: 0.6739\n",
      "Epoch 00013: val_loss improved from 1.05735 to 0.98555, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9530 - accuracy: 0.6739 - val_loss: 0.9855 - val_accuracy: 0.6915\n",
      "Epoch 14/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9303 - accuracy: 0.6806\n",
      "Epoch 00014: val_loss improved from 0.98555 to 0.97075, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9303 - accuracy: 0.6806 - val_loss: 0.9708 - val_accuracy: 0.6949\n",
      "Epoch 15/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9171 - accuracy: 0.6842\n",
      "Epoch 00015: val_loss improved from 0.97075 to 0.93620, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9171 - accuracy: 0.6842 - val_loss: 0.9362 - val_accuracy: 0.7075\n",
      "Epoch 16/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8793 - accuracy: 0.7024\n",
      "Epoch 00016: val_loss improved from 0.93620 to 0.88366, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8793 - accuracy: 0.7024 - val_loss: 0.8837 - val_accuracy: 0.7298\n",
      "Epoch 17/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8296 - accuracy: 0.7188\n",
      "Epoch 00017: val_loss improved from 0.88366 to 0.87952, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8296 - accuracy: 0.7188 - val_loss: 0.8795 - val_accuracy: 0.7161\n",
      "Epoch 18/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8038 - accuracy: 0.7250\n",
      "Epoch 00018: val_loss improved from 0.87952 to 0.84416, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8038 - accuracy: 0.7250 - val_loss: 0.8442 - val_accuracy: 0.7355\n",
      "Epoch 19/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8041 - accuracy: 0.7243\n",
      "Epoch 00019: val_loss improved from 0.84416 to 0.82750, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8041 - accuracy: 0.7243 - val_loss: 0.8275 - val_accuracy: 0.7396\n",
      "Epoch 20/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7760 - accuracy: 0.7442\n",
      "Epoch 00020: val_loss did not improve from 0.82750\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.7760 - accuracy: 0.7442 - val_loss: 0.8446 - val_accuracy: 0.7367\n",
      "Epoch 21/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7356 - accuracy: 0.7526\n",
      "Epoch 00021: val_loss improved from 0.82750 to 0.78406, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7356 - accuracy: 0.7526 - val_loss: 0.7841 - val_accuracy: 0.7636\n",
      "Epoch 22/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7244 - accuracy: 0.7558\n",
      "Epoch 00022: val_loss improved from 0.78406 to 0.76405, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7244 - accuracy: 0.7558 - val_loss: 0.7640 - val_accuracy: 0.7682\n",
      "Epoch 23/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7118 - accuracy: 0.7556\n",
      "Epoch 00023: val_loss improved from 0.76405 to 0.74188, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7118 - accuracy: 0.7556 - val_loss: 0.7419 - val_accuracy: 0.7642\n",
      "Epoch 24/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.6836 - accuracy: 0.7688\n",
      "Epoch 00024: val_loss did not improve from 0.74188\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.6836 - accuracy: 0.7688 - val_loss: 0.7433 - val_accuracy: 0.7653\n",
      "Epoch 25/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.6595 - accuracy: 0.7774\n",
      "Epoch 00025: val_loss improved from 0.74188 to 0.71418, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.6595 - accuracy: 0.7774 - val_loss: 0.7142 - val_accuracy: 0.7693\n",
      "Epoch 26/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.6589 - accuracy: 0.7722\n",
      "Epoch 00026: val_loss improved from 0.71418 to 0.67450, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.6589 - accuracy: 0.7722 - val_loss: 0.6745 - val_accuracy: 0.7876\n",
      "Epoch 27/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.6413 - accuracy: 0.7864\n",
      "Epoch 00027: val_loss did not improve from 0.67450\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.6413 - accuracy: 0.7864 - val_loss: 0.6965 - val_accuracy: 0.7876\n",
      "Epoch 28/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.6321 - accuracy: 0.7858\n",
      "Epoch 00028: val_loss did not improve from 0.67450\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.6321 - accuracy: 0.7858 - val_loss: 0.6799 - val_accuracy: 0.7894\n",
      "Epoch 29/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.5902 - accuracy: 0.7997\n",
      "Epoch 00029: val_loss improved from 0.67450 to 0.64199, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.5902 - accuracy: 0.7997 - val_loss: 0.6420 - val_accuracy: 0.8002\n",
      "Epoch 30/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.5938 - accuracy: 0.7967\n",
      "Epoch 00030: val_loss did not improve from 0.64199\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.5938 - accuracy: 0.7967 - val_loss: 0.6600 - val_accuracy: 0.8008\n",
      "Epoch 31/72\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 0.5772 - accuracy: 0.8068\n",
      "Epoch 00031: val_loss improved from 0.64199 to 0.59702, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.5763 - accuracy: 0.8067 - val_loss: 0.5970 - val_accuracy: 0.8174\n",
      "Epoch 32/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.5640 - accuracy: 0.8084\n",
      "Epoch 00032: val_loss did not improve from 0.59702\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.5640 - accuracy: 0.8084 - val_loss: 0.5972 - val_accuracy: 0.8122\n",
      "Epoch 33/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.5562 - accuracy: 0.8056\n",
      "Epoch 00033: val_loss did not improve from 0.59702\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.5562 - accuracy: 0.8056 - val_loss: 0.5981 - val_accuracy: 0.8111\n",
      "Epoch 34/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.5343 - accuracy: 0.8203\n",
      "Epoch 00034: val_loss improved from 0.59702 to 0.59372, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.5343 - accuracy: 0.8203 - val_loss: 0.5937 - val_accuracy: 0.8191\n",
      "Epoch 35/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.5217 - accuracy: 0.8261\n",
      "Epoch 00035: val_loss improved from 0.59372 to 0.57412, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.5217 - accuracy: 0.8261 - val_loss: 0.5741 - val_accuracy: 0.8306\n",
      "Epoch 36/72\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.5139 - accuracy: 0.8288\n",
      "Epoch 00036: val_loss improved from 0.57412 to 0.56440, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.5123 - accuracy: 0.8295 - val_loss: 0.5644 - val_accuracy: 0.8260\n",
      "Epoch 37/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4973 - accuracy: 0.8316\n",
      "Epoch 00037: val_loss did not improve from 0.56440\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.4973 - accuracy: 0.8316 - val_loss: 0.5668 - val_accuracy: 0.8185\n",
      "Epoch 38/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.5061 - accuracy: 0.8283\n",
      "Epoch 00038: val_loss improved from 0.56440 to 0.55876, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.5061 - accuracy: 0.8283 - val_loss: 0.5588 - val_accuracy: 0.8254\n",
      "Epoch 39/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4802 - accuracy: 0.8375\n",
      "Epoch 00039: val_loss improved from 0.55876 to 0.50892, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.4802 - accuracy: 0.8375 - val_loss: 0.5089 - val_accuracy: 0.8477\n",
      "Epoch 40/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4805 - accuracy: 0.8364\n",
      "Epoch 00040: val_loss did not improve from 0.50892\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.4805 - accuracy: 0.8364 - val_loss: 0.5156 - val_accuracy: 0.8454\n",
      "Epoch 41/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4673 - accuracy: 0.8387\n",
      "Epoch 00041: val_loss did not improve from 0.50892\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.4673 - accuracy: 0.8387 - val_loss: 0.5273 - val_accuracy: 0.8426\n",
      "Epoch 42/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4421 - accuracy: 0.8478\n",
      "Epoch 00042: val_loss improved from 0.50892 to 0.50282, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.4421 - accuracy: 0.8478 - val_loss: 0.5028 - val_accuracy: 0.8477\n",
      "Epoch 43/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4370 - accuracy: 0.8523\n",
      "Epoch 00043: val_loss improved from 0.50282 to 0.48810, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.4370 - accuracy: 0.8523 - val_loss: 0.4881 - val_accuracy: 0.8580\n",
      "Epoch 44/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4311 - accuracy: 0.8537\n",
      "Epoch 00044: val_loss did not improve from 0.48810\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.4311 - accuracy: 0.8537 - val_loss: 0.5039 - val_accuracy: 0.8483\n",
      "Epoch 45/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4580 - accuracy: 0.8429\n",
      "Epoch 00045: val_loss did not improve from 0.48810\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.4580 - accuracy: 0.8429 - val_loss: 0.4933 - val_accuracy: 0.8552\n",
      "Epoch 46/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4187 - accuracy: 0.8561\n",
      "Epoch 00046: val_loss improved from 0.48810 to 0.47756, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.4187 - accuracy: 0.8561 - val_loss: 0.4776 - val_accuracy: 0.8609\n",
      "Epoch 47/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4202 - accuracy: 0.8581\n",
      "Epoch 00047: val_loss improved from 0.47756 to 0.46141, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.4202 - accuracy: 0.8581 - val_loss: 0.4614 - val_accuracy: 0.8678\n",
      "Epoch 48/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3963 - accuracy: 0.8663\n",
      "Epoch 00048: val_loss did not improve from 0.46141\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.3963 - accuracy: 0.8663 - val_loss: 0.5019 - val_accuracy: 0.8558\n",
      "Epoch 49/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3987 - accuracy: 0.8674\n",
      "Epoch 00049: val_loss improved from 0.46141 to 0.45299, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.3987 - accuracy: 0.8674 - val_loss: 0.4530 - val_accuracy: 0.8735\n",
      "Epoch 50/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4037 - accuracy: 0.8578\n",
      "Epoch 00050: val_loss did not improve from 0.45299\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.4037 - accuracy: 0.8578 - val_loss: 0.4611 - val_accuracy: 0.8752\n",
      "Epoch 51/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3780 - accuracy: 0.8732\n",
      "Epoch 00051: val_loss did not improve from 0.45299\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.3780 - accuracy: 0.8732 - val_loss: 0.4618 - val_accuracy: 0.8769\n",
      "Epoch 52/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3740 - accuracy: 0.8722\n",
      "Epoch 00052: val_loss improved from 0.45299 to 0.45031, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.3740 - accuracy: 0.8722 - val_loss: 0.4503 - val_accuracy: 0.8689\n",
      "Epoch 53/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3701 - accuracy: 0.8786\n",
      "Epoch 00053: val_loss improved from 0.45031 to 0.44491, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.3701 - accuracy: 0.8786 - val_loss: 0.4449 - val_accuracy: 0.8729\n",
      "Epoch 54/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3629 - accuracy: 0.8757\n",
      "Epoch 00054: val_loss did not improve from 0.44491\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.3629 - accuracy: 0.8757 - val_loss: 0.4499 - val_accuracy: 0.8666\n",
      "Epoch 55/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3719 - accuracy: 0.8737\n",
      "Epoch 00055: val_loss did not improve from 0.44491\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.3719 - accuracy: 0.8737 - val_loss: 0.4636 - val_accuracy: 0.8666\n",
      "Epoch 56/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3522 - accuracy: 0.8840\n",
      "Epoch 00056: val_loss did not improve from 0.44491\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.3522 - accuracy: 0.8840 - val_loss: 0.4567 - val_accuracy: 0.8735\n",
      "Epoch 57/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3428 - accuracy: 0.8802\n",
      "Epoch 00057: val_loss improved from 0.44491 to 0.39927, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.3428 - accuracy: 0.8802 - val_loss: 0.3993 - val_accuracy: 0.8901\n",
      "Epoch 58/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3297 - accuracy: 0.8850\n",
      "Epoch 00058: val_loss did not improve from 0.39927\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.3297 - accuracy: 0.8850 - val_loss: 0.4084 - val_accuracy: 0.8798\n",
      "Epoch 59/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3422 - accuracy: 0.8800\n",
      "Epoch 00059: val_loss did not improve from 0.39927\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.3422 - accuracy: 0.8800 - val_loss: 0.4146 - val_accuracy: 0.8809\n",
      "Epoch 60/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3373 - accuracy: 0.8832\n",
      "Epoch 00060: val_loss did not improve from 0.39927\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.3373 - accuracy: 0.8832 - val_loss: 0.4384 - val_accuracy: 0.8718\n",
      "Epoch 61/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3341 - accuracy: 0.8839\n",
      "Epoch 00061: val_loss did not improve from 0.39927\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.3341 - accuracy: 0.8839 - val_loss: 0.4388 - val_accuracy: 0.8701\n",
      "Epoch 62/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3236 - accuracy: 0.8885\n",
      "Epoch 00062: val_loss improved from 0.39927 to 0.39781, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.3236 - accuracy: 0.8885 - val_loss: 0.3978 - val_accuracy: 0.8849\n",
      "Epoch 63/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3225 - accuracy: 0.8872\n",
      "Epoch 00063: val_loss did not improve from 0.39781\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.3225 - accuracy: 0.8872 - val_loss: 0.4397 - val_accuracy: 0.8695\n",
      "Epoch 64/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3184 - accuracy: 0.8889\n",
      "Epoch 00064: val_loss did not improve from 0.39781\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.3184 - accuracy: 0.8889 - val_loss: 0.4096 - val_accuracy: 0.8827\n",
      "Epoch 65/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3154 - accuracy: 0.8945\n",
      "Epoch 00065: val_loss did not improve from 0.39781\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.3154 - accuracy: 0.8945 - val_loss: 0.4070 - val_accuracy: 0.8867\n",
      "Epoch 66/72\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2995 - accuracy: 0.8997\n",
      "Epoch 00066: val_loss did not improve from 0.39781\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.2989 - accuracy: 0.8999 - val_loss: 0.4007 - val_accuracy: 0.8912\n",
      "Epoch 67/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.2920 - accuracy: 0.8982\n",
      "Epoch 00067: val_loss did not improve from 0.39781\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.2920 - accuracy: 0.8982 - val_loss: 0.4032 - val_accuracy: 0.8821\n",
      "Epoch 68/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3038 - accuracy: 0.8946\n",
      "Epoch 00068: val_loss did not improve from 0.39781\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.3038 - accuracy: 0.8946 - val_loss: 0.3985 - val_accuracy: 0.8901\n",
      "Epoch 69/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.2951 - accuracy: 0.8969\n",
      "Epoch 00069: val_loss improved from 0.39781 to 0.37762, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.2951 - accuracy: 0.8969 - val_loss: 0.3776 - val_accuracy: 0.8930\n",
      "Epoch 70/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.2768 - accuracy: 0.9057\n",
      "Epoch 00070: val_loss did not improve from 0.37762\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.2768 - accuracy: 0.9057 - val_loss: 0.3890 - val_accuracy: 0.8861\n",
      "Epoch 71/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.2632 - accuracy: 0.9071\n",
      "Epoch 00071: val_loss did not improve from 0.37762\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.2632 - accuracy: 0.9071 - val_loss: 0.3818 - val_accuracy: 0.8935\n",
      "Epoch 72/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.2827 - accuracy: 0.9001\n",
      "Epoch 00072: val_loss did not improve from 0.37762\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.2827 - accuracy: 0.9001 - val_loss: 0.3840 - val_accuracy: 0.8970\n",
      "Trained the model in: 0:00:54.513209\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9348604083061218\n",
      "Testing Accuracy:  0.8969662189483643\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def print_prediction(file_name):\n",
    "    prediction_feature = extract_features(file_name)\n",
    "    prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n",
    "\n",
    "    predicted_vector = model.predict(prediction_feature)\n",
    "    classes_x = np.argmax(predicted_vector, axis=1)\n",
    "    predicted_class = le.inverse_transform(classes_x)\n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n')\n",
    "\n",
    "    predicted_proba_vector = model.predict(prediction_feature)\n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)):\n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: air_conditioner \n",
      "\n",
      "air_conditioner \t\t :  0.98010075092315673828125000000000\n",
      "car_horn \t\t :  0.00016890684491954743862152099609\n",
      "children_playing \t\t :  0.00067353463964536786079406738281\n",
      "dog_bark \t\t :  0.00012608239194378256797790527344\n",
      "drilling \t\t :  0.00638101948425173759460449218750\n",
      "engine_idling \t\t :  0.00105679396074265241622924804688\n",
      "gun_shot \t\t :  0.00080544687807559967041015625000\n",
      "jackhammer \t\t :  0.00158881745301187038421630859375\n",
      "siren \t\t :  0.00005560976205742917954921722412\n",
      "street_music \t\t :  0.00904300250113010406494140625000\n"
     ]
    }
   ],
   "source": [
    "# Air conditioner\n",
    "file_name = 'samples/100852-0-0-0.wav'\n",
    "print_prediction(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: drilling \n",
      "\n",
      "air_conditioner \t\t :  0.00000005317914286706582061015069\n",
      "car_horn \t\t :  0.00000065600721654845983721315861\n",
      "children_playing \t\t :  0.00000014725989672115247230976820\n",
      "dog_bark \t\t :  0.00000002234189366845384938642383\n",
      "drilling \t\t :  0.99977868795394897460937500000000\n",
      "engine_idling \t\t :  0.00000152471716319269035011529922\n",
      "gun_shot \t\t :  0.00000032341472433472517877817154\n",
      "jackhammer \t\t :  0.00000678274363963282667100429535\n",
      "siren \t\t :  0.00000016280453962735919049009681\n",
      "street_music \t\t :  0.00021165110229048877954483032227\n"
     ]
    }
   ],
   "source": [
    "# Drilling\n",
    "file_name = 'samples/103199-4-0-0.wav'\n",
    "print_prediction(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: street_music \n",
      "\n",
      "air_conditioner \t\t :  0.00000226030101657670456916093826\n",
      "car_horn \t\t :  0.00005847968350281007587909698486\n",
      "children_playing \t\t :  0.00188699341379106044769287109375\n",
      "dog_bark \t\t :  0.00002070566915790550410747528076\n",
      "drilling \t\t :  0.00000422837547375820577144622803\n",
      "engine_idling \t\t :  0.00000224240966417710296809673309\n",
      "gun_shot \t\t :  0.00000000009598265238164316315306\n",
      "jackhammer \t\t :  0.00000008436382614718240802176297\n",
      "siren \t\t :  0.00011829331197077408432960510254\n",
      "street_music \t\t :  0.99790680408477783203125000000000\n"
     ]
    }
   ],
   "source": [
    "# Street music\n",
    "file_name = 'samples/101848-9-0-0.wav'\n",
    "print_prediction(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: gun_shot \n",
      "\n",
      "air_conditioner \t\t :  0.00091128156054764986038208007812\n",
      "car_horn \t\t :  0.19520971179008483886718750000000\n",
      "children_playing \t\t :  0.01489647850394248962402343750000\n",
      "dog_bark \t\t :  0.12509010732173919677734375000000\n",
      "drilling \t\t :  0.16062036156654357910156250000000\n",
      "engine_idling \t\t :  0.01196355093270540237426757812500\n",
      "gun_shot \t\t :  0.36392092704772949218750000000000\n",
      "jackhammer \t\t :  0.10206745564937591552734375000000\n",
      "siren \t\t :  0.01796950027346611022949218750000\n",
      "street_music \t\t :  0.00735064176842570304870605468750\n"
     ]
    }
   ],
   "source": [
    "# Car horn\n",
    "file_name = 'samples/100648-1-0-0.wav'\n",
    "print_prediction(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://49278814-0144-4dad-b9f6-b2c1bad5c2aa/assets\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotFoundError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\MASTER~1\\AppData\\Local\\Temp/ipykernel_21388/1134428706.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpickle\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mpickle\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'saved_models_CNN/CNN_v1.pkl'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'wb'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36m__reduce__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    313\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbuilt\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    314\u001B[0m       return (pickle_utils.deserialize_model_from_bytecode,\n\u001B[1;32m--> 315\u001B[1;33m               pickle_utils.serialize_model_as_bytecode(self))\n\u001B[0m\u001B[0;32m    316\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    317\u001B[0m       \u001B[1;31m# SavedModel (and hence serialize_model_as_bytecode) only support\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\keras\\saving\\pickle_utils.py\u001B[0m in \u001B[0;36mserialize_model_as_bytecode\u001B[1;34m(model)\u001B[0m\n\u001B[0;32m     75\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mio\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgfile\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mGFile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdest_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"rb\"\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     76\u001B[0m           \u001B[0minfo\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtarfile\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTarInfo\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelpath\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdest_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtemp_dir\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 77\u001B[1;33m           \u001B[0minfo\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     78\u001B[0m           \u001B[0marchive\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maddfile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtarinfo\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minfo\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfileobj\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     79\u001B[0m   \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mio\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgfile\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrmtree\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtemp_dir\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001B[0m in \u001B[0;36msize\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     97\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0msize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     98\u001B[0m     \u001B[1;34m\"\"\"Returns the size of the file.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 99\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mstat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlength\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    100\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    101\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mwrite\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfile_content\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001B[0m in \u001B[0;36mstat\u001B[1;34m(filename)\u001B[0m\n\u001B[0;32m    908\u001B[0m     \u001B[0merrors\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mOpError\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mIf\u001B[0m \u001B[0mthe\u001B[0m \u001B[0moperation\u001B[0m \u001B[0mfails\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    909\u001B[0m   \"\"\"\n\u001B[1;32m--> 910\u001B[1;33m   \u001B[1;32mreturn\u001B[0m \u001B[0mstat_v2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    911\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    912\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001B[0m in \u001B[0;36mstat_v2\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m    924\u001B[0m     \u001B[0merrors\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mOpError\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mIf\u001B[0m \u001B[0mthe\u001B[0m \u001B[0moperation\u001B[0m \u001B[0mfails\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    925\u001B[0m   \"\"\"\n\u001B[1;32m--> 926\u001B[1;33m   \u001B[1;32mreturn\u001B[0m \u001B[0m_pywrap_file_io\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mStat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcompat\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath_to_str\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    927\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    928\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNotFoundError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open('saved_models_CNN/CNN_v1.pkl', 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}