{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "![image](https://docs.google.com/uc?export=download&id=1NUy1Q-abpoV9XYK9qT9t8Mdhj3ZVlveO)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Integrantes**\n",
    "- Daniel Andres Jimenez\n",
    "- Alejandro Leon Andrade\n",
    "- Andrés Felipe Rojas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Proyecto Final**\n",
    "\n",
    "Dados los bajos costes en sensores, y teniendo en cuenta la vida en grandes ciudades como Bogotá, se hace interesante la identificación de los diferentes sonidos urbanos presentes en toda la ciudad. Al tener identificadas diferentes zonas de la ciudad con cierto tipo de sonidos, instituciones como la secretaria Distrital de Ambiente, pueden tomar decisiones concretas y rápidas, respecto a la contaminación ambiental presentada.  En futuros trabajos es posible combinar la identificación del sonido junto con los niveles de intensidad del sonido, para tomar mejores decisiones.\n",
    "Desde el punto de vista del negocio se propone en este proyecto realizar un modelo de aprendizaje profundo que sea capaz de identificar y clasificar sonidos urbanos en 10 categorías iniciales y básicas de la taxonomía de sonidos urbanos\n",
    "\n",
    "\n",
    "> [Fuente de Datos](https://urbansounddataset.weebly.com/urbansound8k.html)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Contenido**\n",
    "1. [**Librerias**](#id1)\n",
    "2. [**Lectura y extracción de características**](#id2)\n",
    "3. [**Generación de conjuntos de train, validation y test**](#id3)\n",
    "4. [**CNN**](#id4)\n",
    "4-1. [**Compilación del modelo**](#id5)\n",
    "4-2. [**Entrenamiento**](#id6)\n",
    "4-3. [**Métricas**](#id7)\n",
    "4-4. [**Matriz de confusión**](#id8)\n",
    "4-5. [**Heatmap**](#id9)\n",
    "4-6. [**Predicciones**](#id10)\n",
    "5. [**Búsqueda de hiperparámetros**](#id11)\n",
    "6. [**Entrenamiento del modelo calibrado**](#id12)\n",
    "6-2. [**Métricas**](#id13)\n",
    "6-3. [**Testeo del modelo**](#id14)\n",
    "6-4. [**Matriz de confusión**](#id15)\n",
    "6-5. [**Heatmap**](#id16)\n",
    "7. [**Conclusiones**](#id17)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Librerias<a name='id1'></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "max_pad_len = 174\n",
    "\n",
    "def extract_features(file_name):\n",
    "\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None\n",
    "\n",
    "    return mfccs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lectura y extracción de características<a name='id2'></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3554it [02:16, 26.19it/s]C:\\Users\\masterdoc\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1323\n",
      "  warnings.warn(\n",
      "8323it [05:12, 34.51it/s]C:\\Users\\masterdoc\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1103\n",
      "  warnings.warn(\n",
      "C:\\Users\\masterdoc\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1523\n",
      "  warnings.warn(\n",
      "8732it [05:27, 26.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  8732  files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the full UrbanSound dataset\n",
    "full_dataset_path = 'Data/UrbanSound8K/audio'\n",
    "metadata = pd.read_csv('Data/UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "features = []\n",
    "\n",
    "# Iterate through each sound file and extract the features\n",
    "for index, row in tqdm(metadata.iterrows()):\n",
    "\n",
    "    file_name = os.path.join(os.path.abspath(full_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "\n",
    "    class_label = row[\"class\"]\n",
    "    data = extract_features(file_name)\n",
    "\n",
    "    features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe\n",
    "features_df = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(features_df), ' files')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                feature       class_label\n0     [[-306.77255, -177.59209, -99.13616, -65.97198...          dog_bark\n1     [[-457.6953, -451.0248, -450.68613, -444.99997...  children_playing\n2     [[-468.0367, -467.42264, -481.04654, -486.5948...  children_playing\n3     [[-422.42215, -411.9085, -409.46243, -409.0892...  children_playing\n4     [[-438.10162, -434.47787, -443.3284, -442.6644...  children_playing\n...                                                 ...               ...\n8727  [[-397.82446, -400.45578, -407.5035, -408.9529...          car_horn\n8728  [[-451.81265, -451.41983, -450.67892, -445.635...          car_horn\n8729  [[-301.06348, -298.25397, -305.0326, -303.8614...          car_horn\n8730  [[-373.6307, -369.44986, -366.48, -364.9094, -...          car_horn\n8731  [[-309.34647, -305.3132, -308.23593, -308.1856...          car_horn\n\n[8732 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n      <th>class_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[-306.77255, -177.59209, -99.13616, -65.97198...</td>\n      <td>dog_bark</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[-457.6953, -451.0248, -450.68613, -444.99997...</td>\n      <td>children_playing</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[-468.0367, -467.42264, -481.04654, -486.5948...</td>\n      <td>children_playing</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[-422.42215, -411.9085, -409.46243, -409.0892...</td>\n      <td>children_playing</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[-438.10162, -434.47787, -443.3284, -442.6644...</td>\n      <td>children_playing</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8727</th>\n      <td>[[-397.82446, -400.45578, -407.5035, -408.9529...</td>\n      <td>car_horn</td>\n    </tr>\n    <tr>\n      <th>8728</th>\n      <td>[[-451.81265, -451.41983, -450.67892, -445.635...</td>\n      <td>car_horn</td>\n    </tr>\n    <tr>\n      <th>8729</th>\n      <td>[[-301.06348, -298.25397, -305.0326, -303.8614...</td>\n      <td>car_horn</td>\n    </tr>\n    <tr>\n      <th>8730</th>\n      <td>[[-373.6307, -369.44986, -366.48, -364.9094, -...</td>\n      <td>car_horn</td>\n    </tr>\n    <tr>\n      <th>8731</th>\n      <td>[[-309.34647, -305.3132, -308.23593, -308.1856...</td>\n      <td>car_horn</td>\n    </tr>\n  </tbody>\n</table>\n<p>8732 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "features_df.to_csv('features_df_index.csv', index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generación de conjuntos de train, validation y test<a name='id3'></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(features_df.feature.tolist())\n",
    "y = np.array(features_df.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y))\n",
    "\n",
    "# split the dataset\n",
    "\n",
    "x_train_full, x_test, y_train_full, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size=0.2, random_state = 42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN<a name='id4'></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, GlobalAveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "num_rows = 40\n",
    "num_columns = 174\n",
    "num_channels = 1\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_val = x_val.reshape(x_val.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model\n",
    "model_basic = Sequential()\n",
    "model_basic.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model_basic.add(MaxPooling2D(pool_size=2))\n",
    "model_basic.add(Dropout(0.2))\n",
    "\n",
    "model_basic.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
    "model_basic.add(MaxPooling2D(pool_size=2))\n",
    "model_basic.add(Dropout(0.2))\n",
    "\n",
    "model_basic.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "model_basic.add(MaxPooling2D(pool_size=2))\n",
    "model_basic.add(Dropout(0.2))\n",
    "\n",
    "model_basic.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "model_basic.add(MaxPooling2D(pool_size=2))\n",
    "model_basic.add(Dropout(0.2))\n",
    "model_basic.add(GlobalAveragePooling2D())\n",
    "\n",
    "model_basic.add(Dense(num_labels, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compilación del modelo<a name='id5'></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_basic.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 39, 173, 16)       80        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 19, 86, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 19, 86, 16)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 18, 85, 32)        2080      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 9, 42, 32)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 9, 42, 32)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 41, 64)         8256      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 20, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 20, 64)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 3, 19, 128)        32896     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 9, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 9, 128)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,602\n",
      "Trainable params: 44,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "44/44 [==============================] - 3s 5ms/step - loss: 8.4576 - accuracy: 0.1274\n",
      "Pre-training accuracy: 12.7416%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary\n",
    "model_basic.summary()\n",
    "\n",
    "# Calculate pre-training accuracy\n",
    "score = model_basic.evaluate(x_val, y_val, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Entrenamiento <a name='id6'></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "num_epochs = 72\n",
    "num_batch_size = 256\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='saved_models_CNN/weights.best.basic_cnn.hdf5',\n",
    "    verbose=1,\n",
    "    save_best_only=True\n",
    ")\n",
    "start = datetime.now()\n",
    "model_basic.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_val, y_val), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(f'Trained the model in: {duration}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 5.6332 - accuracy: 0.1705\n",
      "Epoch 00001: val_loss improved from inf to 2.52932, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 2s 48ms/step - loss: 5.6332 - accuracy: 0.1705 - val_loss: 2.5293 - val_accuracy: 0.1954\n",
      "Epoch 2/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 2.2591 - accuracy: 0.2568\n",
      "Epoch 00002: val_loss improved from 2.52932 to 1.95529, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 2.2591 - accuracy: 0.2568 - val_loss: 1.9553 - val_accuracy: 0.3164\n",
      "Epoch 3/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.8939 - accuracy: 0.3312\n",
      "Epoch 00003: val_loss improved from 1.95529 to 1.85334, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 1.8939 - accuracy: 0.3312 - val_loss: 1.8533 - val_accuracy: 0.3457\n",
      "Epoch 4/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.7058 - accuracy: 0.4028\n",
      "Epoch 00004: val_loss improved from 1.85334 to 1.73950, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 1.7058 - accuracy: 0.4028 - val_loss: 1.7395 - val_accuracy: 0.3694\n",
      "Epoch 5/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.5709 - accuracy: 0.4511\n",
      "Epoch 00005: val_loss improved from 1.73950 to 1.64577, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 1.5709 - accuracy: 0.4511 - val_loss: 1.6458 - val_accuracy: 0.4173\n",
      "Epoch 6/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.4591 - accuracy: 0.4900\n",
      "Epoch 00006: val_loss improved from 1.64577 to 1.54686, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 1.4591 - accuracy: 0.4900 - val_loss: 1.5469 - val_accuracy: 0.4732\n",
      "Epoch 7/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.3641 - accuracy: 0.5254\n",
      "Epoch 00007: val_loss improved from 1.54686 to 1.42156, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 1.3641 - accuracy: 0.5254 - val_loss: 1.4216 - val_accuracy: 0.5247\n",
      "Epoch 8/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.3031 - accuracy: 0.5451\n",
      "Epoch 00008: val_loss improved from 1.42156 to 1.39937, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 1.3031 - accuracy: 0.5451 - val_loss: 1.3994 - val_accuracy: 0.5211\n",
      "Epoch 9/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.2383 - accuracy: 0.5666\n",
      "Epoch 00009: val_loss improved from 1.39937 to 1.33211, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 1.2383 - accuracy: 0.5666 - val_loss: 1.3321 - val_accuracy: 0.5412\n",
      "Epoch 10/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.1810 - accuracy: 0.5965\n",
      "Epoch 00010: val_loss improved from 1.33211 to 1.31043, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 1.1810 - accuracy: 0.5965 - val_loss: 1.3104 - val_accuracy: 0.5533\n",
      "Epoch 11/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.1489 - accuracy: 0.5979\n",
      "Epoch 00011: val_loss improved from 1.31043 to 1.26831, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 1.1489 - accuracy: 0.5979 - val_loss: 1.2683 - val_accuracy: 0.5698\n",
      "Epoch 12/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.0932 - accuracy: 0.6203\n",
      "Epoch 00012: val_loss improved from 1.26831 to 1.23575, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 1.0932 - accuracy: 0.6203 - val_loss: 1.2358 - val_accuracy: 0.5583\n",
      "Epoch 13/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.0597 - accuracy: 0.6324\n",
      "Epoch 00013: val_loss improved from 1.23575 to 1.17924, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 1.0597 - accuracy: 0.6324 - val_loss: 1.1792 - val_accuracy: 0.6013\n",
      "Epoch 14/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.0298 - accuracy: 0.6467\n",
      "Epoch 00014: val_loss improved from 1.17924 to 1.17289, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 1.0298 - accuracy: 0.6467 - val_loss: 1.1729 - val_accuracy: 0.6056\n",
      "Epoch 15/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9886 - accuracy: 0.6575\n",
      "Epoch 00015: val_loss improved from 1.17289 to 1.13102, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.9886 - accuracy: 0.6575 - val_loss: 1.1310 - val_accuracy: 0.6314\n",
      "Epoch 16/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9558 - accuracy: 0.6732\n",
      "Epoch 00016: val_loss improved from 1.13102 to 1.09144, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.9558 - accuracy: 0.6732 - val_loss: 1.0914 - val_accuracy: 0.6421\n",
      "Epoch 17/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9302 - accuracy: 0.6793\n",
      "Epoch 00017: val_loss improved from 1.09144 to 1.03305, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.9302 - accuracy: 0.6793 - val_loss: 1.0331 - val_accuracy: 0.6779\n",
      "Epoch 18/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8942 - accuracy: 0.6897\n",
      "Epoch 00018: val_loss improved from 1.03305 to 1.02527, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.8942 - accuracy: 0.6897 - val_loss: 1.0253 - val_accuracy: 0.6628\n",
      "Epoch 19/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8699 - accuracy: 0.6999\n",
      "Epoch 00019: val_loss improved from 1.02527 to 0.98538, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.8699 - accuracy: 0.6999 - val_loss: 0.9854 - val_accuracy: 0.6872\n",
      "Epoch 20/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8537 - accuracy: 0.7044\n",
      "Epoch 00020: val_loss improved from 0.98538 to 0.98443, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.8537 - accuracy: 0.7044 - val_loss: 0.9844 - val_accuracy: 0.6994\n",
      "Epoch 21/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8165 - accuracy: 0.7267\n",
      "Epoch 00021: val_loss improved from 0.98443 to 0.97440, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.8165 - accuracy: 0.7267 - val_loss: 0.9744 - val_accuracy: 0.6872\n",
      "Epoch 22/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8219 - accuracy: 0.7169\n",
      "Epoch 00022: val_loss improved from 0.97440 to 0.93003, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.8219 - accuracy: 0.7169 - val_loss: 0.9300 - val_accuracy: 0.7122\n",
      "Epoch 23/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7837 - accuracy: 0.7335\n",
      "Epoch 00023: val_loss did not improve from 0.93003\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.7837 - accuracy: 0.7335 - val_loss: 0.9510 - val_accuracy: 0.6915\n",
      "Epoch 24/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7646 - accuracy: 0.7391\n",
      "Epoch 00024: val_loss improved from 0.93003 to 0.86230, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.7646 - accuracy: 0.7391 - val_loss: 0.8623 - val_accuracy: 0.7445\n",
      "Epoch 25/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7405 - accuracy: 0.7443\n",
      "Epoch 00025: val_loss did not improve from 0.86230\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.7405 - accuracy: 0.7443 - val_loss: 0.9134 - val_accuracy: 0.7244\n",
      "Epoch 26/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7374 - accuracy: 0.7495\n",
      "Epoch 00026: val_loss improved from 0.86230 to 0.84312, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.7374 - accuracy: 0.7495 - val_loss: 0.8431 - val_accuracy: 0.7502\n",
      "Epoch 27/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7249 - accuracy: 0.7473\n",
      "Epoch 00027: val_loss improved from 0.84312 to 0.81347, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.7249 - accuracy: 0.7473 - val_loss: 0.8135 - val_accuracy: 0.7659\n",
      "Epoch 28/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6987 - accuracy: 0.7597\n",
      "Epoch 00028: val_loss improved from 0.81347 to 0.79786, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.6987 - accuracy: 0.7597 - val_loss: 0.7979 - val_accuracy: 0.7573\n",
      "Epoch 29/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6944 - accuracy: 0.7602\n",
      "Epoch 00029: val_loss improved from 0.79786 to 0.79157, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.6944 - accuracy: 0.7602 - val_loss: 0.7916 - val_accuracy: 0.7581\n",
      "Epoch 30/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6608 - accuracy: 0.7754\n",
      "Epoch 00030: val_loss improved from 0.79157 to 0.78305, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.6608 - accuracy: 0.7754 - val_loss: 0.7831 - val_accuracy: 0.7559\n",
      "Epoch 31/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6491 - accuracy: 0.7758\n",
      "Epoch 00031: val_loss improved from 0.78305 to 0.75478, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.6491 - accuracy: 0.7758 - val_loss: 0.7548 - val_accuracy: 0.7681\n",
      "Epoch 32/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6224 - accuracy: 0.7845\n",
      "Epoch 00032: val_loss did not improve from 0.75478\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.6224 - accuracy: 0.7845 - val_loss: 0.7874 - val_accuracy: 0.7581\n",
      "Epoch 33/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6296 - accuracy: 0.7867\n",
      "Epoch 00033: val_loss improved from 0.75478 to 0.72126, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.6296 - accuracy: 0.7867 - val_loss: 0.7213 - val_accuracy: 0.7802\n",
      "Epoch 34/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5960 - accuracy: 0.7938\n",
      "Epoch 00034: val_loss improved from 0.72126 to 0.69881, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.5960 - accuracy: 0.7938 - val_loss: 0.6988 - val_accuracy: 0.7874\n",
      "Epoch 35/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5948 - accuracy: 0.7972\n",
      "Epoch 00035: val_loss did not improve from 0.69881\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.5948 - accuracy: 0.7972 - val_loss: 0.7363 - val_accuracy: 0.7709\n",
      "Epoch 36/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5900 - accuracy: 0.7951\n",
      "Epoch 00036: val_loss did not improve from 0.69881\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.5900 - accuracy: 0.7951 - val_loss: 0.7001 - val_accuracy: 0.7838\n",
      "Epoch 37/72\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 0.5813 - accuracy: 0.8032\n",
      "Epoch 00037: val_loss improved from 0.69881 to 0.69130, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.5815 - accuracy: 0.8030 - val_loss: 0.6913 - val_accuracy: 0.7867\n",
      "Epoch 38/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5542 - accuracy: 0.8125\n",
      "Epoch 00038: val_loss improved from 0.69130 to 0.67631, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.5542 - accuracy: 0.8125 - val_loss: 0.6763 - val_accuracy: 0.7817\n",
      "Epoch 39/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5501 - accuracy: 0.8125\n",
      "Epoch 00039: val_loss improved from 0.67631 to 0.64353, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.5501 - accuracy: 0.8125 - val_loss: 0.6435 - val_accuracy: 0.7931\n",
      "Epoch 40/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5439 - accuracy: 0.8171\n",
      "Epoch 00040: val_loss improved from 0.64353 to 0.63253, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.5439 - accuracy: 0.8171 - val_loss: 0.6325 - val_accuracy: 0.8017\n",
      "Epoch 41/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5341 - accuracy: 0.8160\n",
      "Epoch 00041: val_loss did not improve from 0.63253\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.5341 - accuracy: 0.8160 - val_loss: 0.6672 - val_accuracy: 0.7853\n",
      "Epoch 42/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5321 - accuracy: 0.8146\n",
      "Epoch 00042: val_loss did not improve from 0.63253\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.5321 - accuracy: 0.8146 - val_loss: 0.6358 - val_accuracy: 0.8046\n",
      "Epoch 43/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5120 - accuracy: 0.8212\n",
      "Epoch 00043: val_loss improved from 0.63253 to 0.63187, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.5120 - accuracy: 0.8212 - val_loss: 0.6319 - val_accuracy: 0.8010\n",
      "Epoch 44/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5128 - accuracy: 0.8218\n",
      "Epoch 00044: val_loss improved from 0.63187 to 0.62540, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.5128 - accuracy: 0.8218 - val_loss: 0.6254 - val_accuracy: 0.8074\n",
      "Epoch 45/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5047 - accuracy: 0.8239\n",
      "Epoch 00045: val_loss improved from 0.62540 to 0.58736, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 0.5047 - accuracy: 0.8239 - val_loss: 0.5874 - val_accuracy: 0.8182\n",
      "Epoch 46/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5138 - accuracy: 0.8180\n",
      "Epoch 00046: val_loss did not improve from 0.58736\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.5138 - accuracy: 0.8180 - val_loss: 0.6436 - val_accuracy: 0.7981\n",
      "Epoch 47/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4923 - accuracy: 0.8336\n",
      "Epoch 00047: val_loss improved from 0.58736 to 0.57838, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.4923 - accuracy: 0.8336 - val_loss: 0.5784 - val_accuracy: 0.8175\n",
      "Epoch 48/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4744 - accuracy: 0.8343\n",
      "Epoch 00048: val_loss did not improve from 0.57838\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.4744 - accuracy: 0.8343 - val_loss: 0.6017 - val_accuracy: 0.8125\n",
      "Epoch 49/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4708 - accuracy: 0.8354\n",
      "Epoch 00049: val_loss did not improve from 0.57838\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.4708 - accuracy: 0.8354 - val_loss: 0.5875 - val_accuracy: 0.8096\n",
      "Epoch 50/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4594 - accuracy: 0.8431\n",
      "Epoch 00050: val_loss did not improve from 0.57838\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.4594 - accuracy: 0.8431 - val_loss: 0.6122 - val_accuracy: 0.7974\n",
      "Epoch 51/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4568 - accuracy: 0.8380\n",
      "Epoch 00051: val_loss improved from 0.57838 to 0.57102, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.4568 - accuracy: 0.8380 - val_loss: 0.5710 - val_accuracy: 0.8168\n",
      "Epoch 52/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4462 - accuracy: 0.8400\n",
      "Epoch 00052: val_loss improved from 0.57102 to 0.55058, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.4462 - accuracy: 0.8400 - val_loss: 0.5506 - val_accuracy: 0.8246\n",
      "Epoch 53/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4436 - accuracy: 0.8416\n",
      "Epoch 00053: val_loss did not improve from 0.55058\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.4436 - accuracy: 0.8416 - val_loss: 0.5803 - val_accuracy: 0.8089\n",
      "Epoch 54/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4294 - accuracy: 0.8484\n",
      "Epoch 00054: val_loss did not improve from 0.55058\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.4294 - accuracy: 0.8484 - val_loss: 0.5961 - val_accuracy: 0.8039\n",
      "Epoch 55/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4198 - accuracy: 0.8576\n",
      "Epoch 00055: val_loss improved from 0.55058 to 0.54260, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.4198 - accuracy: 0.8576 - val_loss: 0.5426 - val_accuracy: 0.8168\n",
      "Epoch 56/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4072 - accuracy: 0.8554\n",
      "Epoch 00056: val_loss improved from 0.54260 to 0.53255, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.4072 - accuracy: 0.8554 - val_loss: 0.5326 - val_accuracy: 0.8239\n",
      "Epoch 57/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4175 - accuracy: 0.8552\n",
      "Epoch 00057: val_loss did not improve from 0.53255\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.4175 - accuracy: 0.8552 - val_loss: 0.5464 - val_accuracy: 0.8196\n",
      "Epoch 58/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4117 - accuracy: 0.8568\n",
      "Epoch 00058: val_loss did not improve from 0.53255\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.4117 - accuracy: 0.8568 - val_loss: 0.5427 - val_accuracy: 0.8311\n",
      "Epoch 59/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4030 - accuracy: 0.8577\n",
      "Epoch 00059: val_loss improved from 0.53255 to 0.51704, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.4030 - accuracy: 0.8577 - val_loss: 0.5170 - val_accuracy: 0.8346\n",
      "Epoch 60/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3823 - accuracy: 0.8656\n",
      "Epoch 00060: val_loss did not improve from 0.51704\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.3823 - accuracy: 0.8656 - val_loss: 0.5384 - val_accuracy: 0.8275\n",
      "Epoch 61/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3795 - accuracy: 0.8672\n",
      "Epoch 00061: val_loss did not improve from 0.51704\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.3795 - accuracy: 0.8672 - val_loss: 0.5348 - val_accuracy: 0.8246\n",
      "Epoch 62/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3900 - accuracy: 0.8640\n",
      "Epoch 00062: val_loss improved from 0.51704 to 0.50780, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.3900 - accuracy: 0.8640 - val_loss: 0.5078 - val_accuracy: 0.8389\n",
      "Epoch 63/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3800 - accuracy: 0.8669\n",
      "Epoch 00063: val_loss improved from 0.50780 to 0.49411, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.3800 - accuracy: 0.8669 - val_loss: 0.4941 - val_accuracy: 0.8332\n",
      "Epoch 64/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3578 - accuracy: 0.8686\n",
      "Epoch 00064: val_loss did not improve from 0.49411\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.3578 - accuracy: 0.8686 - val_loss: 0.5157 - val_accuracy: 0.8346\n",
      "Epoch 65/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3692 - accuracy: 0.8690\n",
      "Epoch 00065: val_loss improved from 0.49411 to 0.49092, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.3692 - accuracy: 0.8690 - val_loss: 0.4909 - val_accuracy: 0.8404\n",
      "Epoch 66/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3548 - accuracy: 0.8754\n",
      "Epoch 00066: val_loss did not improve from 0.49092\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.3548 - accuracy: 0.8754 - val_loss: 0.5177 - val_accuracy: 0.8289\n",
      "Epoch 67/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3523 - accuracy: 0.8765\n",
      "Epoch 00067: val_loss did not improve from 0.49092\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.3523 - accuracy: 0.8765 - val_loss: 0.5225 - val_accuracy: 0.8318\n",
      "Epoch 68/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3336 - accuracy: 0.8817\n",
      "Epoch 00068: val_loss did not improve from 0.49092\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.3336 - accuracy: 0.8817 - val_loss: 0.5306 - val_accuracy: 0.8268\n",
      "Epoch 69/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3483 - accuracy: 0.8790\n",
      "Epoch 00069: val_loss improved from 0.49092 to 0.48921, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.3483 - accuracy: 0.8790 - val_loss: 0.4892 - val_accuracy: 0.8418\n",
      "Epoch 70/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3313 - accuracy: 0.8803\n",
      "Epoch 00070: val_loss improved from 0.48921 to 0.47975, saving model to saved_models_CNN\\weights.best.basic_cnn.hdf5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.3313 - accuracy: 0.8803 - val_loss: 0.4798 - val_accuracy: 0.8504\n",
      "Epoch 71/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3452 - accuracy: 0.8760\n",
      "Epoch 00071: val_loss did not improve from 0.47975\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.3452 - accuracy: 0.8760 - val_loss: 0.5088 - val_accuracy: 0.8225\n",
      "Epoch 72/72\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3332 - accuracy: 0.8814\n",
      "Epoch 00072: val_loss did not improve from 0.47975\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.3332 - accuracy: 0.8814 - val_loss: 0.5348 - val_accuracy: 0.8296\n",
      "Trained the model in: 0:00:40.190156\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Métricas <a name='id7'></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9005010724067688\n",
      "Testing Accuracy:  0.8296349048614502\n"
     ]
    }
   ],
   "source": [
    "score = model_basic.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model_basic.evaluate(x_val, y_val, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Matriz de confusión <a name='id8'></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def confusion_matrix(x_test, y_test, target):\n",
    "    predicted_vector = target.predict(x_test)\n",
    "    classes_x = np.argmax(predicted_vector, axis=1)\n",
    "    predicted_class = le.inverse_transform(classes_x)\n",
    "\n",
    "    classes_y = np.argmax(y_test, axis=1)\n",
    "    true_class = le.inverse_transform(classes_y)\n",
    "    print(classification_report(true_class, predicted_class))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      " air_conditioner       0.84      0.96      0.90       203\n",
      "        car_horn       0.74      0.98      0.84        86\n",
      "children_playing       0.83      0.66      0.74       183\n",
      "        dog_bark       0.99      0.63      0.77       201\n",
      "        drilling       0.86      0.86      0.86       206\n",
      "   engine_idling       0.84      0.93      0.88       193\n",
      "        gun_shot       0.90      0.96      0.93        72\n",
      "      jackhammer       0.92      0.95      0.94       208\n",
      "           siren       0.80      0.94      0.86       165\n",
      "    street_music       0.78      0.77      0.77       230\n",
      "\n",
      "        accuracy                           0.85      1747\n",
      "       macro avg       0.85      0.86      0.85      1747\n",
      "    weighted avg       0.85      0.85      0.84      1747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix(x_test, y_test, model_basic)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Heatmap <a name='id9'></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix as cf\n",
    "def heat_map(x_test, y_test, target):\n",
    "    predicted_vector = target.predict(x_test)\n",
    "    classes_x = np.argmax(predicted_vector, axis=1)\n",
    "    predicted_class = le.inverse_transform(classes_x)\n",
    "\n",
    "    classes_y = np.argmax(y_test, axis=1)\n",
    "    true_class = le.inverse_transform(classes_y)\n",
    "    ax = sns.heatmap(cf(true_class, predicted_class), annot=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "heat_map(x_test, y_test, model_basic)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predictiones <a name='id1'></a><a name='id10'></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def print_prediction(file_name, target):\n",
    "    prediction_feature = extract_features(file_name)\n",
    "    prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n",
    "\n",
    "    predicted_vector = target.predict(prediction_feature)\n",
    "    classes_x = np.argmax(predicted_vector, axis=1)\n",
    "    predicted_class = le.inverse_transform(classes_x)\n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n')\n",
    "\n",
    "    predicted_proba_vector = target.predict(prediction_feature)\n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)):\n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: air_conditioner \n",
      "\n",
      "air_conditioner \t\t :  0.93232434988021850585937500000000\n",
      "car_horn \t\t :  0.00002944457264675293117761611938\n",
      "children_playing \t\t :  0.00198938813991844654083251953125\n",
      "dog_bark \t\t :  0.00001823407365009188652038574219\n",
      "drilling \t\t :  0.00667552230879664421081542968750\n",
      "engine_idling \t\t :  0.02055497467517852783203125000000\n",
      "gun_shot \t\t :  0.00015482208982575684785842895508\n",
      "jackhammer \t\t :  0.03789340332150459289550781250000\n",
      "siren \t\t :  0.00030287238769233226776123046875\n",
      "street_music \t\t :  0.00005689940735464915633201599121\n"
     ]
    }
   ],
   "source": [
    "# Air conditioner\n",
    "file_name = 'samples/100852-0-0-0.wav'\n",
    "print_prediction(file_name, model_basic)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: drilling \n",
      "\n",
      "air_conditioner \t\t :  0.00000243364092966658063232898712\n",
      "car_horn \t\t :  0.00000258209252024244051426649094\n",
      "children_playing \t\t :  0.00001591095860931091010570526123\n",
      "dog_bark \t\t :  0.00001640665323066059499979019165\n",
      "drilling \t\t :  0.99586063623428344726562500000000\n",
      "engine_idling \t\t :  0.00007234972144942730665206909180\n",
      "gun_shot \t\t :  0.00000568887935514794662594795227\n",
      "jackhammer \t\t :  0.00052923709154129028320312500000\n",
      "siren \t\t :  0.00000022276857691849727416411042\n",
      "street_music \t\t :  0.00349460612051188945770263671875\n"
     ]
    }
   ],
   "source": [
    "# Drilling\n",
    "file_name = 'samples/103199-4-0-0.wav'\n",
    "print_prediction(file_name, model_basic)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: street_music \n",
      "\n",
      "air_conditioner \t\t :  0.00113205052912235260009765625000\n",
      "car_horn \t\t :  0.00691472319886088371276855468750\n",
      "children_playing \t\t :  0.02257700636982917785644531250000\n",
      "dog_bark \t\t :  0.00057672831462696194648742675781\n",
      "drilling \t\t :  0.00000466042138214106671512126923\n",
      "engine_idling \t\t :  0.00001532563692308031022548675537\n",
      "gun_shot \t\t :  0.00000000006087955833899982849289\n",
      "jackhammer \t\t :  0.00000135088612296385690569877625\n",
      "siren \t\t :  0.00485296547412872314453125000000\n",
      "street_music \t\t :  0.96392518281936645507812500000000\n"
     ]
    }
   ],
   "source": [
    "# Street music\n",
    "file_name = 'samples/101848-9-0-0.wav'\n",
    "print_prediction(file_name, model_basic)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: drilling \n",
      "\n",
      "air_conditioner \t\t :  0.00188682472798973321914672851562\n",
      "car_horn \t\t :  0.24110135436058044433593750000000\n",
      "children_playing \t\t :  0.00853456463664770126342773437500\n",
      "dog_bark \t\t :  0.14143005013465881347656250000000\n",
      "drilling \t\t :  0.24255423247814178466796875000000\n",
      "engine_idling \t\t :  0.00945129245519638061523437500000\n",
      "gun_shot \t\t :  0.11836099624633789062500000000000\n",
      "jackhammer \t\t :  0.21975129842758178710937500000000\n",
      "siren \t\t :  0.01350787747651338577270507812500\n",
      "street_music \t\t :  0.00342152873054146766662597656250\n"
     ]
    }
   ],
   "source": [
    "# Car horn\n",
    "file_name = 'samples/100648-1-0-0.wav'\n",
    "print_prediction(file_name, model_basic)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "# Serialize model to Json\n",
    "model_json = model_basic.to_json()\n",
    "with open('models/cnn.json', 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# Serialize weights to HDF5\n",
    "model_basic.save_weights('models/cnn.h5')\n",
    "print('Model saved')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the model and test it"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "json_file2 = open('models/cnn.json')\n",
    "loaded_model_json = json_file2.read()\n",
    "json_file2.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# Load weights into new model\n",
    "loaded_model.load_weights('models/cnn.h5')\n",
    "print('Model loaded')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test the loaded model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: street_music \n",
      "\n",
      "air_conditioner \t\t :  0.00113205052912235260009765625000\n",
      "car_horn \t\t :  0.00691472319886088371276855468750\n",
      "children_playing \t\t :  0.02257700636982917785644531250000\n",
      "dog_bark \t\t :  0.00057672831462696194648742675781\n",
      "drilling \t\t :  0.00000466042138214106671512126923\n",
      "engine_idling \t\t :  0.00001532563692308031022548675537\n",
      "gun_shot \t\t :  0.00000000006087955833899982849289\n",
      "jackhammer \t\t :  0.00000135088612296385690569877625\n",
      "siren \t\t :  0.00485296547412872314453125000000\n",
      "street_music \t\t :  0.96392518281936645507812500000000\n"
     ]
    }
   ],
   "source": [
    "file_name = 'samples/101848-9-0-0.wav'\n",
    "prediction_feature = extract_features(file_name)\n",
    "prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n",
    "\n",
    "predicted_vector = loaded_model.predict(prediction_feature)\n",
    "classes_x = np.argmax(predicted_vector, axis=1)\n",
    "predicted_class = le.inverse_transform(classes_x)\n",
    "print(\"The predicted class is:\", predicted_class[0], '\\n')\n",
    "\n",
    "predicted_proba_vector = loaded_model.predict(prediction_feature)\n",
    "predicted_proba = predicted_proba_vector[0]\n",
    "for i in range(len(predicted_proba)):\n",
    "    category = le.inverse_transform(np.array([i]))\n",
    "    print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Búsqueda de hiperparámetros <a name='id11'></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def cnn_tunning():\n",
    "    results = pd.DataFrame(columns=['epochs', 'kernel_size', 'train', 'val', 'time'])\n",
    "    kernel_list = [8, 16, 32]\n",
    "    epochs_list = [50, 100, 150]\n",
    "    for kernel in kernel_list:\n",
    "        for epoch in epochs_list:\n",
    "            print(f'Training model: Kernel -> {kernel} - Epochs -> {epoch}')\n",
    "            # Construct model\n",
    "            model = Sequential()\n",
    "            model.add(Conv2D(filters=kernel, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "            model.add(MaxPooling2D(pool_size=2))\n",
    "            model.add(Dropout(0.2))\n",
    "\n",
    "            model.add(Conv2D(filters=kernel*2, kernel_size=2, activation='relu'))\n",
    "            model.add(MaxPooling2D(pool_size=2))\n",
    "            model.add(Dropout(0.2))\n",
    "\n",
    "            model.add(Conv2D(filters=kernel*3, kernel_size=2, activation='relu'))\n",
    "            model.add(MaxPooling2D(pool_size=2))\n",
    "            model.add(Dropout(0.2))\n",
    "\n",
    "            model.add(Conv2D(filters=kernel*4, kernel_size=2, activation='relu'))\n",
    "            model.add(MaxPooling2D(pool_size=2))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(GlobalAveragePooling2D())\n",
    "\n",
    "            model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "            # Compile the model\n",
    "            model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "            checkpointer = ModelCheckpoint(\n",
    "                filepath='saved_models_CNN/weights.best.basic_cnn.hdf5',\n",
    "                verbose=1,\n",
    "                save_best_only=True\n",
    "            )\n",
    "            start = datetime.now()\n",
    "            model.fit(x_train, y_train, batch_size=num_batch_size, epochs=epoch, validation_data=(x_val, y_val), verbose=0)\n",
    "\n",
    "            duration = datetime.now() - start\n",
    "\n",
    "            score_train = model.evaluate(x_train, y_train, verbose=0)\n",
    "\n",
    "            score_val = model.evaluate(x_val, y_val, verbose=0)\n",
    "            results.loc[len(results)] = [epoch, kernel, score_train[1], score_val[1], duration]\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: Kernel -> 8 - Epochs -> 50\n",
      "Training model: Kernel -> 8 - Epochs -> 100\n",
      "Training model: Kernel -> 8 - Epochs -> 150\n",
      "Training model: Kernel -> 16 - Epochs -> 50\n",
      "Training model: Kernel -> 16 - Epochs -> 100\n",
      "Training model: Kernel -> 16 - Epochs -> 150\n",
      "Training model: Kernel -> 32 - Epochs -> 50\n",
      "Training model: Kernel -> 32 - Epochs -> 100\n",
      "Training model: Kernel -> 32 - Epochs -> 150\n"
     ]
    }
   ],
   "source": [
    "tunning_results = cnn_tunning()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "  epochs kernel_size     train       val                   time\n0     50           8  0.608805  0.581246 0 days 00:00:19.657822\n1    100           8  0.726020  0.690050 0 days 00:00:36.898316\n2    150           8  0.762527  0.730852 0 days 00:00:53.667048\n3     50          16  0.826235  0.797423 0 days 00:00:24.213938\n4    100          16  0.901933  0.843235 0 days 00:00:47.145021\n5    150          16  0.947208  0.871152 0 days 00:01:08.602828\n6     50          32  0.927881  0.875447 0 days 00:00:41.869337\n7    100          32  0.987115  0.921976 0 days 00:01:19.543911\n8    150          32  0.993737  0.921260 0 days 00:02:01.024631",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epochs</th>\n      <th>kernel_size</th>\n      <th>train</th>\n      <th>val</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50</td>\n      <td>8</td>\n      <td>0.608805</td>\n      <td>0.581246</td>\n      <td>0 days 00:00:19.657822</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100</td>\n      <td>8</td>\n      <td>0.726020</td>\n      <td>0.690050</td>\n      <td>0 days 00:00:36.898316</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>150</td>\n      <td>8</td>\n      <td>0.762527</td>\n      <td>0.730852</td>\n      <td>0 days 00:00:53.667048</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50</td>\n      <td>16</td>\n      <td>0.826235</td>\n      <td>0.797423</td>\n      <td>0 days 00:00:24.213938</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100</td>\n      <td>16</td>\n      <td>0.901933</td>\n      <td>0.843235</td>\n      <td>0 days 00:00:47.145021</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>150</td>\n      <td>16</td>\n      <td>0.947208</td>\n      <td>0.871152</td>\n      <td>0 days 00:01:08.602828</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>50</td>\n      <td>32</td>\n      <td>0.927881</td>\n      <td>0.875447</td>\n      <td>0 days 00:00:41.869337</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>100</td>\n      <td>32</td>\n      <td>0.987115</td>\n      <td>0.921976</td>\n      <td>0 days 00:01:19.543911</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>150</td>\n      <td>32</td>\n      <td>0.993737</td>\n      <td>0.921260</td>\n      <td>0 days 00:02:01.024631</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tunning_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Entrenamiento del modelo calibrado <a name='id12'></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# Construct model\n",
    "model_tunned = Sequential()\n",
    "model_tunned.add(Conv2D(filters=32, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model_tunned.add(MaxPooling2D(pool_size=2))\n",
    "model_tunned.add(Dropout(0.2))\n",
    "\n",
    "model_tunned.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "model_tunned.add(MaxPooling2D(pool_size=2))\n",
    "model_tunned.add(Dropout(0.2))\n",
    "\n",
    "model_tunned.add(Conv2D(filters=96, kernel_size=2, activation='relu'))\n",
    "model_tunned.add(MaxPooling2D(pool_size=2))\n",
    "model_tunned.add(Dropout(0.2))\n",
    "\n",
    "model_tunned.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "model_tunned.add(MaxPooling2D(pool_size=2))\n",
    "model_tunned.add(Dropout(0.2))\n",
    "model_tunned.add(GlobalAveragePooling2D())\n",
    "\n",
    "model_tunned.add(Dense(num_labels, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "22/22 [==============================] - 1s 44ms/step - loss: 4.6280 - accuracy: 0.1650 - val_loss: 2.1679 - val_accuracy: 0.2169\n",
      "Epoch 2/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 1.9161 - accuracy: 0.3178 - val_loss: 1.9022 - val_accuracy: 0.3930\n",
      "Epoch 3/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 1.6070 - accuracy: 0.4284 - val_loss: 1.6388 - val_accuracy: 0.4603\n",
      "Epoch 4/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 1.4272 - accuracy: 0.4918 - val_loss: 1.5301 - val_accuracy: 0.4882\n",
      "Epoch 5/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 1.3247 - accuracy: 0.5408 - val_loss: 1.4607 - val_accuracy: 0.5025\n",
      "Epoch 6/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 1.2301 - accuracy: 0.5702 - val_loss: 1.3190 - val_accuracy: 0.5540\n",
      "Epoch 7/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 1.1532 - accuracy: 0.5966 - val_loss: 1.2195 - val_accuracy: 0.6034\n",
      "Epoch 8/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 1.0736 - accuracy: 0.6328 - val_loss: 1.1541 - val_accuracy: 0.6342\n",
      "Epoch 9/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 1.0281 - accuracy: 0.6450 - val_loss: 1.1220 - val_accuracy: 0.6342\n",
      "Epoch 10/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.9878 - accuracy: 0.6596 - val_loss: 1.0370 - val_accuracy: 0.6893\n",
      "Epoch 11/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.9486 - accuracy: 0.6707 - val_loss: 1.0726 - val_accuracy: 0.6571\n",
      "Epoch 12/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.9251 - accuracy: 0.6836 - val_loss: 1.0115 - val_accuracy: 0.6757\n",
      "Epoch 13/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.8507 - accuracy: 0.7049 - val_loss: 0.9247 - val_accuracy: 0.7008\n",
      "Epoch 14/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.8029 - accuracy: 0.7267 - val_loss: 0.8827 - val_accuracy: 0.7273\n",
      "Epoch 15/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.7912 - accuracy: 0.7323 - val_loss: 0.8574 - val_accuracy: 0.7215\n",
      "Epoch 16/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.7270 - accuracy: 0.7586 - val_loss: 0.8418 - val_accuracy: 0.7344\n",
      "Epoch 17/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.7400 - accuracy: 0.7443 - val_loss: 0.8386 - val_accuracy: 0.7316\n",
      "Epoch 18/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.7136 - accuracy: 0.7534 - val_loss: 0.7833 - val_accuracy: 0.7473\n",
      "Epoch 19/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.6762 - accuracy: 0.7684 - val_loss: 0.7489 - val_accuracy: 0.7437\n",
      "Epoch 20/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.6457 - accuracy: 0.7822 - val_loss: 0.7167 - val_accuracy: 0.7731\n",
      "Epoch 21/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.6380 - accuracy: 0.7835 - val_loss: 0.6932 - val_accuracy: 0.7860\n",
      "Epoch 22/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.5917 - accuracy: 0.8001 - val_loss: 0.6912 - val_accuracy: 0.7831\n",
      "Epoch 23/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.5937 - accuracy: 0.8006 - val_loss: 0.6583 - val_accuracy: 0.7974\n",
      "Epoch 24/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.5815 - accuracy: 0.8015 - val_loss: 0.6424 - val_accuracy: 0.8074\n",
      "Epoch 25/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.5601 - accuracy: 0.8116 - val_loss: 0.6465 - val_accuracy: 0.7974\n",
      "Epoch 26/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.5195 - accuracy: 0.8210 - val_loss: 0.6478 - val_accuracy: 0.7938\n",
      "Epoch 27/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.5190 - accuracy: 0.8253 - val_loss: 0.5818 - val_accuracy: 0.8268\n",
      "Epoch 28/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.5136 - accuracy: 0.8286 - val_loss: 0.6111 - val_accuracy: 0.7946\n",
      "Epoch 29/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.4793 - accuracy: 0.8361 - val_loss: 0.5672 - val_accuracy: 0.8175\n",
      "Epoch 30/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.4662 - accuracy: 0.8447 - val_loss: 0.5576 - val_accuracy: 0.8346\n",
      "Epoch 31/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.4593 - accuracy: 0.8447 - val_loss: 0.5506 - val_accuracy: 0.8311\n",
      "Epoch 32/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.4476 - accuracy: 0.8477 - val_loss: 0.5317 - val_accuracy: 0.8346\n",
      "Epoch 33/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.4181 - accuracy: 0.8579 - val_loss: 0.5188 - val_accuracy: 0.8404\n",
      "Epoch 34/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.4125 - accuracy: 0.8631 - val_loss: 0.4868 - val_accuracy: 0.8533\n",
      "Epoch 35/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.4277 - accuracy: 0.8540 - val_loss: 0.4804 - val_accuracy: 0.8533\n",
      "Epoch 36/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.3941 - accuracy: 0.8665 - val_loss: 0.4559 - val_accuracy: 0.8611\n",
      "Epoch 37/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.3684 - accuracy: 0.8801 - val_loss: 0.4832 - val_accuracy: 0.8504\n",
      "Epoch 38/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.3752 - accuracy: 0.8756 - val_loss: 0.4420 - val_accuracy: 0.8618\n",
      "Epoch 39/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.3629 - accuracy: 0.8756 - val_loss: 0.4387 - val_accuracy: 0.8719\n",
      "Epoch 40/150\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.3506 - accuracy: 0.8776 - val_loss: 0.4421 - val_accuracy: 0.8647\n",
      "Epoch 41/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.3476 - accuracy: 0.8819 - val_loss: 0.4371 - val_accuracy: 0.8669\n",
      "Epoch 42/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.3292 - accuracy: 0.8901 - val_loss: 0.4597 - val_accuracy: 0.8719\n",
      "Epoch 43/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.3099 - accuracy: 0.8941 - val_loss: 0.4438 - val_accuracy: 0.8669\n",
      "Epoch 44/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.3166 - accuracy: 0.8930 - val_loss: 0.4119 - val_accuracy: 0.8898\n",
      "Epoch 45/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.3195 - accuracy: 0.8933 - val_loss: 0.4287 - val_accuracy: 0.8747\n",
      "Epoch 46/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.3042 - accuracy: 0.8962 - val_loss: 0.4123 - val_accuracy: 0.8876\n",
      "Epoch 47/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.2822 - accuracy: 0.9064 - val_loss: 0.4147 - val_accuracy: 0.8747\n",
      "Epoch 48/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.2787 - accuracy: 0.9064 - val_loss: 0.3794 - val_accuracy: 0.8941\n",
      "Epoch 49/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.2806 - accuracy: 0.9023 - val_loss: 0.4315 - val_accuracy: 0.8640\n",
      "Epoch 50/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.2805 - accuracy: 0.9030 - val_loss: 0.4017 - val_accuracy: 0.8805\n",
      "Epoch 51/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.2634 - accuracy: 0.9111 - val_loss: 0.3754 - val_accuracy: 0.8948\n",
      "Epoch 52/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.2706 - accuracy: 0.9057 - val_loss: 0.3835 - val_accuracy: 0.8869\n",
      "Epoch 53/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.2471 - accuracy: 0.9157 - val_loss: 0.3890 - val_accuracy: 0.8941\n",
      "Epoch 54/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.2553 - accuracy: 0.9162 - val_loss: 0.3721 - val_accuracy: 0.8790\n",
      "Epoch 55/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.2487 - accuracy: 0.9127 - val_loss: 0.3623 - val_accuracy: 0.9041\n",
      "Epoch 56/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.2519 - accuracy: 0.9123 - val_loss: 0.3748 - val_accuracy: 0.8933\n",
      "Epoch 57/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.2533 - accuracy: 0.9112 - val_loss: 0.3970 - val_accuracy: 0.8826\n",
      "Epoch 58/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.2305 - accuracy: 0.9166 - val_loss: 0.3494 - val_accuracy: 0.9098\n",
      "Epoch 59/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.2174 - accuracy: 0.9225 - val_loss: 0.3340 - val_accuracy: 0.9141\n",
      "Epoch 60/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.2120 - accuracy: 0.9291 - val_loss: 0.3596 - val_accuracy: 0.8941\n",
      "Epoch 61/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.2185 - accuracy: 0.9248 - val_loss: 0.3679 - val_accuracy: 0.8933\n",
      "Epoch 62/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.2168 - accuracy: 0.9264 - val_loss: 0.3807 - val_accuracy: 0.8905\n",
      "Epoch 63/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.2126 - accuracy: 0.9304 - val_loss: 0.3513 - val_accuracy: 0.9041\n",
      "Epoch 64/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1976 - accuracy: 0.9297 - val_loss: 0.3464 - val_accuracy: 0.9120\n",
      "Epoch 65/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.1768 - accuracy: 0.9386 - val_loss: 0.3225 - val_accuracy: 0.9148\n",
      "Epoch 66/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.1951 - accuracy: 0.9340 - val_loss: 0.3634 - val_accuracy: 0.8969\n",
      "Epoch 67/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1889 - accuracy: 0.9350 - val_loss: 0.3206 - val_accuracy: 0.9134\n",
      "Epoch 68/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.2000 - accuracy: 0.9298 - val_loss: 0.3298 - val_accuracy: 0.9141\n",
      "Epoch 69/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1767 - accuracy: 0.9359 - val_loss: 0.3547 - val_accuracy: 0.9048\n",
      "Epoch 70/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1825 - accuracy: 0.9377 - val_loss: 0.3693 - val_accuracy: 0.9005\n",
      "Epoch 71/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.1860 - accuracy: 0.9361 - val_loss: 0.3507 - val_accuracy: 0.9091\n",
      "Epoch 72/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1800 - accuracy: 0.9384 - val_loss: 0.3257 - val_accuracy: 0.9091\n",
      "Epoch 73/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1756 - accuracy: 0.9392 - val_loss: 0.3148 - val_accuracy: 0.9091\n",
      "Epoch 74/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1652 - accuracy: 0.9427 - val_loss: 0.3213 - val_accuracy: 0.9141\n",
      "Epoch 75/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1761 - accuracy: 0.9401 - val_loss: 0.3429 - val_accuracy: 0.9105\n",
      "Epoch 76/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1585 - accuracy: 0.9460 - val_loss: 0.3145 - val_accuracy: 0.9198\n",
      "Epoch 77/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1509 - accuracy: 0.9485 - val_loss: 0.3253 - val_accuracy: 0.9105\n",
      "Epoch 78/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1461 - accuracy: 0.9503 - val_loss: 0.3090 - val_accuracy: 0.9198\n",
      "Epoch 79/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1363 - accuracy: 0.9553 - val_loss: 0.3128 - val_accuracy: 0.9198\n",
      "Epoch 80/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1308 - accuracy: 0.9558 - val_loss: 0.3005 - val_accuracy: 0.9313\n",
      "Epoch 81/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1426 - accuracy: 0.9440 - val_loss: 0.3351 - val_accuracy: 0.9141\n",
      "Epoch 82/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1404 - accuracy: 0.9495 - val_loss: 0.3542 - val_accuracy: 0.9034\n",
      "Epoch 83/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1309 - accuracy: 0.9547 - val_loss: 0.3185 - val_accuracy: 0.9198\n",
      "Epoch 84/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1341 - accuracy: 0.9563 - val_loss: 0.3199 - val_accuracy: 0.9184\n",
      "Epoch 85/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1427 - accuracy: 0.9520 - val_loss: 0.3615 - val_accuracy: 0.9069\n",
      "Epoch 86/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1331 - accuracy: 0.9515 - val_loss: 0.3223 - val_accuracy: 0.9198\n",
      "Epoch 87/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1310 - accuracy: 0.9540 - val_loss: 0.3260 - val_accuracy: 0.9162\n",
      "Epoch 88/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1163 - accuracy: 0.9617 - val_loss: 0.3354 - val_accuracy: 0.9155\n",
      "Epoch 89/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1149 - accuracy: 0.9601 - val_loss: 0.3181 - val_accuracy: 0.9184\n",
      "Epoch 90/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1175 - accuracy: 0.9613 - val_loss: 0.3464 - val_accuracy: 0.9170\n",
      "Epoch 91/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1325 - accuracy: 0.9549 - val_loss: 0.3047 - val_accuracy: 0.9298\n",
      "Epoch 92/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1107 - accuracy: 0.9621 - val_loss: 0.3484 - val_accuracy: 0.9084\n",
      "Epoch 93/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1127 - accuracy: 0.9606 - val_loss: 0.3214 - val_accuracy: 0.9241\n",
      "Epoch 94/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1093 - accuracy: 0.9639 - val_loss: 0.3185 - val_accuracy: 0.9270\n",
      "Epoch 95/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1114 - accuracy: 0.9603 - val_loss: 0.3187 - val_accuracy: 0.9177\n",
      "Epoch 96/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1051 - accuracy: 0.9649 - val_loss: 0.3084 - val_accuracy: 0.9205\n",
      "Epoch 97/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1100 - accuracy: 0.9658 - val_loss: 0.2989 - val_accuracy: 0.9306\n",
      "Epoch 98/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0988 - accuracy: 0.9640 - val_loss: 0.3497 - val_accuracy: 0.9112\n",
      "Epoch 99/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1100 - accuracy: 0.9613 - val_loss: 0.3231 - val_accuracy: 0.9184\n",
      "Epoch 100/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0951 - accuracy: 0.9647 - val_loss: 0.3375 - val_accuracy: 0.9162\n",
      "Epoch 101/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0915 - accuracy: 0.9683 - val_loss: 0.3434 - val_accuracy: 0.9205\n",
      "Epoch 102/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.1131 - accuracy: 0.9606 - val_loss: 0.3028 - val_accuracy: 0.9198\n",
      "Epoch 103/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1045 - accuracy: 0.9655 - val_loss: 0.3396 - val_accuracy: 0.9191\n",
      "Epoch 104/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0930 - accuracy: 0.9681 - val_loss: 0.3065 - val_accuracy: 0.9327\n",
      "Epoch 105/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0921 - accuracy: 0.9714 - val_loss: 0.3442 - val_accuracy: 0.9162\n",
      "Epoch 106/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0978 - accuracy: 0.9667 - val_loss: 0.3646 - val_accuracy: 0.9184\n",
      "Epoch 107/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1029 - accuracy: 0.9642 - val_loss: 0.3187 - val_accuracy: 0.9263\n",
      "Epoch 108/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0915 - accuracy: 0.9683 - val_loss: 0.3238 - val_accuracy: 0.9198\n",
      "Epoch 109/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.1002 - accuracy: 0.9676 - val_loss: 0.2943 - val_accuracy: 0.9248\n",
      "Epoch 110/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0976 - accuracy: 0.9647 - val_loss: 0.3214 - val_accuracy: 0.9248\n",
      "Epoch 111/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0924 - accuracy: 0.9705 - val_loss: 0.3035 - val_accuracy: 0.9277\n",
      "Epoch 112/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0791 - accuracy: 0.9742 - val_loss: 0.3114 - val_accuracy: 0.9270\n",
      "Epoch 113/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0852 - accuracy: 0.9698 - val_loss: 0.3381 - val_accuracy: 0.9270\n",
      "Epoch 114/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0816 - accuracy: 0.9723 - val_loss: 0.3659 - val_accuracy: 0.9184\n",
      "Epoch 115/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0800 - accuracy: 0.9723 - val_loss: 0.3174 - val_accuracy: 0.9227\n",
      "Epoch 116/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0822 - accuracy: 0.9710 - val_loss: 0.3162 - val_accuracy: 0.9263\n",
      "Epoch 117/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0787 - accuracy: 0.9737 - val_loss: 0.3198 - val_accuracy: 0.9291\n",
      "Epoch 118/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0799 - accuracy: 0.9707 - val_loss: 0.3254 - val_accuracy: 0.9277\n",
      "Epoch 119/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0743 - accuracy: 0.9741 - val_loss: 0.3312 - val_accuracy: 0.9248\n",
      "Epoch 120/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0833 - accuracy: 0.9701 - val_loss: 0.3339 - val_accuracy: 0.9248\n",
      "Epoch 121/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0913 - accuracy: 0.9685 - val_loss: 0.3283 - val_accuracy: 0.9327\n",
      "Epoch 122/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0811 - accuracy: 0.9723 - val_loss: 0.3393 - val_accuracy: 0.9234\n",
      "Epoch 123/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0777 - accuracy: 0.9719 - val_loss: 0.2953 - val_accuracy: 0.9291\n",
      "Epoch 124/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0789 - accuracy: 0.9726 - val_loss: 0.2952 - val_accuracy: 0.9349\n",
      "Epoch 125/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0738 - accuracy: 0.9755 - val_loss: 0.3110 - val_accuracy: 0.9298\n",
      "Epoch 126/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0685 - accuracy: 0.9775 - val_loss: 0.2955 - val_accuracy: 0.9306\n",
      "Epoch 127/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0731 - accuracy: 0.9755 - val_loss: 0.3209 - val_accuracy: 0.9263\n",
      "Epoch 128/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0677 - accuracy: 0.9776 - val_loss: 0.3481 - val_accuracy: 0.9263\n",
      "Epoch 129/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0736 - accuracy: 0.9742 - val_loss: 0.3111 - val_accuracy: 0.9313\n",
      "Epoch 130/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0765 - accuracy: 0.9733 - val_loss: 0.3419 - val_accuracy: 0.9234\n",
      "Epoch 131/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0722 - accuracy: 0.9741 - val_loss: 0.3176 - val_accuracy: 0.9270\n",
      "Epoch 132/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0679 - accuracy: 0.9782 - val_loss: 0.2874 - val_accuracy: 0.9363\n",
      "Epoch 133/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0740 - accuracy: 0.9749 - val_loss: 0.3263 - val_accuracy: 0.9248\n",
      "Epoch 134/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0748 - accuracy: 0.9766 - val_loss: 0.3036 - val_accuracy: 0.9306\n",
      "Epoch 135/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0650 - accuracy: 0.9771 - val_loss: 0.3379 - val_accuracy: 0.9320\n",
      "Epoch 136/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0678 - accuracy: 0.9771 - val_loss: 0.3070 - val_accuracy: 0.9284\n",
      "Epoch 137/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0692 - accuracy: 0.9749 - val_loss: 0.3267 - val_accuracy: 0.9277\n",
      "Epoch 138/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0580 - accuracy: 0.9810 - val_loss: 0.3315 - val_accuracy: 0.9320\n",
      "Epoch 139/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0567 - accuracy: 0.9796 - val_loss: 0.3414 - val_accuracy: 0.9256\n",
      "Epoch 140/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0755 - accuracy: 0.9742 - val_loss: 0.3227 - val_accuracy: 0.9356\n",
      "Epoch 141/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0750 - accuracy: 0.9715 - val_loss: 0.3390 - val_accuracy: 0.9263\n",
      "Epoch 142/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0711 - accuracy: 0.9748 - val_loss: 0.3117 - val_accuracy: 0.9320\n",
      "Epoch 143/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0659 - accuracy: 0.9760 - val_loss: 0.3270 - val_accuracy: 0.9298\n",
      "Epoch 144/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0550 - accuracy: 0.9803 - val_loss: 0.2960 - val_accuracy: 0.9320\n",
      "Epoch 145/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0465 - accuracy: 0.9851 - val_loss: 0.3350 - val_accuracy: 0.9341\n",
      "Epoch 146/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0567 - accuracy: 0.9796 - val_loss: 0.3349 - val_accuracy: 0.9263\n",
      "Epoch 147/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0598 - accuracy: 0.9812 - val_loss: 0.3296 - val_accuracy: 0.9227\n",
      "Epoch 148/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0515 - accuracy: 0.9821 - val_loss: 0.3441 - val_accuracy: 0.9277\n",
      "Epoch 149/150\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0610 - accuracy: 0.9821 - val_loss: 0.3131 - val_accuracy: 0.9284\n",
      "Epoch 150/150\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0693 - accuracy: 0.9775 - val_loss: 0.3315 - val_accuracy: 0.9284\n",
      "Trained the model in: 0:02:06.925878\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model_tunned.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='saved_models_CNN/weights.best.basic_cnn.hdf5',\n",
    "    verbose=1,\n",
    "    save_best_only=True\n",
    ")\n",
    "start = datetime.now()\n",
    "model_tunned.fit(x_train, y_train, batch_size=num_batch_size, epochs=150, validation_data=(x_val, y_val), verbose=1)\n",
    "duration = datetime.now() - start\n",
    "print(f'Trained the model in: {duration}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Métricas <a name='id13'></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9973157048225403\n",
      "Validation accuracy: 0.9284180402755737\n"
     ]
    }
   ],
   "source": [
    "score_train = model_tunned.evaluate(x_train, y_train, verbose=0)\n",
    "print(f'Training accuracy: {score_train[1]}')\n",
    "score_val = model_tunned.evaluate(x_val, y_val, verbose=0)\n",
    "print(f'Validation accuracy: {score_val[1]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testeo del modelo <a name='id14'></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: air_conditioner \n",
      "\n",
      "air_conditioner \t\t :  0.99999630451202392578125000000000\n",
      "car_horn \t\t :  0.00000006697479904005376738496125\n",
      "children_playing \t\t :  0.00000000167404823336880781425862\n",
      "dog_bark \t\t :  0.00000000000075765787957773889083\n",
      "drilling \t\t :  0.00000021185903165132913272827864\n",
      "engine_idling \t\t :  0.00000014702264650168217485770583\n",
      "gun_shot \t\t :  0.00000000366393448913981956138741\n",
      "jackhammer \t\t :  0.00000017999784063249535392969847\n",
      "siren \t\t :  0.00000001099093882572788061224855\n",
      "street_music \t\t :  0.00000296965458801423665136098862\n"
     ]
    }
   ],
   "source": [
    "# Air conditioner\n",
    "file_name = 'samples/100852-0-0-0.wav'\n",
    "print_prediction(file_name, model_tunned)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: drilling \n",
      "\n",
      "air_conditioner \t\t :  0.00000000000000026979293742271989\n",
      "car_horn \t\t :  0.00000000000024457202213966355853\n",
      "children_playing \t\t :  0.00000000000000706878386526983357\n",
      "dog_bark \t\t :  0.00000000000000000018919165110388\n",
      "drilling \t\t :  1.00000000000000000000000000000000\n",
      "engine_idling \t\t :  0.00000000000000000346369101566116\n",
      "gun_shot \t\t :  0.00000000000000021787157799637479\n",
      "jackhammer \t\t :  0.00000000378456110894376251962967\n",
      "siren \t\t :  0.00000000000000000009114571984047\n",
      "street_music \t\t :  0.00000000059555377296405254128331\n"
     ]
    }
   ],
   "source": [
    "# Drilling\n",
    "file_name = 'samples/103199-4-0-0.wav'\n",
    "print_prediction(file_name, model_tunned)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: street_music \n",
      "\n",
      "air_conditioner \t\t :  0.00000001049017406273833330487832\n",
      "car_horn \t\t :  0.00000000674281652734975978091825\n",
      "children_playing \t\t :  0.00010638760431902483105659484863\n",
      "dog_bark \t\t :  0.00000350892128153645899146795273\n",
      "drilling \t\t :  0.00000001670273874765371147077531\n",
      "engine_idling \t\t :  0.00000000044320253023144573489844\n",
      "gun_shot \t\t :  0.00000000000000000014077409443886\n",
      "jackhammer \t\t :  0.00000000001790111982258313361172\n",
      "siren \t\t :  0.00000002098840390374334674561396\n",
      "street_music \t\t :  0.99989008903503417968750000000000\n"
     ]
    }
   ],
   "source": [
    "# Street music\n",
    "file_name = 'samples/101848-9-0-0.wav'\n",
    "print_prediction(file_name, model_tunned)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: car_horn \n",
      "\n",
      "air_conditioner \t\t :  0.00008723148494027554988861083984\n",
      "car_horn \t\t :  0.77237874269485473632812500000000\n",
      "children_playing \t\t :  0.00090009614359587430953979492188\n",
      "dog_bark \t\t :  0.09703276306390762329101562500000\n",
      "drilling \t\t :  0.07019501924514770507812500000000\n",
      "engine_idling \t\t :  0.00024893652880564332008361816406\n",
      "gun_shot \t\t :  0.01377445738762617111206054687500\n",
      "jackhammer \t\t :  0.04301467537879943847656250000000\n",
      "siren \t\t :  0.00208531599491834640502929687500\n",
      "street_music \t\t :  0.00028278314857743680477142333984\n"
     ]
    }
   ],
   "source": [
    "# Car horn\n",
    "file_name = 'samples/100648-1-0-0.wav'\n",
    "print_prediction(file_name, model_tunned)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Matriz de confusión <a name='id15'></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      " air_conditioner       0.94      0.95      0.94       203\n",
      "        car_horn       0.92      0.94      0.93        86\n",
      "children_playing       0.85      0.91      0.88       183\n",
      "        dog_bark       0.97      0.86      0.91       201\n",
      "        drilling       0.86      0.95      0.90       206\n",
      "   engine_idling       0.98      0.95      0.97       193\n",
      "        gun_shot       0.96      0.96      0.96        72\n",
      "      jackhammer       0.98      0.90      0.94       208\n",
      "           siren       0.94      0.98      0.96       165\n",
      "    street_music       0.87      0.87      0.87       230\n",
      "\n",
      "        accuracy                           0.92      1747\n",
      "       macro avg       0.93      0.93      0.93      1747\n",
      "    weighted avg       0.92      0.92      0.92      1747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix(x_test, y_test, model_tunned)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Heatmap <a name='id16'></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD8CAYAAABJsn7AAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA+F0lEQVR4nO2dd3wUVfeHn7NJSAESSiCUIMUSRV8FlChiAUFAERULig0Vxcarovyw6ytW7NgFAbGAoqiIIoggoIJ0BKRIVQhpBAg9be/vj93EAEl2k+zM7o7n4TMfZu/M3HPvzOzJ3TN3zleMMSiKoij24wp2AxRFUf6tqANWFEUJEuqAFUVRgoQ6YEVRlCChDlhRFCVIqANWFEUJEuqAFUVRykBEmonITyKySkT+EJF7vOX1RGS6iKzz/l/XWy4i8rqIrBeR5SLSzpcNdcCKoihlUwjcb4xpDZwB3CUirYEHgRnGmGOBGd7PABcAx3qXAcA7vgyoA1YURSkDY0y6MWaJd30PsBpoClwCjPXuNha41Lt+CfCh8fAbUEdEGldkI9KKhpcmb8Nvtr1qV/OEy+0y5UgiXPb9PS5yu22zpVSP2jVibbO1c+96qW4dBds3+u1zajQ4+jY8o9ViRhhjRhy+n4i0ANoC84EkY0y6d1MGkORdbwpsKXXYVm9ZOuVguQNWFEWxFXeR37t6ne0RDrc0IlILmAjca4zZLfLP3whjjBGRKg8y1QEriuIsTOB+XYlIFB7n+4kx5ktvcaaINDbGpHtDDFne8jSgWanDk71l5aIxYEVRnIXb7f9SAeIZ6o4CVhtjXim16Rugn3e9HzCpVPkN3tkQZwC5pUIVZaIjYEVRHIUJ3Ai4I3A9sEJElnnLHgaeByaISH/gL6CPd9sU4EJgPbAfuMmXAXXAiqI4i6LCgFRjjPkFKO+hYJcy9jfAXZWxoQ5YURRnUYmHcMEmIDHglJSU0SkpKVkpKSkry9q+e88+7n1qOJff+QjX3Ps/1m3eWm2b+QUF/N9zb9Gz//9xzb1PkpaZDUBsTATJTWJJbhpLcpNYYmMiyq2je7dO/LFyDmtW/cKQ/6vUH65KY5ctu+xER0fzy8+TWbhgGkuX/Mhjj91nmS1w5rWy05adfbrjrpuYu/B75i6YwvtjXiU6uoal9o7AuP1fgkygHsJ9APQob+PICZNJaXUUE99+hmfuH8Cw9z7xu+K0zGxufuC5I8q/nDaH+Fo1+W7Ui1zfuzuvjZ4AQJHbkJ55kK1pB8jKzqNhg+gy63W5XLw+/Bku6nUd/zmlM1dddSknnHCs3+2qDHbZsrNPeXl5dO9xFe1Tu9M+tQfdzu9EampbS2w58VrZacvOPjVunMRtd9zAeWdfypmpF+KKiOCyKy6yxFa5BOghnB0ExAGvXbt2DrCjvO0b/95G6imtAWjZrAnbMrPJ2ZkLwLczf+Wae//HlQMfY+gbYygq8u+kzPptCRd3PQuA889qz/zfVwGQn++mqMgzLS+/wE3pOXulSW3flg0bNrNp098UFBQwYcIkLu7V3b8OVxK7bNnZJ4B9+/YDEBUVSVRUJFbJWznxWtlpy+77IjIykpjYGCIiIoiLjSEjPcv3QQHEGLffS7Dx6YBF5HgRecCbZOJ17/oJlTFyXMtmzJi7CIAVazeQnpVD5vYdbPx7G1PnLGDsS4/y+ZtP4XK5+G7WXL/qzMzZSVKDegBERkRQKy6Ww1/kqhkXQV5+2fGgJk0bsWXrtpLPW9PSadKkUWW65Td22bKzT+AZWS2YP5WtW5YxY8bPLFy4zBI7TrxWdtqys0/p6Zm88fr7rFg9hzUb5rF79x5+mvmLJbbKJYxGwBU+hBORB4C+wKfAAm9xMjBeRD41xjxfznED8L7e9+bTD9C/z0UMe/djrhz4GMc2T+b4o5vjcrmY//sfrF6/mWvufRKAg3n51EuIB+Dep4aTlrmdgoJC0rNzuHLgYwBce/H5XNrtHJ8di4pyUb9eNNsyDvg+C0qVcLvdpJ7eg4SEeCZMGEnr1imsWrU22M1SgkhCnXgu7NmVNid1JnfXbj746A36XHUJEz6b5PvgQFFUYJ+tauJrFkR/4ERjzCE9EpFXgD/wzIc7gtKv9xXngnjqvluLt3HBTYNJbtyQJX/8ycVdOnLPTX2OqOO1x+4BPDHgx155n9HDHjpke1L9umRm76BRYj0Ki4rYu/9AyR+0iAihUVIMWdkHKSws+2fxtrQMmiU3Kfmc3LQx27Zl+DgdVcMuW3b2qTS5ubuZPXsu3bt1ssQBO/Fa2WnLzj516tyRvzZvJWe7JyI5+ZtppJ7Rzl4HHAKhBX/xFYJwA03KKG/s3eYXu/fuo6DAMzdv4rTZtDvpOGrFxXJ6m9ZM/3URObt2A5C7Zy/bMrf7VWen09vyzY+enzbTf1lI6smeqIjLBY2TYtixI4+DeeU3ceGiZRxzTEtatGhGVFQUffpcwuRvf/C3S5XCLlt29ikxsR4J3l8rMTExdOlyDmvXrrfElhOvlZ227OzT1i3bOC21DbGxMQCc2+lMy+6LcnFKCAK4F5ghIuv4J8vPUcAxwMDinVJSUsYDnYDElJSUrcATQBTA8ilj2bQlnUdfHgEiHNO8KU/e0x+Ao49qysDrL+f2R1/E7XYTGRnBw3feQJOkRJ8N7939HB5+aQQ9+/8fCbVr8sIDd/LORz8RHx9FVJSLunVqULeOZ9/0jIMUuQ8dCRcVFXHPvY8y5btxRLhcfDD2M1at+tOn3apgly07+9SoUUNGvf8qERERuFwuvpg4mSnfz7DElhOvlZ227OzT4kW/883XU5n16ySKCotY/vsqxo7+zBJb5RJGI2Dx9eRaRFxAKp60auBJLrHQGOPXbGdNRxk+aDpKpSzCLR1l3vJpfvuc6JO7V9tedfD5JpzxzNX4zYa2KIqiVBvjds5DOEVRlPAijH5dqQNWFMVZhFEMWB2woijOIoyS8agDVhTFWegIWFEUJUhoDPgfatk4NeyDxM622bpx+0+22XIids79sW0epEPZkx9mr/MHKCG7HegIWFEUZ6EjYEVRlODg5ztifiEio4GLgCxjzEness+AFO8udYBdxpg2ItICWA0UJ0T5zRhze0X1qwNWFMVZBHYE/AHwJvBhcYEx5qridRF5Gcgttf8GY0wbfytXB6woirMI4CwIY8wc78j2CLyy9X2A86pav30v/yuKotiBfdnQzgYyjTHrSpW1FJGlIjJbRM72VYGOgBVFcRaVmAVRWjzCywhvPnN/6AuML/U5HTjKGJMjIqcCX4vIicaY3eVVEHIj4JEjXiZt6+8sXWpNasPjb+3BRT89z0Uzn+Ost+/CFR3FcTedzyW/vsx12z4mul4tS+w6Tf3WTlVkq++Jw1FV5PCxVSaVUEU2xowwxpxWavHL+YpIJHAZUJJr0xiTZ4zJ8a4vBjYAx1VUT8g54LEfTuCii661pO7YRnU5vn83vr/gMb497yHE5aLFJWeQvfBPfrzqOfZuybbErhPVb+1URbbynjgcVUUOH1vlYk8IoiuwxhiztbhARBqISIR3vRVwLLCxokpCzgH/8st8duzcZVn9EhlBREwNJMJFRGwNDmTuZOfKv9i31T8ljqrgVPVbu1SRrb4nSqOqyOFjq1wC6IBFZDwwD0gRka0i0t+76WoODT8AnAMsF5FlwBfA7caYctXiIQQdsJUcyNjJqnem0HvhcC5f9iYFe/aTPnul5XadqH4L9qki24mqIoePrXKpRAjCZ1XG9DXGNDbGRBljko0xo7zlNxpj3j1s34nGmBONMW2MMe2MMZN91V9lBywiN1WwbYCILBKRRW73vqqaCDg1EuJo1r0dX58+iIlt/0tkXDQtL+sY7GaFLcWqyK2OTuW09m1o3TrF90GKYjVFhf4vQaY6I+Any9tQOrDtctWshonA0ujsk9i7JZu8HXswhUX8PWURiadZH59yovptaUqrIoc7qoocPrbKJYxEOSt0wCKyvJxlBZBkUxsDxr60HBLbHUNEbA0AGp11IrvXp1lu14nqt3aqItuJqiKHj61yCWAIwmp8zQNOAroDOw8rF2CuFQ366KO3OPecDiQm1mPTxkUMHfoSYz74NCB15yzdwN/fLeDCaU9jCovYsfIv1n38Eyn9u9H6jouIbZhAzx+fY9vM3/lt8PsBsQnOVL+1UxXZynvicFQVOXxslUsIjGz9pUJVZBEZBYwxxvxSxrZxxphrfBmIqtHUtmyAYzQdZbWwUxXZbeOXRNNRhg+F+WnVzlR6YMJQvy95bJ/HQ1cV2RjTv4JtPp2voiiK7Vg0HdIK9FVkRVGcRWHwZzf4izpgRVGcRQg8XPMXdcCKojiLMHoIpw5YURRnoTFgRVGUIKEj4H/wJI23Bzunhu35+DbbbNW+7j1b7BTZeOMGde6PA7BzymCd6NB5m9Uv1AEriqIEB1MUOFFOq1EHrCiKs9ARsKIoSpDQaWiKoihBwq2zIBRFUYKDhiAURVGCRBg9hAspSaLk5Mb8MG0Cvy+bybKlMxg4sNxcQAHBl3prg8RoWhwVR7OmsWUe/8Evq+jz1hT6vDWFy9/4lnaPjyN3f1612pRfWMSQz36m16uTuO69qaTt3AtAbEwEyU1iSW4aS3KTWGJjIqrUp0Bily1VRa4eVitYv/bmM/yx/ldmz/umpKzXpd2Z/dtk0neu4pS2JwXUnk+ckpDdbgoLixjywFBOaXMeZ519MXfc3o8Tjg+eeuuevQVsyzhYbh03ntWaCXddyIS7LuTu89twaouGJMRF+2U/bede+o+afkT5V4s3EB9bg8mDLuG6Dscz/IelABS5DemZB9madoCs7DwaNjjSjlPVb1UVuXpYrWD96bivuPryWw8pW7NqHTdfdzfzfl0UMDt+4zb+Lz4QkdEikiUiK0uV/U9E0kRkmXe5sNS2h0RkvYisFRGfaqQh5YAzMrJYtszTz71797FmzTqaNLVG0M8f9daDB924/Qzof798Mz1OblHy+btlm7j23an0eWsKT02a7/dLDrPWbKVXm1YAdD3xKBZszAQgP99NUZGnLfkF7jJfcHGq+q2qIlcfKxWsf5u7iF07cw8pW/fnRjas3xQwG5UisIoYHwA9yih/1Su+2cYYMwVARFrjUUs+0XvM28Uy9eXh0wGLyPEi0kVEah1WXlajAkbz5smccspJLFiw1JL6A6neeiC/kLnr0+nauhkAG7NymbbyLz64tRsT7roQl0uY8vtmv+rK2r2fRgmeN48iI1zUio7i8JeeasZFkJd/ZJzrX6d+awFOPYdOVLAulwCOgI0xc4AKpeVLcQnwqTEmzxizCVgPpFZ0QIUP4UTkbuAuYDUwSkTuMcZM8m5+FphaznEDgAEAERF1cEVU7lXGmjXj+OzTEQwe/D/27NlbqWODwZy1W2lzVIOS8MOCjRms3raDa9/1nJ68gkLq1YwBYNC42aTt3EdhURHpufvp89YUAK7pkMKl7Y72aSsqykX9etFsyzhgUW8UJ1KsYJ2QEM+ECSNp3TqFVavWBrtZlmAqEdst7au8jDDGjPDj0IEicgOwCLjfGLMTaAr8Vmqfrd6ycvE1C+JW4FRjzF4RaQF8ISItjDHDqeB1fm8HRgDUiE6u1G+dyMhIPvtsBOM//YqvJ31fmUMrRSDVW6eu+Ise/2le8tkAvdq05O5uR8bZXr3mXMATA378y3mM6n/+IdsbxseRkbuPpIQ4Covc7M0rKHlWEBEhNEqKISv7IIWFR57Wf536rQU4/RyWVrB2qgOuzCyI0r6qErwDPIXnq/4U8DJwcyXrAHyHIFzGmL0AxpjNQCfgAhF5BYvyqYx47yXWrFnP8OEjrai+hECpt+45mM/izVl0PqFZSVlqq0ZM/2MLO/Z6HuDl7s9j2y7/RvLnHt+Uycs2AvDjH3/TvqVHfNrlgsZJMezYkcfBvLL/wv/r1G8twInn0KkK1uUSwBBEWRhjMo0xRcYYNzCSf8IMaUCzUrsme8vKxdcIOFNE2hhjlnkN7xWRi4DRwH+q0viKOPPM9lx33RWsWLGahQumAfDY48OYOnVmoE35pd7asEE0sTERREQIzZvFsWNnPoc/+5q5agsdjm5MbI1/TuXRDRMY2PVkbh87E2MMkREuHrqoPU3q1MIXvdsdwyMT59Lr1UnEx0YzrE9H3v12FfHxUURFuahbpwZ163j2Tc84SFGpm8ip6reqilw9rFawfnfUy5x5Vnvq1a/L0lWzePG5N9i5M5dnX3iU+on1+GTCu6xcsYarL7slYDYrxOLpZSLS2BiT7v3YGyieIfENMM47QG0CHAssqLAuH6rIyUChMeaI30Ui0tEY86uvxlY2BFEd3DYmYnZiOko7sTMdZfi8mOo/Tk1HmZm7ptq3xr7Hr/b7ktcc+mmF9kRkPJ5f/olAJvCE93MbPLfWZuC2YocsIo/gCUcUAvcaYyqMo/pSRd5awTafzldRFMV2ApiMxxjTt4ziURXs/wzwjL/166vIiqI4C03GoyiKEhxMYfjkglAHrCiKs9ARsKIoSpDQhOyKoihBQkfAwcHOqU3NbvnYNlt7Jj9ki50GvV+2xQ5AXmG+bbZcNipz2zkV0i525e0LdhMqhVEHrCiKEiT0IZyiKEqQ0BGwoihKkFAHrCiKEhwCmWzeatQBK4riLMJoBBxSkkR2inJaLfQ4/K1nWb1hHj//9m1JWZ26CXzx9RgWLP2BL74eQ0Kd+JJtNROgbkNISCy7vg9mLKHPsPH0GTaey5/7hHb3vEnuvvL16vwhv6CIIWO+p9fQD7nu5QlEeMVToqOFBkmRNEyKpEFSJDWiy55FkJBQm48/eZslS39k8ZLpAdUZK42dopyhJgwbCKwW5QyWrXKxOB1lIAkpB2ynKKfVQo+ffvIlV1126Jf3nkEDmDN7HqltuzFn9jzuGfRPIv68A7C7AuGTG7u0Y8IDfZnwQF/uvuhMTj2mKQlelQ1fpOXspv/rXx5R/tVvfxAfF8Pkx2/guk5tiK/j8cBuN+RkF5KVWcjOHUXUq1f2D6UXXnyC6dNn065tV844/ULLcszaKcoZasKwgcBqUc5g2SoPU+j2ewk2IeWA7RTltFrocd7cRew8TKjwgp5d+GzcVwB8Nu4rLryoa8m2wnzwN3T1/ZI/6XHqP1/U7xau4dqXPqPPsPE89elM/wVAV2yiV+rxAHRtcwzR0Z7boaDAlKRULSwwR+RABoiPr03Hs1IZ+8Fn3mMKyM3d418HKomdopyhJgwbKKwU5QymrTJxV2IJMv6IcqaKSHvvemsRua+0DLNVWC3KGQwaNEgkMzMbgMzMbBo0KCfeUAEH8guYu/ovup5yDAAbM3Ywbck6Phh0BRMe6IvL5WLKIv+kZrJy99KoTm3AIwBqDEcIgMbECvkFR36BmrdIZvv2Hbz73ov8Ou9b3nz7eeLiYivdn1AmnIRhfWGnKGewBUCN2/i9BBtfopxPABcAkSIyHTgd+Al4UETaenNflnXcv0qUs6pUZWQwZ+Um2rRsXBJ+WPDnFlZvyebalyYAXgHQWh5HOOj970jL2U1hYRHpO/fSZ9h4AK459xQuPaO1T1uRkUJCnUi2ZxWUsS2SNm1OZPD9/2PRwmW88OLj3D/4Dp4a+kql+xSKOO0etFOUM+gCoCHgWP3F1yyIK/Bkfo8GMoBkY8xuEXkJmE85iYfDQZQzGGRnbycpqQGZmdkkJTVg+/acStcxdck6epx6XMlnY6BX6vHcffGZR+z76i09AU8M+PFPfmTU3Zcdsr1hQi0ydu0hqW4tCovciPyj5uKKgPqJkezMKSxT4zAtLZ20tAwWeUc3X3/1PfcNvr3S/QlFwlEY1l/sFOUMmgBoCIQW/MVXCKLQKz63H9hgjNkNYIw5gEXdtEuUMxhMnTKTq67pDcBV1/Tm++8q91R/z4E8Fq9Po/N/WpWUpR7XjOm/r2fHHk/cLXffQbbt2O1Xfeee1JLJC9YA8OOy9eR5xT5FIDExktzcQvLzy/77mZW5nbSt6Rx7rKctnTqfyZrVzhB6DDdhWF/YKcoZCgKgjglBAPkiEud1wKcWF4pIAhY4YDtFOa0Wehwx+hU6npVKvfp1Wb56DsOefZ3hr45g1AfDue6GK9jy9zb633hPyf616kBUDRAX1GkIB/ZwRHahmcs30uH4o4iNjiopO7pxPQb2PIPb357kEQB1uXjoyk40qRePL3p3aM0jH02n19APiY+LZvcuz1C3Vm0XEZFC7fgIanuryckuPELr8P77n2DUmFepEVWDTZv/5o7b/q8qp8ondopyhpowbCCwWpQzWLbKwxQGzrGKyGjgIiDLGHOSt+xFoBeQD2wAbjLG7BKRFsBqoHi4/5sxpsKfhb5EOaONMXlllCcCjY0xK3x1wE5RTjuftibE2CdUuOXzu22x49RsaOLAbGh2inLaSd7BLdW+WDsuOdfvi1Bv0mxfopznAHuBD0s54G7ATGNMoYgMAzDGPOB1wN8W7+cPFV7Fspyvt3y7P85XURTFbozb/8VnXcbMAXYcVvaDMabQ+/E3ILmqbXXmn1FFUf69VGIesIgMEJFFpZYB5VVbDjcDpZ/UthSRpSIyW0TO9nWw5oJQFMVRVEaRqPSMrcoiIo8AhcAn3qJ04ChjTI6InAp8LSInFk9eKAt1wIqiOIqS4ICFiMiNeB7OdTHeh0/ekG2ed32xiGwAjgMWlVePOmBFURyF1ZqcItIDGAKc650hVlzeANhhjCkSkVbAscDGiupSB6woiqMIpAMWkfFAJyBRRLYCTwAP4Xk5bbp3hk3xdLNzgKEiUoAnyny7MaaCFFs+pqEFgqgaTYM/29kC7OyUXZOo9m2capMliGvVwzZbdoq12jXlzc4ply4bp7wFYhpaZqdOfp+cpFmz7Lw9jkBHwIqiOAqrQxCBRB2woiiOwriDOqitFOqAFUVxFO4idcCKoihBQUMQiqIoQUJDEIqiKEEijFTpQy8XhF0KuHYq7YI96rdQtX5FRAiNG8VwyU33cunN9/LxxO+q3Y5J02bR84aB9LxhIJOmzQLgwME87nz4WXrdeDfNmsZSr24Nv+sL5fNXVZykAl5MKKgiG7f4vQSbkHPAding2qm0a5f6LVS9Xzk78pk05jU+efM5Pp00lQ2bt/h13E33PU5aRtYhZbm79/DORxMY9+ZzjHvred75aAK5XlmfG6+8mMkfvM6WtAPExEQQFxvh00Y4nL+q4CQV8GJCQRXZXSR+L8Em5BywXQq4dirt2ql+W5V+FRUZ8vM9Ty5qxsXSsnlTMrfvYMu2DG5/8Gn63D6Efvc8ysa/0/yq79dFv9Oh3SkkxNcmoXYtOrQ7hV8XLiM2JprUtv+kSs3LKyIi0veXINTPX1Vxkgp4aYKtiuzoEbCIfGhFQ5yMneq31SUtI4s16zdz8gnH8uQr7/LQwP5MePcF7r/9Bp7xU6Ina3sOjRrWL/mc1KAeWYfp37lcUDMukgMHyhCcO4xwOn9VxUkq4EFXRTbi9xJsfKkif3N4EdBZROoAGGMuLue4ElVkV0QCLpd96hFK1dl/4ACD/vcSD9x5Iy6XsOyPP7l/6D8qGfkFHnXkr6bO5JMvpwDwd1oGdz70LFFRkTRt1JDhQ4f4tFNYVERSgxhydxdQGED5mHBFFZgDi5OmoSUDq4D38aQ/EOA0oELtmtI5Np2aC6IyBEP9tioM+t9L9OxyNl3PPoO9+/ZTu1YcX4x46Yj9evc4j949zgM8MeCnhwykaaOGJdsbJtZn4bI/Sj5nZu+gfZsTSz4/+cq75Be4yd19pNx9WYTL+asKTlYBD5YqsjsERrb+4isEcRqwGHgEyDXGzAIOGGNmG2NmW904p2CX+m11aJAYTaujkul3ZS8AatWMo2mjhkybPRfwJH9Zu2GzX3V1PO0U5i3+ndw9e8nds5d5i3+n42mnAPD66PHs3befnB3+a8KFw/mrKk5TAQ8JVeQwCkH40oRzG2NeBW4CHhGRN7F47vBHH73Fz3O+IeW4o9m0cRE33Xh1WNuBQ9VvVy6fxRdfTLZE/Raq1q/oaBe1a0cxf+kKrhgwmCsGDGbO/CU8//A9fPX9TC6/9X4uvXkQM39d6FcbEuJrc9t1l9P3zgfpe+eD3Hb9FSTE1yYjO4eRn0xkw19bSW4SS3KTWGrX8n07hfr5qyrFCsydO3Vk4YJpLFwwjR7eXxaBxq5+NWrUkB+mfcaihT8w99dvmTFjju2qyOE0C6JS6ShFpCfQ0RjzsL/HODUEoekoq4emo6wemo6yfFYd3dPvk9N6w3fhk47SGPMdUP1Z+oqiKBYRTjFgfRVZURRHEQqxXX9RB6woiqPQXBCKoihBwm3E78UXIjJaRLJEZGWpsnoiMl1E1nn/r+stFxF5XUTWi8hyEWnnq351wIqiOAq3W/xe/OAD4PAnxg8CM4wxxwIzvJ8BLsCjhHwsnhfR3vFVuTpgRVEcRSBHwMaYOcDhysaXAGO962OBS0uVf2g8/AbUEZHGFdXvqBiwXVOAAFsDTXZZqmnj1LC9v/kcHASMWmfcYZutsApA+ondyXSqS2UewpVOm+BlhPdN3opIMsake9czgCTvelOgdBrBrd6ydMrBUQ5YURSlMtPQSqdNqArGGCMiVf4LpSEIRVEchanEUkUyi0ML3v+LE2KnAc1K7ZfsLSsXdcCKojiKIrfL76WKfAP08673AyaVKr/BOxviDDz5c8oNP4CGIBRFcRiBzEYpIuOBTkCiiGwFngCeByaISH/gL6CPd/cpwIXAemA/nhw6FaIOWFEUR2ECmP3DGNO3nE1dytjXAJUSLFQHrCiKo3CH0aSNkIsB26Xe6kRFWrBPPRh896tBYjTNj4ojuWlsmdv37D/Af18czZUPvELvwS/x9Sz/0l1WRO7e/dz2zAh6DRrGbc+MYPdejz5ZrZqRJDeNJblpLE0bx1KjRvm3vhMVmJ34vSoPN+L3EmxCzgHbpd7qREVaO9WDwXe/9uwtID3jYLnbP/thLq2aJvH5sPsY9fjtvPzxZAoKC/2yvXDVBh5759MjykdPmknqSccw+dUHSD3pGEZ98xMABYVutqUfYGvaAXbuyqdB/egy63WqArMTv1flYRC/l2ATcg7YLvVWJyrS2qkeDL77dfCgG3cFvwcFYf+BPIwx7D+YT0KtOCK8uWc/mDyLax4ZzhVDXubtz6f53aafFq/i4nNOA+Dic07jp0UeaaS8PDdu79OZg3lFRJajxuxUBWYnfq/Kowjxewk2lXLAInKWiNwnIt2salAwcIoibbipB1/d/Uw2bsui651PccWQlxlywyW4XC7mLl/L3xnb+eTpu5nw/CBWbUpj8eqNftW5I3cPDep6JHES69RmR+6eI/apXSuK/eWoMYfbOQxlgvW9cldiCTa+VJEXGGNSveu34nnC9xXwhIi0M8Y8X85xYaOK7DRF2nBi7vI/Ob55E95/9Da2ZOZw27MjaHd8S+Yt/5N5y//kqodeBWD/wXz+ytjOqSe04tpHX6egsJD9B/PJ3bufPg++AsA9fXvS8ZSUQ+oXETjs9fSYmAjia0eRlr7fnk7+Swnm9yoUHKu/+JoFEVVqfQBwvjEmW0ReAn7DMx/uCMJFFdlpirThph48adZCbr6kMyLCUY0SadqgHpu2ZWEM3HxJZ67s2uGIYz55+m7AEwP+ZvZCnrrjUG2zegm1yd65mwZ148neuZt68bWAbABqRLlomBhNesaBknDE4YTbOQxFgv29CoXYrr/4CkG4RKSuiNTHox+XDWCM2Qf497QkhHGaIm24qQc3SqzD/JUexdycXXvYnJ5NcsP6nHnKcXw9ayH7D+YBkLkjl5xc/0ZRnU5tzTdzFgHwzZxFdD61NQCREUKjpBgysw9SUFj+mCDczmEoEuzvlVv8X4KNLwecgEeWfhFQr9T7z7WwSOvQLvVWJyrS2qkeDL771bBBNE0axxIV5eKoZnHUrhVJ7dqeBWBA764s+3Mzlw95mVufeY97+15I3fianHlyChd2bMv1j7/J5UNeZvBrH7L/YPmzKUpz88Wd+W3FOnoNGsb8leu4+RLPNa1btwYul9CgfjTJTWJp2qTsqXFOVWB24veqPMJpGlqlVJFLDhKJw5OSbZOvfe0MQdiZjtLOFH12WbLzdtzj0HSUwf9KBx47v1f5eVurbezLRtf4/ZW5LGNc+KgiF2OM2Q/4dL6Koih247YzL3g10VeRFUVxFCH71L8M1AEriuIonDQNTVEUJawIhdkN/qIOWFEURxEKrxj7izpgRVEchY6AS2FrQDzM1FtDDTvPnp1Tw55t3Nk2W4+k/2SLHTuvVbipImsMWFEUJUiE058LdcCKojiKQIUgRCQF+KxUUSvgcaAOcCvFSUbgYWPMlKrYUAesKIqjCFQIwhizFmgDICIReCTmv8IjtvmqMeal6tpQB6woiqMosuYhXBdggzHmr0C+mh1yihiKoijVoTIJ2UVkgIgsKrUMKKfaq4HxpT4PFJHlIjJaROpWta3qgBVFcRSVccDGmBHGmNNKLSMOr09EagAXA597i94BjsYTnkgHXq5qW0POAasibfWwUxXZSbai4+O45J276T/jBfrPGEaTdsfQ4ISjuParJ7hp2nNcNuo+atQqO4VlVdH7whpMJRY/uQBYYozJBDDGZBpjiowxbmAkkFrVtoaUA1ZF2uph5/lzmq0uT1zPptnLGdVlCGN6PEzO+m30GHYLc57/jDHdH2LdtEWk3tYzoDb1vrAGCxKy96VU+KE4L7qX3sDKqrY1pBywKtJWDzvPn5Ns1agdS/LpKSz/dBYA7oIi8nbvp17LRmyZvwaAzT+v5LgL2gfMJuh9YRWBFOUUkZrA+cCXpYpfEJEVIrIc6AwMqmpbK3TAInK6iMR712NF5EkRmSwiw0QkoapGy0MVaauHnefPSbbqNGvAgZw9XPDSAPpNeZoew24hKjaa7eu2cky3UwFI6Xk68Y3rBcymnTjpWvlDUSUWXxhj9hlj6htjckuVXW+M+Y8x5mRjzMXGmPSqttXXCHg0UCwfOxyPRNEwb9mY8g4q/WTR7d5X1bYpii24IiJIOqkFyz6ewdgLHyV/fx6n39mL7/9vJG2v78oN3z5FjZoxFBWEvQziv4Jw0oTzNQ/YZYwpvutOM8a0867/IiLLyjuotCpyZCUkiVSRtnrYef6cZGtPxg72pO8gfdkGAP6csoDT7+zFLy9/wefXDwOgbstGHH1em4DZtBMnXSt/CKdcEL5GwCtF5Cbv+u8ichqAiBwHFAS6MapIWz3sPH9OsrUvO5fd6Tuo18rzbKV5xxPJWZdGXP14zw4idPjvJSz7xPrZClbgpGvlDxbMgrAMXyPgW4DhIvIosB2YJyJbgC3ebQGltCJthMvFB2M/s1SR9txzOpCYWI9NGxcxdOhLjPng07C2Zef5c5qtGU+M5aLhd+CKiiT37yymDB7BSZefTdsbugLw59RFrJgwJ6A29b6wBndIuFb/8EsV2fsgriUeh721eD6cP1QmBFFdQiCkYwnhczuFJpqOMnwozE+r9td4aPNr/T49j//1SeirIhtjdgO/W9wWRVGUahNOMWBNxqMoiqMIhdkN/qIOWFEURxFOMWB1wIqiOIrwcb/qgBVFcRgaA1YURQkSRWE0BrbcAUe47Mv3U+S2729fGMX5/aZJLftyHWzbu8M2Ww/bNDUMYN/SD22xU7PtDbbYgfC713UErCiKEiT0IZyiKEqQCB/3qw5YURSHoSEIRVGUIKEP4RRFUYJEOMWAQ0qSKDo6ml9+nszCBdNYuuRHHnvsPkvtOVEA1Mo+vfjGUJasncX0X/9RZxn0wB0sWPkj38/+nO9nf07nrmcH1GYxoSQq2SAxmhZHxdGsadkinbv37ufe59/j8kFPc82QYaz7a1uZ+1WG/IIC/u+l9+l55xNc88ALREZ65ibExkSQ3CSW5KaxJDeJJTYmokp9CiR23u9lEU7pKEPKAefl5dG9x1W0T+1O+9QedDu/E6mpbS2x5UQBUKv79Pm4Sdxw5R1HlL//7kdccO6VXHDulfz0488Bs1dMqIlK7tlbwLaMg+XWMXLiVFJaJjPx1Ud55u5+DBv9ebn7Hk5aVg43P/bqEeVf/jiX+FpxfPf2k1zf6zzq160BQJHbkJ55kK1pB8jKzqNhg+gq9SmQ2Cl4WxZujN+LL0Rks1f/bZmILPKW1ROR6SKyzvt/3aq2NaQcMMC+fR4FpKioSKKiIvEnXWZVcKIAqNV9WjBvMbt25vreMcCEmqjkwYNu3O7y78uNW9JJ/U8KAC2TG7EtK4ecXbsB+Hb2fK4ZMowr73uWoe+Mo6jIv0dGsxYu5+LOZwBwfoe2xMZ6oof5+W6KijxtyS9wI3LkrF27hTLtFLwti0CKcnrpbIxpY4w5zfv5QWCGMeZYYIb3c5XwJcp5t4g0q2rlVcHlcrFg/lS2blnGjBk/s3DhMkvshIJ4YKAJVp/63dKXaT9P5MU3hpKQEB/w+sNNVPK4FsnM+G0ZACvWbSY9eweZObvYuDWdqb8uZuyzg/n8lYdxuYTv5izwq87MnF0k1fcMtCIjInC7DYe/41QzLoK8/COlJp14r1eEqcS/KnIJMNa7Pha4tKoV+XoI9xTwoIhsAMYDnxtjsn1VKiIDgAEAEZF1iIio5XeD3G43qaf3ICEhngkTRtK6dQqrVq31+3jFXj4aPYHhL76HMYbBDw/k0acH83//fTzYzQoq/S/rxrBRn3Plfc9ybPMmHN8yGZdLmL98Las3bOGaIR6duYP5+dRLqA3Avc+/R1pWDgWFhaRv38mV9z0LwLU9O3Nplw4+bUZFuahfL5ptGQes61iYUJlZEKV9lZcRXk3LYgzwg4gY4D3vtqRSSsgZQFJV2+rLAW8ETgW6AlcBT4rIYjzO+EtjzJ6yDiotyhkd06xKf2Zyc3cze/ZcunfrZIkDDgXxwEATjD5tz84pWR//4UTGfPpmwG2Em6hkrbhYnvqv51VhYwwX3P4YyUmJLFm1nos7n8491116xDGvPXgb4IkBP/bGh4x+atAh25Pq1yEzZyeNEutSWFSEyyUUv3kfESE0SoohK/sghYVHft2ceK9XRGXmAZf2VeVwljEmTUQaAtNFZM1hxxuvc64SvmLAxhjjNsb8YIzpDzQB3gZ64HHOASUxsV7JT9iYmBi6dDmHtWvXB9oMEBrigYEmGH1qmJRYst79oi6sXR346xVuopK79+2nwCthP/HHX2nX+hhqxcVy+snHM33eUnJ2ecYtuXv2sS0rp6KqSujU/mS++ek3AKbPW8qBA576XS5onBTDjh15HMwr2/U48V6vCLcxfi++MMakef/PAr4CUoFMEWkM4P0/q6pt9TUCPiSib4wpAL4BvhGRuKoaLY9GjRoy6v1XiYiIwOVy8cXEyUz53pqpLE4UALW6T2+MHEaHju2pW78O81f+yCvPv0WHju1p/Z/jMcaw9e80HrpvaMDsFRNqopING0QTGxNBRITQvFkcO3bmU/rZ16atGTz6+ocgcEyzxjx51/UAHN2sMQP79uL2oW/gNm4iIyJ4+NaradKwvs929e5yJg8P/4Cedz5BQq04cnbmAxAfH0VUlIu6dWpQt45n3/SMgxSVekhot1CmnYK3ZRGox/YiUhNwGWP2eNe7AUPx+MB+wPPe/ydV2UZFswxE5DhjTLWuVFVDEFXBqdnQ7DqBTs2GZieaDa16FARAlPOa5r39/sqM++urcu2JSCs8o17wDFbHGWOeEZH6wATgKOAvoI8xpko3dIUj4Oo6X0VRFLupxuyGQ+sxZiNwShnlOUCXQNjQV5EVRXEUhSHxjpt/qANWFMVRBGoEbAfqgBVFcRSajlJRFCVIWJW+wArUASuK4ijCKR2l5Q7YzqlhTsWuaUBOnRpmJ3ZND9vzvn3T0OJvsWdqXaDQhOyKoihBQkfAiqIoQUJjwIqiKEEinIKe6oAVRXEUOg9YURQlSGgMWFEUJUgUmfAJQoScJlwoqd8GCjtVYp2iwKy2fKsvAyz8K5s+I2dw2XvT6f/RnGq3J7+wiCFfzqfX29O4bsxPpO3aB3jUl5t61ZebNoklphz1ZQgFVWTLJYkCRkg54FBTvw0UdqrEOkWBWW35Vl/efTCf56YuY3ifDnx52/m8eFmq37bTdu0r02F/tWwz8TE1mHxnd65LPYbhM1cCHvXlDB/qy8UEXRU5gAnZrSakHHCoqd8GCjtVYp2iwKy2fKsvf79yC+elNKFxgkcboV7NmJJt3634m2tH/0SfkTN4asqSQxK0V8Ssden0OvkoALqe0JQFmz0SkKXVlwvKUV8uJtiqyKYSS7DxpYpcQ0RuEJGu3s/XiMibInKXiEQFujHhpn77b8ap1yqcbP21Yy+7DxbQ/6M59B01k8nL/wJg4/bdTFu1lQ/6ncuEW7vgEmHKyr/9qjNrz0EaxXtCHpEuF7Wio/xWXw4V3Bi/l2Dj6yHcGO8+cSLSD6gFfIknGXEqHjmOIyitNCoRCbhcNQPWYEVRPBS5DavTdzLi2rM5WFjEDR/M4uSm9ViwKZvVGbu4dvRPAOQVFlGvpidkMOjzeaTt2k+h20167n76jPTEaa9JPZpLT2nh02ZUlIt69aJJD2H15VBwrP7iywH/xxhzsohEAmlAE2NMkYh8DPxe3kGllUYjazT1+2yEm/rtvxmnXqtwspUUH0tCbA1ia0QSWyOSU49KZG1WLgbodfJR3N35pCOOefVKj8R92q59PD55MaOuP+eQ7Q1rx5Cx+wBJ8XEUut3szSs4RH05qQL15VDBSbMgXCJSA6gNxAEJ3vJoIOAhiHBTv/0349RrFU62Oh3XmGVbcyh0uzlQUMiKbTtpVb82qS0aMH11Gjv2eR7g5R7IZ1vufr/qPPfYxkxe7glX/Lg6jfYtGgAe9eVGXvXlvHLUl0OFQM2CEJFmIvKTiKwSkT9E5B5v+f9EJE1ElnmXC6vaVl8j4FHAGiACeAT4XEQ2AmcAAZc5DTX120Bhp0qsUxSY1ZZv9eVWifGc2SqJPiNnICL0btOCYxp6xkgDO53I7eN+xWCIdLl4qEcbmiT4FjLv3aYFj0xaRK+3pxEfU4NhvVN5b8ractWXy3pIGHRV5MDNbigE7jfGLBGR2sBiEZnu3faqMeal6hqoUBUZQESaABhjtolIHaAr8LcxZoE/BioTgggn7FSKtQtHXiiH4tR0lIFQRW7X+Cy/b+Ul6b/4bU9EJgFvAh2BvYFwwD6noRljthljtnnXdxljvvDX+SqKotiNMcbvxV9EpAXQFpjvLRooIstFZLSI1K1qW0NqHrCiKEp1KcLt9yIiA0RkUallwOH1iUgtYCJwrzFmN/AOcDTQBkgHXq5qWzUXhKIojqIyb7iVnrFVFt73HSYCnxhjvvQek1lq+0jg26q2VUfAiqI4igDOghA8ExFWG2NeKVXeuNRuvYGVVW2rjoAVRXEUAczx0BG4HlghIsu8ZQ8DfUWkDZ7n1puB26pqQB2woiiOIlBZzowxv1D2hKcpATGADQ444vAXyS3ETi2oRjWr/OCz0mTu32WLHZfYd60Kiwpts+XE6XUJt35km6392362zVYgCIUsZ/6iI2BFURxFOL2KrA5YURRHEQqJ1v1FHbCiKI7C6AhYURQlODgpHaWiKEpYYefD+OqiDlhRFEcRTiPgkHoTLjo6ml9+nszCBdNYuuRHHnvsPstsJSc35odpE/h92UyWLZ3BwIH9A1r/i28MZcnaWUz/9cuSskEP3MGClT/y/ezP+X7253TuenZAbYK95xA8wpLz5k1h4sTRltmwW2U3VFSRA0VV7/WICKFRUgwXXzuAS669jY8mfF3ttkyaMp0Lr+rPhVf1Z9IUT2bHAwcPcsfgx+nV91ZSUlL+SElJeb46Norcbr+XYBNSDjgvL4/uPa6ifWp32qf2oNv5nUhNbWuJrcLCIoY8MJRT2pzHWWdfzB239+OE4wOnfvv5uEnccOUdR5S//+5HXHDulVxw7pX89GPg51faeQ4BBg68mbVr11tWP9irshtKqsiBojr3+o6d+XzzyQjGjXiVT7/8lg2b/vLruBsHDiEtPfOQstzde3hnzDjGj3yN8SNf450x48jdvQeAm/pezuTxI8GTcaxjSkrKBZXo4iGoLH012LfPk7k/KiqSqKhIy+I5GRlZLFvmeYV77959rFmzjiZNAye+uGDeYnbtzA1YfZXBrnPYtGkjevQ4jzFjrE22bafKbiipIgeKqt7rRUWG/HzPKLFmzThaNW9GZnYOf2/dxm33PUqfm//LDXcMZuNfW/xqx6/zF9OhfVsS4muTEF+bDu3b8uv8xcTGxJB66ikArF27Nh9YAiRXqbNYk47SKnw6YBFpJSKDRWS4iLwiIreLSLxlDXK5WDB/Klu3LGPGjJ9ZuHCZVaZKaN48mVNOOYkFC5ZabqvfLX2Z9vNEXnxjKAkJ1pxGu87hiy8+wSOPPIs7BH7KBYpwUkWuClW919PSM1m9bgMnn5jCky+8zsOD7mDC6DcYPPAWnn7pLb/qyMzeTqOGDUo+JzVIJDN7+yH7pKSk1AF6AVWON4WTKrIvWfq7gXeBGKA9Hi24ZsBvItKpguNKcmwWFe2tVIPcbjepp/eg1dGpnNa+Da1bp1Tq+MpSs2Ycn306gsGD/8eePZVra2X5aPQEzm53IT3OuYKsjGwefXqwJXbsOIcXXHAeWVk5LF1a5URQis1U9V7fv/8Agx55mgfuvg2XuFi2YjX3Pfosl/e7iydfeIPsnB0AfPXdD1ze7y4u73cXf6xZxx2DH+Pyfndx90ND/bJTWFgEMB54fe3atRsr30MP4TQC9jUL4lagjVcJ+RVgijGmk4i8B0zCE685gtI5NqNjmlWpl7m5u5k9ey7du3Vi1aq1VanCJ5GRkXz22QjGf/oVX0/63hIbpdmenVOyPv7DiYz59E1L7Vl5Djt0OI2LLupKjx6diI6OJj6+NqNHv8bNN98bUDt2E06qyJWhOvf6vY88Tc9unTm/U0f27ttH7do1mTj2yFFv757d6N2zG+CJAT/zyP00bZxUsj2pQSILly4v+ZyZvZ32bU8u+fy/F4YDrFu7du1rlWrgYYTCwzV/8ScGXOyko4FaAMaYv7FAFTkxsV7Jz/KYmBi6dDnH0gc8I957iTVr1jN8+EjLbJSmYVJiyXr3i7qwdnXg+2bXOXz88Rc45pgzOP74s7jhhv8ya9bcsHe+EF6qyJWhqvd6YmINWjVvRr+rLwOgVs2aNG3ciGkzPQ+QjTGsWeffYLXj6acyd8EScnfvIXf3HuYuWELH008F4PURY9m7dz/AvZVqYBmEUwjC1wj4fWChiMwHzgaGAYhIA2BHoBvTqFFDRr3/KhEREbhcLr6YOJkp31sz9ejMM9tz3XVXsGLFahYumAbAY48PY+rUmQGp/42Rw+jQsT1169dh/sofeeX5t+jQsT2t/3M8xhi2/p3GQ/f599OsMth5Du3CTpXdUFJFDhRVvdejo13UrhXF/CW/c3k/zxS5e27rx7AnhvDUS2/y3tjxFBYWckGXczn+2FY+25EQX5vbbuzL1bfcA8DtN11DQnxtMrKyGTH2U1o2bwawJCUlBeDNtWvXvl+V/oZCaMFf/FFFPhE4AVhpjFlTWQNVDUFUBU1HWT00HWX44BL7dLn3pc2xzVZUYqtqd6xWXEu/L/ne/ZuCKnDu8004Y8wfwB82tEVRFKXahML8Xn/RV5EVRXEUmpBdURQlSLjDKB1lyL0JpyiKUh0COQ9YRHqIyFoRWS8iDwa6rToCVhTFUQTqYbyIRABvAecDW/HMCPvGGLMqIAbQEbCiKA7DVGLxQSqw3hiz0RiTD3wKXBLItlo+As47uKVK0zxEZID3jTpLscuO2govW07sk5NtlaYwP81vnyMiA4ABpYpGlGpzU6B0pqGtwOnVb+E/hPIIeIDvXcLKjtoKL1tO7JOTbVUJY8wIY8xppRZb/2CEsgNWFEUJJml4ko8Vk+wtCxjqgBVFUcpmIXCsiLQUkRrA1cA3gTQQyrMg7PopYOdPDrUVPrac2Ccn2wo4xphCERkITAMigNHeN4MDhs9cEIqiKIo1aAhCURQlSKgDVhRFCRIh54CtfvWvlJ3RIpIlIpZr6ohIMxH5SURWicgfInKPhbZiRGSBiPzutfWkVba89iJEZKmIfGuxnc0iskJElonIIott1RGRL0RkjYisFpEOFtlJ8faneNktIvdaZGuQ935YKSLjRSTGCjteW/d47fxhVX8cQ2Xem7Z6wRPo3gC0AmoAvwOtLbJ1DtAOT55jq/vVGGjnXa8N/GlhvwSo5V2PAuYDZ1jYt/uAccC3Fp/DzUCi1dfKa2sscIt3vQZQxwabEUAG0NyCupsCm4BY7+cJwI0W9eMkYCUQh+ch/4/AMXZct3BcQm0EbPmrf8UYY+ZggapHObbSjTFLvOt7gNV4vhRW2DLGmGLFxSjvYsmTVhFJBnriUU5xBCKSgOeP8ygAY0y+MWaXDaa7ABuMMX9ZVH8kECsikXic4zYf+1eVE4D5xpj9xphCYDZwmUW2wp5Qc8BlvfpniaMKFiLSAo+Y6XwLbUSIyDIgC5hujLHK1mvAEMCO/H8G+EFEFntfH7WKlkA2MMYbWnlfRGpaaK+Yq/EoAgccY0wa8BLwN5AO5BpjrBGf84x+zxaR+iISB1zIoS8zKKUINQfsaESkFjARuNcYs9sqO8aYImNMGzxv7qSKyEmBtiEiFwFZxpjFga67HM4yxrQDLgDuEpFzLLITiSc09Y4xpi2wD7DsWQSAd5L/xcDnFtVfF88vyZZAE6CmiFxnhS1jzGo82pE/AFOBZUCRFbacQKg5YMtf/QsWIhKFx/l+Yoz50g6b3p/OPwE9LKi+I3CxiGzGEyo6T0Q+tsAOUDKKwxiTBXyFJ1xlBVuBraV+NXyBxyFbyQXAEmNMpkX1dwU2GWOyjTEFwJfAmRbZwhgzyhhzqjHmHGAnnmceShmEmgO2/NW/YCAigiemuNoY84rFthqISB3veiyeXKaVFlP1hTHmIWNMsjGmBZ7rNNMYY8moSkRqikjt4nWgG56fugHHGJMBbBGRFG9RFyBg+V/LoS8WhR+8/A2cISJx3nuxC57nEJYgIg29/x+FJ/47zipb4U5IvYpsbHj1rxgRGQ90AhJFZCvwhDFmlBW28IwWrwdWeGOzAA8bY6ZYYKsxMNabTNoFTDDGWDpFzAaSgK88voNIYJwxZqqF9v4LfOIdBGwEbrLKkPcPyvnAbVbZMMbMF5EvgCVAIbAUa18Tnigi9YEC4C6bHmKGJfoqsqIoSpAItRCEoijKvwZ1wIqiKEFCHbCiKEqQUAesKIoSJNQBK4qiBAl1wIqiKEFCHbCiKEqQ+H+K0MWCOrLpUwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "heat_map(x_test, y_test, model_tunned)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Saving the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "model_json = model_tunned.to_json()\n",
    "with open('models/cnn_tunned.json', 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# Serialize weights to HDF5\n",
    "model_tunned.save_weights('models/cnn_tunned.h5')\n",
    "print('Model saved')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusiones<a name='id17'></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Las redes convolucionales tienen una ventaja fuertemente visible respecto a otros modelos la cual es la posibilidad de adaptarse a clases con numero de muestras bajo (clases desbalanceadas). En el presente trabajo, aunque no dio un mal resultado, le costó clasificar tanto bocinas de auto como disparos lo cual se logro solventar aumentando los mapas de características en cada una de las capas convolucionales y el numero de épocas. Esta estrategia garantizo que la clase desbalanceada sea estudiada por mas tiempo logrando reconocer el patrón de dichas clases y generalizándolo frente al conjunto de testeo.\n",
    "Dependiendo del conjunto de datos, es prudente utilizar uno u otro método para pre procesarlo. Trabajando con audio se concluyo que es mucho mejor utilizar la data original (a través de extracción de características) representada en un vector que abordar el problema ‘interpretando’ los audios como imágenes ya que se pierde mucha información importante que es decisiva para tener un buen rendimiento del modelo.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}